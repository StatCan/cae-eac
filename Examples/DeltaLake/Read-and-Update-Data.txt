
--- PYTHON ---

# read data from delta table
df = spark.read.format("delta").load(path)
df.show()

# --- conditional update -----------------------------
from pyspark.sql.functions import *
from delta.tables import *

delta_table = DeltaTable.forPath(spark, path)

# delete all even numbered rows
delta_table.delete("id % 2 == 0")

# change name of person with id = 1 to jade
delta_table.update("id == 1", { "given_name": "'jade'" } )

# show new data
deltaTable.toDF.show()


--- SCALA ---

// read data from delta table
val df = spark.read.format("delta").load(path)
df.show()

// --- conditional update -----------------------------
import io.delta.tables._
import org.apache.spark.sql.functions._

val delta_table = DeltaTable.forPath(path)

// delete all even numbered rows
delta_table.delete(condition = expr("id % 2 == 0"))

// change name of person with id = 1 to jade
delta_table.update("id == 1", { "given_name": "'jade'" } )

// show new data
deltaTable.toDF.show()


