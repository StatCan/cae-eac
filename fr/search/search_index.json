{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"En avant!","text":""},{"location":"#les-services-danalyse-des-donnees-sad-offrent-les-avantages-et-la-familiarite-dun-logiciel-statistique","title":"Les Services d\u2019analyse des donn\u00e9es (SAD) offrent les avantages et la familiarit\u00e9 d'un logiciel statistique","text":"<p>Les Services d\u2019analyse des donn\u00e9es, propuls\u00e9s par Statistique Canada, permettent aux intendants des donn\u00e9es, aux analystes et aux chercheurs d'acc\u00e9der \u00e0 des donn\u00e9es et des microdonn\u00e9es publiques dans un Environnement d'analyse collaborative. Ce service d'analyse de donn\u00e9es s\u00e9curis\u00e9 et en nuage, offre de nombreuses fonctionnalit\u00e9s avantageuses. -   T\u00e9l\u00e9versez et stockez des donn\u00e9es rapidement et en toute s\u00e9curit\u00e9 \u00e0 partir d'un compte de stockage interne ou externe. -   Choisissez parmi une vari\u00e9t\u00e9 d'outils qui vous sont familiers pour vous aider \u00e0 pr\u00e9parer et \u00e0 transformer des ensembles de donn\u00e9es. -   Analysez et pr\u00e9sentez des donn\u00e9es en utilisant des produits de visualisation dynamiques de mani\u00e8re \u00e0 captiver l'auditoire en faisant parler les donn\u00e9es.</p> <p>Veuillez noter qu'\u00e0 l'heure actuelle, certains outils peuvent ne pas \u00eatre accessibles aux fins d'utilisation dans les deux langues officielles. Statistique Canada a entrepris des d\u00e9marches pour s'assurer que tous les produits de donn\u00e9es et outils accessibles sur la plateforme des SAD soient offerts dans les deux langues officielles. Pour obtenir plus d'information \u00e0 ce sujet, veuillez visiter la documentation du langage GitHub pour EAC.</p>"},{"location":"#stockage-des-donnees","title":"Stockage des donn\u00e9es","text":"<p>G\u00e9rez, modifiez, partagez et sauvegardez</p> <p>Stockage Blob Azure</p> <p>Ce service comprend le stockage d'objets, de fichiers, de disques, de files d'attente et de tableaux. Des services de solutions de stockage hybrides et des services de transfert, de partage et de sauvegarde de donn\u00e9es sont \u00e9galement disponibles.</p> <p>Stockage Azure Datalake</p> <p>Cet outil, qui met \u00e0 profit les capacit\u00e9s de nos deux services de stockage existants, est d\u00e9di\u00e9 \u00e0 l'analyse des m\u00e9gadonn\u00e9es. Des fonctions, telles que la s\u00e9mantique de syst\u00e8me de fichiers, la fonction de r\u00e9pertoire et la s\u00e9curit\u00e9 de niveau fichier, sont combin\u00e9es au stockage hi\u00e9rarchis\u00e9 \u00e0 faible co\u00fbt et \u00e0 des capacit\u00e9s de haute disponibilit\u00e9 ou de r\u00e9cup\u00e9ration d'urgence.</p> <p>Base de donn\u00e9es SQL Azure)</p> <p>Ce moteur de base de donn\u00e9es, sous forme de plateforme en tant que service (PS), g\u00e8re automatiquement la plupart des fonctions de gestion de base de donn\u00e9es, telles que la mise \u00e0 niveau, la correction de programmes, les sauvegardes et la surveillance, sans intervention de l'utilisateur.</p>"},{"location":"#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<p>Nettoyez, organisez, formatez</p> <p>Azure Data Factory</p> <p>Cr\u00e9ez et planifiez des flux de travail ax\u00e9s sur les donn\u00e9es (appel\u00e9s pipelines) qui peuvent ing\u00e9rer des donn\u00e9es provenant de magasins de donn\u00e9es disparates, \u00e9laborez des processus d'ETC complexes qui transforment visuellement les donn\u00e9es au moyen de flux de donn\u00e9es, ou en utilisant des services de calcul comme Hadoop d'Azure HDInsight, Azure Databricks et Base de donn\u00e9es SQL Azure.</p>"},{"location":"#analyse-et-visualisation-des-donnees","title":"Analyse et visualisation des donn\u00e9es","text":"<p>Partagez des id\u00e9es et des histoires fond\u00e9es sur vos donn\u00e9es</p> <p>Azure Databricks</p> <p>Plateforme d'analytique fond\u00e9e sur Apache Spark et optimis\u00e9e pour la plateforme de services infonuagiques de Microsoft Azure.</p> <p>Power BI</p> <p>Ensemble d'applications et de services logiciels qui relient facilement vos sources de donn\u00e9es en vue de cr\u00e9er des aper\u00e7us coh\u00e9rents, visuellement immersifs et interactifs.</p> <p>Azure Machine Learning</p> <p>Entra\u00eenez, d\u00e9ployez et g\u00e9rez des mod\u00e8les d'apprentissage automatique, des exp\u00e9riences AutoML et des pipelines, et ce, \u00e0 grande \u00e9chelle.</p> <p>Machines virtuelles Azure </p> <p>Ce service vous permet de mettre en place rapidement un environnement pour les travaux quotidiens de votre \u00e9quipe, en cr\u00e9ant ou en utilisant des machines virtuelles au moyen d'Azure DevTest Labs.</p>"},{"location":"AzureML/","title":"Azure Machine Learning","text":""},{"location":"AzureML/#pour-commencer","title":"Pour commencer","text":"<ol> <li> <p>\u00c0 la page Vue d\u2019ensemble de l\u2019apprentissage automatique, cliquez sur Lancer le studio.</p> <p> </p> </li> <li> <p>Utilisez le menu d\u00e9roulant pour s\u00e9lectionner l\u2019abonnement vdl et l\u2019espace de travail Machine Learning auquel vous souhaitez acc\u00e9der, puis cliquez sur D\u00e9marrer.</p> <p></p> </li> <li> <p>Une fois dans votre espace de travail Machine Learning, vous pouvez former, d\u00e9ployer et g\u00e9rer des mod\u00e8les d\u2019apprentissage automatique, utiliser AutoML et utiliser des pipelines. Voir le Guide de d\u00e9marrage rapide pour obtenir de plus amples renseignements.</p> <p> </p> </li> </ol>"},{"location":"AzureML/#utilisation-de-la-fonction-independante-notebook-dazure-machine-learning","title":"Utilisation de la fonction ind\u00e9pendante notebook d\u2019Azure Machine Learning","text":""},{"location":"AzureML/#exigences","title":"Exigences","text":"<p>Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --&gt; Instances de calcul. Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack.</p>"},{"location":"AzureML/#etapes","title":"\u00c9tapes","text":"<ol> <li> <p>Sous Notebooks, cr\u00e9ez un nouveau notebook dans votre r\u00e9pertoire d\u2019utilisateur. Vous pouvez ensuite saisir le code \u00e0 ex\u00e9cuter.</p> <p></p> </li> <li> <p>S\u00e9lectionnez l\u2019instance de calcul qui vous est attribu\u00e9e.</p> <p></p> </li> <li> <p>Cliquez sur le bouton D\u00e9marrer le calcul et ex\u00e9cuter toutes les cellules pour ex\u00e9cuter votre code.</p> <p></p> </li> </ol>"},{"location":"AzureML/#utilisation-de-databricks-connect-comme-ordinateur-a-distance","title":"Utilisation de Databricks Connect comme ordinateur \u00e0 distance","text":"<p>Avertissement : Veuillez noter que la configuration de Databricks Connect pr\u00e9sent\u00e9e ci-dessous est en cours de r\u00e9vision et qu\u2019elle changera probablement dans un avenir proche.</p>"},{"location":"AzureML/#exigences_1","title":"Exigences","text":"<p>Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --&gt; Instances de calcul.</p> <p>Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack.</p>"},{"location":"AzureML/#etapes_1","title":"\u00c9tapes","text":"<ol> <li> <p>Sous Notebooks, ouvrez Terminal.</p> <p></p> </li> <li> <p>S\u00e9lectionnez votre instance de calcul dans le menu d\u00e9roulant \u00e0 c\u00f4t\u00e9 de Calculer.</p> </li> <li> <p>Ex\u00e9cutez le code \u00e0 partir de la page Databricks Connect Setup dans le terminal tout en suivant les directives pour continuer selon les besoins. Ce code installe Python 3.7 et met en place un nouveau noyau pour les notebooks d\u2019Azure Machine Learning.</p> <p>Lorsque vous y \u00eates invit\u00e9, entrez les valeurs suivantes pour configurer Databricks Connect :</p> <p>H\u00f4te : l\u2019URL de la page Vue d\u2019ensemble pour votre espace de travail Databricks</p> <p></p> <p>Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks</p> <p>ID de grappe : la valeur indiqu\u00e9e sous Instance de calcul --&gt; Options avanc\u00e9es--&gt; \u00c9tiquettes dans votre espace de travail Databricks</p> <p></p> <p>ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= </p> <p></p> <p>Port : conserver la valeur existante</p> </li> <li> <p>Ex\u00e9cutez le code suivant dans le terminal pour tester la connexion avec Azure Databricks.     <code>databricks-connect test (databricks - test de connexion)</code></p> </li> <li> <p>Cr\u00e9ez un nouveau notebook avec l\u2019espace de travail Azure Machine Learning et s\u00e9lectionnez noyau Python 3. La version Python 3.7.9 devrait maintenant s\u2019afficher.</p> <p></p> </li> <li> <p>Databricks Connect devrait maintenant \u00eatre configur\u00e9! Essayez le code \u00e9chantillon Databricks Connect dans le bloc-notes, en rempla\u00e7ant public-data/incoming/1test.txt par le chemin d\u2019acc\u00e8s \u00e0 un fichier dans votre conteneur de lac de donn\u00e9es.</p> </li> </ol>"},{"location":"AzureML/#demander-un-calcul","title":"Demander un calcul","text":"<p>Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal slack pour demander un calcul dans Azure Machine Learning. Vous recevrez l'erreur suivante si vous proc\u00e9dez \u00e0 la cr\u00e9ation par vous-m\u00eame:</p> <p></p>"},{"location":"AzurePortal/","title":"Portail Azure","text":""},{"location":"AzurePortal/#tableau-de-bord","title":"Tableau de bord","text":"<p>Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements.</p> <ol> <li> <p>Cliquez sur le menu Tableau de bord dans le portail\u00a0Azure.</p> <p></p> </li> </ol>"},{"location":"AzurePortal/#acceder-a-databricks-utilisateurs-internes","title":"Acc\u00e9der \u00e0 Databricks- Utilisateurs internes","text":"<ol> <li> <p>Dans la bo\u00eete de recherche du portail\u00a0Azure, recherchez Databricks.</p> <p></p> </li> <li> <p>Vous devriez alors voir une liste des espaces de travail\u00a0Databricks auxquels vous pouvez acc\u00e9der.</p> <p></p> </li> </ol>"},{"location":"AzurePortal/#acceder-a-synapse-utilisateurs-internes","title":"Acc\u00e9der \u00e0 Synapse- Utilisateurs internes","text":"<p>Il est recommand\u00e9 aux utilisateurs de Statistiques Canada d'acc\u00e9der aux diff\u00e9rents service \u00e0 partir de leur Bureau Virtuel Azure 1.  Assurez-vous que vous utilisez votre machine virtuelle en nuage pour acc\u00e9der \u00e0 Azure Synapse. Reportez-vous \u00e0 la rubrique Machines virtuelles pour savoir comment en cr\u00e9er une si n\u00e9cessaire.</p> <ol> <li> <p>Dans votre machine virtuelle, ouvrez un navigateur Web et acc\u00e9dez au portail Azure. Ouvrez une session \u00e0 l\u2019aide des donn\u00e9es d\u2019identification de votre compte en nuage.</p> </li> <li> <pre><code>a. Cliquez sur l\u2019ic\u00f4ne **Azure Synapse Analytics** sous **Services Azure**. Si vous ne voyez pas cette ic\u00f4ne, suivez plut\u00f4t l\u2019\u00e9tape 3b.\n</code></pre> <p></p> <p>b. Commencez \u00e0 taper \"synapse\" dans la barre de recherche pour trouver Azure Synapse Analytics.</p> <p> </p> </li> <li> <p>Rep\u00e9rez votre espace de travail Synapse dans la liste, puis cliquez dessus. Cliquez ensuite sur Ouvrir Synapse Studio.</p> </li> </ol> <p></p> <p>Note: Vous pouvez \u00e9galement acc\u00e9der aux espaces de travail Synapse \u00e0 partir du tableau de bord Environnement d\u2019analyse collaborative.</p>"},{"location":"AzurePortal/#acceder-a-azure-machine-learning-utilisateurs-internes","title":"Acc\u00e9der \u00e0 Azure Machine Learning- Utilisateurs internes","text":"<p>Il est recommand\u00e9 aux utilisateurs de Statistiques Canada d'acc\u00e9der aux diff\u00e9rents service \u00e0 partir de leur Bureau Virtuel Azure</p>"},{"location":"AzurePortal/#tableau-de-bord_1","title":"Tableau de bord","text":"<p>Consultez la section  Tableau de bord de cette documentation pour obtenir de plus amples renseignements..  </p> <ol> <li> <p>Cliquez sur le menu Tableau de bord du portail Azure. L\u2019affichage par d\u00e9faut pourrait d\u00e9j\u00e0 correspondre au tableau de bord.  </p> <p></p> </li> <li> <p>Sous Machine Learning (apprentissage automatique), s\u00e9lectionnez l\u2019espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous. Si l\u2019espace de travail que vous souhaitez ouvrir n\u2019est pas r\u00e9pertori\u00e9, cliquez sur Plus\u2026 pour acc\u00e9der \u00e0 la liste compl\u00e8te.</p> <p></p> </li> </ol>"},{"location":"AzurePortal/#portail-azure","title":"Portail Azure","text":"<ol> <li> <p>Dans la bo\u00eete de recherche du portail Azure, cherchez Machine Learning.</p> <p></p> </li> <li> <p>Vous devriez voir une liste des espaces de travail Machine Learning auxquels vous avez \u00e9t\u00e9 autoris\u00e9 \u00e0 acc\u00e9der. S\u00e9lectionnez l\u2019espace de travail Machine Learning auquel vous souhaitez acc\u00e9der</p> <p></p> </li> </ol>"},{"location":"AzurePortal/#adresse-de-machine-learning","title":"Adresse de Machine Learning","text":"<ol> <li> <p>Allez sur Machine Learning, connectez-vous avec les justificatifs d\u2019identit\u00e9 de votre compte d\u2019infonuagique, puis s\u00e9lectionnez l\u2019abonnement vdl et l\u2019espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous.</p> <p></p> </li> </ol>"},{"location":"AzureSQL/","title":"Base de donn\u00e9es Azure SQL","text":"<p>Une base de donn\u00e9es Azure SQL peut \u00eatre cr\u00e9\u00e9e \u00e0 l'avance si vous en avez besoin pour votre projet.</p> <p>Rappel: Les bases de donn\u00e9es Azure SQL de l'Environnement d'Analyse Collaborative (EAC) sont seulement disponibles \u00e0 partir de l'environnement infonuagique de l'EAC. Vous ne pouvez y acc\u00e9der \u00e0 partir des centres de donn\u00e9es du gouvernement du Canada.</p>"},{"location":"AzureSQL/#acces-a-une-base-de-donnees-azure-sql","title":"Acc\u00e8s \u00e0 une base de donn\u00e9es Azure\u00a0SQL","text":""},{"location":"AzureSQL/#azure-data-factory","title":"Azure Data Factory","text":"<p>On peut cr\u00e9er un service li\u00e9 dans Azure Data Factory. Configurez le service li\u00e9 pour se connecter via le runtime d'int\u00e9gration auto-h\u00e9berg\u00e9 et utilisez Identit\u00e9 manag\u00e9e comme M\u00e9thode d'authentification. Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack si vous avez besoin d'aide.</p>"},{"location":"AzureSQL/#databricks","title":"Databricks","text":"<p>On peut configurer un carnet Databricks pour ouvrir une connexion \u00e0 la base de donn\u00e9es. Puisque ceci exige une configuration additionnelle, veuillez faire une demande aupr\u00e8s de l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack.</p>"},{"location":"AzureSQL/#machine-virtuelle","title":"Machine virtuelle","text":"<p>Vous pouvez vous connecter \u00e0 une base de donn\u00e9es Azure SQL \u00e0 partir de votre machine virtuelle en infonuagique, en utilisant une application telle que:  - SQL Server Management Studio  - Power BI Desktop - Azure Data Studio - Visual Studio ou Visual Studio Code</p>"},{"location":"AzureSQL/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li> <p>Une machine virtuelle dans l'EAC. Voir la page Machines Virtuelle pour plus d'informations.</p> </li> <li> <p>SQL\u00a0Server\u00a0Management\u00a0Studio ou un autre outil tel que Power\u00a0BI\u00a0Desktop. Ces outils sont offerts par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine.</p> </li> </ul>"},{"location":"AzureSQL/#etapes","title":"\u00c9tapes","text":"<ol> <li> <p>Connectez-vous \u00e0 votre machine virtuelle dans l'EAC.</p> </li> <li> <p>Lancez un outil tel que SQL\u00a0Server\u00a0Management\u00a0Studio.</p> </li> <li> <p>Choisissez Azure Active Directory - Auth.universelle avec MFA comme type d'Authentication.</p> </li> <li> <p>Entrez le nom de votre serveur SQL puis entrez votre compte Cloud comme nom d'utilisateur.</p> <p></p> </li> <li> <p>Cliquez sur le bouton Options.</p> </li> <li> <p>Sous l'onglet Propri\u00e9t\u00e9s de Connexion, selectionnez le nom de la base de donn\u00e9es en face du libell\u00e9 Se connecter \u00e0 la base de donn\u00e9es, puis cliquez sur le bouton de Connexion.</p> <p></p> </li> <li> <p>Effectuer l'authentication avec les param\u00e8tres d'identification de votre compte Cloud.</p> </li> </ol>"},{"location":"AzureStorage/","title":"Stockage Azure","text":""},{"location":"AzureStorage/#stockage-azure-utilisateurs-externes","title":"Stockage Azure - Utilisateurs externes","text":""},{"location":"AzureStorage/#explorateur-de-stockage","title":"Explorateur de stockage","text":"<ol> <li> <p>Pour acc\u00e9der aux diff\u00e9rents services offerts, vous devez d'abord vous connecter \u00e0 votre machine virtuelle. Voir Connectez-Vous</p> </li> <li> <p>A partir de la machine virtuelle, vous serez en mesure d'acc\u00e9der \u00e0 votre espace de stockage en utilisant l'Explorateur de stockage Azure</p> </li> </ol>"},{"location":"AzureStorage/#ingestion-de-fichier-de-donnees","title":"Ingestion de fichier de donn\u00e9es","text":""},{"location":"AzureStorage/#tranfert-de-fichier-electroniques-tfe","title":"Tranfert de fichier Electroniques (TFE)","text":"<p>Pour certains cas d'utilisations, les donn\u00e9es sensibles peuvent \u00eatre transf\u00e9r\u00e9es en utilisant TFE. Veuillez nous contacter pour plus d'instructions si vous voulez recourir \u00e0 ce service.</p>"},{"location":"AzureStorage/#telecharger-les-donnees-sur-votre-espace-de-stoackage","title":"T\u00e9l\u00e9charger les donn\u00e9es sur votre espace de stoackage","text":"<ol> <li>A partir de votre machine virtuelle, il est possible de t\u00e9l\u00e9charger des donn\u00e9es directement  de certains liens. Exemples:</li> <li>statcan.gc.ca</li> <li>open.toronto.ca</li> <li>T\u00e9l\u00e9charger les donn\u00e9es sur le disque local de votre machine virtuelle</li> <li>T\u00e9l\u00e9versez les donn\u00e9es en utilisant l'explorateur de stockage Azure dans l'espace de stockage de votre projet.</li> </ol>"},{"location":"AzureStorageExplorer/","title":"Azure Storage Explorer","text":""},{"location":"AzureStorageExplorer/#explorateur-de-stockage","title":"Explorateur de Stockage","text":"<ol> <li> <p>Pour acc\u00e9der aux diff\u00e9rents services disponibles, vous devez au pr\u00e9alable vous connecter \u00e0 votre machine virtuelle. Voir Connectez vous</p> </li> <li> <p>Sur votre machine virtuelle, lancez l'Explorateur de stockage\u00a0Azure \u00e0 partir du menu\u00a0D\u00e9marrer.</p> </li> </ol> <p></p> <ol> <li>La premi\u00e8re fois que vous d\u00e9marrez l'explorateur de stockage, vous devrez cliquer sur le boutton de connexion</li> </ol> <p></p> <p>ou cliquer sur le bouton Sign in with Azure</p> <p></p> <ol> <li>Vous devrez ensuite selectionner votre environement.  </li> </ol> <p> </p> <ol> <li>et vous connecter en utilisant vos identifiants azure</li> </ol> <p> </p> <ol> <li> <p>Une fois connect\u00e9, vos espaces de stockage seront visibles.</p> </li> <li> <p>Vous pourrez t\u00e9l\u00e9charger ou t\u00e9l\u00e9verser des fichiers vers\\\u00e0 partir de votre machine virtuelle en utilisant votre espace de stockage </p> </li> </ol> <p> </p> <ol> <li>Vous devez t\u00e9l\u00e9charger vos fichiers de donn\u00e9es sur le disque local de votre machine virtuelle pour pouvoir les utiliser avec les outils install\u00e9s sur la localement. Les espaces de stockage ne peuvent pas \u00eatre connect\u00e9s aux machines virtuelles.</li> <li>Vous pouvez cr\u00e9er des repertoires personnels pour pouvoir organiser vos fichiers.</li> </ol> <p>Note: 9. Il est bien de toujours t\u00e9l\u00e9verser ou stocker vos donn\u00e9esB sur votre espace de stockage. Il n'y a pas de sauvegarde effectu\u00e9es pour les donn\u00e9es sur les machines virtuelles.</p>"},{"location":"AzureStorageExplorer/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>T\u00e9l\u00e9chargez l'Explorateur de stockage\u00a0Azure</li> <li>D\u00e9marrage rapide\u00a0: Charger, t\u00e9l\u00e9charger et lister les objets blob avec le portail\u00a0Azure</li> </ul>"},{"location":"AzureSynapse/","title":"Azure Synapse","text":""},{"location":"AzureSynapse/#pour-commencer","title":"Pour commencer","text":""},{"location":"AzureSynapse/#demarrer-et-arreter-un-pool-sql-dedie","title":"D\u00e9marrer et arr\u00eater un pool SQL d\u00e9di\u00e9","text":"<ol> <li>Cliquez sur l\u2019onglet Int\u00e9grer.</li> </ol> <ol> <li>Sous Pipelines, cliquez soit sur Start Dedicated SQL Pool, soit sur Pause Dedicated SQL Pool. Ensuite, cliquez sur le bouton de d\u00e9clenchement pour ouvrir un menu, puis s\u00e9lectionnez D\u00e9clencher maintenant. \u00c0 l\u2019\u00e9cran suivant, cliquez sur OK.</li> </ol>"},{"location":"AzureSynapse/#accueil","title":"Accueil","text":"<p>L\u2019onglet Accueil est l\u2019endroit o\u00f9 vous commencez lorsque vous ouvrez Azure Synapse Studio pour la premi\u00e8re fois.</p> <p>\u00c0 partir de cet endroit, vous pouvez acc\u00e9der \u00e0 des raccourcis pour des t\u00e2ches courantes telles que la cr\u00e9ation de scripts SQL ou de notebooks en cliquant sur le bouton du menu d\u00e9roulant Nouveau. Les ressources r\u00e9cemment ouvertes sont \u00e9galement affich\u00e9es.</p>"},{"location":"AzureSynapse/#donnees","title":"Donn\u00e9es","text":"<p>L\u2019onglet Donn\u00e9es est l\u2019endroit o\u00f9 vous pouvez explorer tout ce qui se trouve dans votre base de donn\u00e9es et les jeux de donn\u00e9es li\u00e9s.</p> <p>Sous l\u2019onglet Espace de travail, vous pouvez explorer la base de donn\u00e9es du pool SQL d\u00e9di\u00e9 ainsi que toutes les bases de donn\u00e9es Spark.</p> <p>Sous l\u2019onglet Li\u00e9, vous pouvez explorer des objets externes (p. ex. comptes Data Lake) et explorer et cr\u00e9er tous jeux de donn\u00e9es d\u2019int\u00e9gration \u00e0 partir de donn\u00e9es externes li\u00e9es (p. ex. Data Lake, stockage Blob, service Web) \u00e0 utiliser dans les pipelines.</p>"},{"location":"AzureSynapse/#comment-introduire-des-donnees-a-partir-de-services-lies","title":"Comment introduire des donn\u00e9es \u00e0 partir de services li\u00e9s","text":"<p>Note: Cet exemple montre comment obtenir des donn\u00e9es \u00e0 partir de Data Lake, bien qu\u2019il y ait de nombreux types de sources disponibles.</p> <ol> <li>Cliquez sur le bouton \u00ab + \u00bb pour ajouter une nouvelle ressource, puis cliquez sur Jeu de donn\u00e9es d\u2019int\u00e9gration.</li> </ol> <p></p> <ol> <li>S\u00e9lectionnez Azure Data Lake Storage Gen2 (pour ce faire, vous devrez peut-\u00eatre effectuer une recherche), puis cliquez sur Continuer. </li> </ol> <p></p> <ol> <li> <p>S\u00e9lectionnez le type de format, puis cliquez sur Continuer.</p> </li> <li> <p>Saisissez un nom, puis cliquez sur le menu d\u00e9roulant sous Service li\u00e9. S\u00e9lectionnez ensuite votre lac de donn\u00e9es.</p> </li> </ol> <p></p> <ol> <li>Sous Runtime d\u2019int\u00e9gration, assurez-vous que la cr\u00e9ation interactive est activ\u00e9e. Dans la n\u00e9gative, cliquez sur le bouton d\u2019\u00e9dition pour l\u2019activer, puis cliquez sur Appliquer.</li> </ol> <p></p> <ol> <li>D\u00e9finissez des propri\u00e9t\u00e9s suppl\u00e9mentaires comme il convient, puis cliquez sur OK.</li> </ol>"},{"location":"AzureSynapse/#comment-explorer-les-donnees-dans-le-lac-de-donnees","title":"Comment explorer les donn\u00e9es dans le lac de donn\u00e9es","text":"<p>Recherchez votre fichier de donn\u00e9es (CSV, Parquet, JSON, Avro, etc.) et faites un clic droit dessus. Un menu s\u2019ouvre avec des options permettant d\u2019avoir un aper\u00e7u des donn\u00e9es ou de cr\u00e9er des ressources telles que des scripts SQL et des notebooks.</p> <p></p>"},{"location":"AzureSynapse/#comment-explorer-le-pool-sql-dedie","title":"Comment explorer le pool SQL d\u00e9di\u00e9","text":"<p>Sous l\u2019onglet Espace de travail, vous pouvez explorer les bases de donn\u00e9es de mani\u00e8re similaire \u00e0 SQL Server Management Studio. Cliquez avec le bouton droit de la souris sur n\u2019importe quel tableau, mettez en surbrillance Nouveau script SQL, puis cliquez sur S\u00e9lectionner les 100 premi\u00e8res lignes pour cr\u00e9er une nouvelle requ\u00eate. Vous pouvez ensuite afficher les r\u00e9sultats sous forme de tableau ou de graphique.</p> <p></p>"},{"location":"AzureSynapse/#importation-de-donnees-vers-le-pool-sql-dedie","title":"Importation de donn\u00e9es vers le pool SQL d\u00e9di\u00e9","text":"<p>Pour importer des donn\u00e9es vers le pool SQL d\u00e9di\u00e9, vous pouvez soit: -   cr\u00e9er un pipeline avec une activit\u00e9 de copie de donn\u00e9es (la plus efficace pour les grands jeux de donn\u00e9es); -   utiliser l\u2019assistant Chargement en masse.</p>"},{"location":"AzureSynapse/#developper","title":"D\u00e9velopper","text":"<p>\u00c0 partir de l\u00e0, vous pouvez cr\u00e9er et enregistrer des ressources telles que des scripts SQL, des notebooks et des rapports Power BI.</p> <p>Pour ajouter une nouvelle ressource, cliquez sur le bouton \u00ab+\u00bb. Un menu d\u00e9roulant s\u2019ouvre.</p> <p></p> <p>Pour rendre vos modifications visibles aux autres, vous devez cliquer sur le bouton Publier.</p>"},{"location":"AzureSynapse/#scripts-sql","title":"Scripts SQL","text":"<p>Assurez-vous de vous connecter \u00e0 votre pool SQL d\u00e9di\u00e9 pour ex\u00e9cuter des scripts SQL.</p> <p></p>"},{"location":"AzureSynapse/#notebooks","title":"Notebooks","text":"<p>Pour ex\u00e9cuter les cellules notebook, vous devez d\u2019abord s\u00e9lectionner votre pool Apache Spark.</p> <p></p> <p>Pour changer de langue pour une seule cellule, vous pouvez utiliser les commandes magiques suivantes : %%pyspark, %%spark, %%csharp et %%sql. Vous pouvez \u00e9galement modifier la langue par d\u00e9faut \u00e0 l\u2019aide du menu d\u00e9roulant Langue.</p> <p></p>"},{"location":"AzureSynapse/#flux-de-donnees","title":"Flux de donn\u00e9es","text":"<p>Pour ajouter une source \u00e0 un flux de donn\u00e9es, cliquez sur le bouton \u00ab+\u00bb sous Param\u00e8tres de la source, puis s\u00e9lectionnez Azure Data Lake Storage Gen2 (pour ce faire, vous devrez peut-\u00eatre effectuer une recherche). Cliquez sur Continuer, s\u00e9lectionnez le format de donn\u00e9es, puis, sur la page suivante, s\u00e9lectionnez votre service li\u00e9.</p> <p></p>"},{"location":"AzureSynapse/#rapports-power-bi","title":"Rapports Power BI","text":"<p>Vous pouvez afficher et cr\u00e9er des rapports Power BI directement dans Azure Synapse. Veuillez communiquer avec l\u2019\u00e9quipe d\u2019assistance de l\u2019Environnement d\u2019analyse collaborative pour valider qu\u2019un service li\u00e9 est configur\u00e9.</p>"},{"location":"AzureSynapse/#integrer","title":"Int\u00e9grer","text":"<p>C\u2019est ici que vous pouvez cr\u00e9er des pipelines pour ing\u00e9rer, pr\u00e9parer et transformer toutes vos donn\u00e9es, comme dans Azure Data Factory. </p>"},{"location":"AzureSynapse/#exemple-copier-les-donnees-dun-blob-externe-vers-un-lac-de-donnees","title":"Exemple : Copier les donn\u00e9es d\u2019un blob externe vers un lac de donn\u00e9es","text":"<ol> <li>Cliquez sur le bouton \u00ab+\u00bb pour ajouter une nouvelle ressource, puis cliquez sur Pipeline.</li> </ol> <ol> <li>Sous D\u00e9placer et transformer, faites glisser et d\u00e9posez Copier les donn\u00e9es dans la fen\u00eatre.</li> </ol> <ol> <li>Cliquez sur l\u2019onglet Source, puis cliquez sur Nouveau pour ajouter le jeu de donn\u00e9es source (d\u2019o\u00f9 vous voulez copier les donn\u00e9es).</li> </ol> <ol> <li> <p>S\u00e9lectionnez Azure Blob Storage, puis s\u00e9lectionnez le type de format (CSV, Parquet, JSON, etc.). D\u00e9finissez toute propri\u00e9t\u00e9 suppl\u00e9mentaire si n\u00e9cessaire, puis cliquez sur OK.</p> </li> <li> <p>Cliquez sur R\u00e9cepteur, puis sur Nouveau pour d\u00e9finir le jeu de donn\u00e9es r\u00e9cepteur (o\u00f9 vous souhaitez que les donn\u00e9es soient copi\u00e9es). Choisissez Azure Data Lake Storage Gen2, puis s\u00e9lectionnez le type de format. Sous Service li\u00e9, choisissez votre lac de donn\u00e9es et assurez-vous que la cr\u00e9ation interactive est activ\u00e9e (voir Comment introduire des donn\u00e9es \u00e0 partir de services li\u00e9s sous Donn\u00e9es pour de plus amples renseignements).</p> </li> </ol>"},{"location":"AzureSynapse/#debogage-et-execution-des-pipelines","title":"D\u00e9bogage et ex\u00e9cution des pipelines","text":"<p>Pour ex\u00e9cuter un pipeline en mode d\u00e9bogage, cliquez sur le bouton D\u00e9boguer en haut de la fen\u00eatre du pipeline. Les r\u00e9sultats figureront dans l\u2019onglet Sortie.</p> <p></p> <p>Pour ex\u00e9cuter un pipeline sans d\u00e9boguer, cliquez sur le bouton Ajouter un d\u00e9clencheur, puis sur D\u00e9clencher maintenant.</p> <p>Lorsque vous \u00eates pr\u00eat \u00e0 publier vos pipelines, cliquez sur le bouton Tout valider, puis sur Tout publier. Il est \u00e0 noter que cette publication permettra \u00e0 l\u2019ensemble des utilisateurs de voir tout ce que vous avez actuellement ouvert (pipelines, scripts SQL, notebooks, etc.).</p> <p></p>"},{"location":"AzureSynapse/#superviser","title":"Superviser","text":"<p>\u00c0 partir de l\u2019onglet Superviser, vous pouvez superviser les ex\u00e9cutions en direct du pipeline (les entr\u00e9es et les sorties de chaque activit\u00e9 et les \u00e9ventuelles erreurs) et afficher l\u2019historique des ex\u00e9cutions du pipeline, des d\u00e9clencheurs, des requ\u00eates SQL, etc.</p>"},{"location":"AzureSynapse/#gerer","title":"G\u00e9rer","text":"<p>C\u2019est ici que vous pouvez : -   ajouter de nouveaux pools SQL ou Apache Spark; -   ajouter de nouveaux services li\u00e9s; -   accorder \u00e0 d\u2019autres personnes l\u2019acc\u00e8s \u00e0 l\u2019espace de travail; -   configurer l\u2019int\u00e9gration de Git.</p>"},{"location":"AzureSynapse/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Azure Synapse Analytics</li> <li>Qu\u2019est-ce qu\u2019Azure Synapse Analytics? </li> <li>Analyser des donn\u00e9es avec des pools SQL d\u00e9di\u00e9s</li> <li>Int\u00e9grer avec des pipelines</li> <li>Visualiser des donn\u00e9es avec Power BI</li> <li>Surveiller votre espace de travail Synapse</li> </ul>"},{"location":"AzureSynapse/#changer-la-langue-daffichage","title":"Changer la langue d\u2019affichage","text":"<p>Consultez la page Langue pour savoir comment modifier la langue d\u2019affichage.</p>"},{"location":"BVA/","title":"BVA","text":""},{"location":"BVA/#bureau-virtuel-azure","title":"Bureau Virtuel Azure","text":"<p>Les employ\u00e9s de Statistiques Canada ont acc\u00e8s au Bureau Virtuel Azure sur leur ordinateur de travail. Ils peuvent utiliser leur compte statcan.gc.ca pour se connecter au Bureau Virtuel Azure.</p> <ol> <li> <p>Pour pouvoir se connecter au Bureau Virtuel Azure, vous aurez besoin de votre identifiant statcan: firstname.lastname@statcan.gc.ca</p> </li> <li> <p>Vous devrez vous connecter \u00e0 votre environement  \u00e0 partir du Bureau Virtuel Azure (BVA). A partir de la barre de recherche Windows, vous pouvez acc\u00e9der \u00e0 l'application de bureau \u00e0 distance et s\u00e9lectionner votre BVA et entrer votre identifiant et votre mot de passe du r\u00e9seau A comme le montre l'image ci-dessous.</p> <p> </p> </li> <li> <p>Une fois connect\u00e9, vous pouvez acc\u00e9der aux services \u00e0 partir du Tableau de bord Azure </p> </li> </ol>"},{"location":"BVAStockage/","title":"Stockage Azure","text":""},{"location":"BVAStockage/#stockage-azure-employes-de-statistiques-canada","title":"Stockage Azure - Employ\u00e9s de Statistiques Canada","text":"<p>Les donn\u00e9es peuvent \u00eatre t\u00e9l\u00e9vers\u00e9es sur la plateforme par l'entremise du portail\u00a0Azure ou de l'application Explorateur de stockage\u00a0Azure. Une fois qu'elles auront \u00e9t\u00e9 t\u00e9l\u00e9vers\u00e9es dans un compte de stockage externe Blob\u00a0Azure, elles seront automatiquement ing\u00e9r\u00e9es dans un compte de stockage interne Azure\u00a0Data\u00a0Lake\u00a0Storage\u00a0(ADLS). Lorsque les donn\u00e9es seront dans Data\u00a0Lake, les utilisateurs pourront choisir des outils de transformation et d'int\u00e9gration. Ils pourront utiliser des outils\u00a0Web, comme Databricks et Data\u00a0Factory, pour effectuer des transformations ou des outils de bureau sur une machine virtuelle pour transformer et analyser les donn\u00e9es. Les donn\u00e9es nettoy\u00e9es et transform\u00e9es pourront \u00eatre plac\u00e9es dans diff\u00e9rents dossiers (contenant des ensembles de donn\u00e9es trait\u00e9es ou de meilleure qualit\u00e9) ou t\u00e9l\u00e9vers\u00e9es dans une base de donn\u00e9es. Les utilisateurs seront de nouveau en mesure de se connecter \u00e0 ces donn\u00e9es \u00e0 l'aide des outils qu'ils souhaiteront utiliser, et ce, \u00e0 partir de leur machine virtuelle ou d'autres services offerts sur la plateforme, tels que Databricks et Data\u00a0Factory.</p> <p>En utilisant votre Bureau Virtuel Azure, vous pouvez acc\u00e9der \u00e0 votre espace de stockage infonuagique.</p>"},{"location":"BVAStockage/#explorateur-de-stockage","title":"Explorateur de stockage","text":"<ol> <li>Si vous n'avez pas l'explorateur de stockage install\u00e9 dans votre Bureau Virtuel Azure, vous pouvez en faire la demande avec le  Portail de Gestion des Demandes de Service (GDS) Uniquement pour les employ\u00e9s de Statistiques Canada. Selectionnez ce qui suit:</li> <li>Type de Demande: \"Soutien aux postes de travail\"</li> <li>Sujet: \"Bureau Virtuel (BVA/AVD, VDI)\"</li> <li>Sous-sujet: \"Bureau Virtuel Azure - BVA/AVD (Cr\u00e9er ou Modifier)\"</li> <li> <p>Description: \"J'aimerais obtenir un Bureau Virtuel Azure avec l'explorateur de Stockage install\u00e9\"</p> </li> <li> <p>Sur votre Bureau Virtuel Azure, vous serez en mesure d'acc\u00e9der \u00e0 vos espaces de stockage en utilisant l'explorateur de Stockage Azure</p> </li> </ol>"},{"location":"BVAStockage/#portail-azure","title":"Portail Azure","text":"<ol> <li> <p>Acc\u00e9dez au compte de stockage (aper\u00e7u) Storage Account (Preview) \u00e0 partir du portail\u00a0Azure.</p> <p></p> </li> <li> <p>S\u00e9lectionnez votre type d'abonnement, puis naviguez dans votre compte de stockage.</p> <p></p> </li> </ol> <p>Questions Frequemment pos\u00e9es (FAQ) 1. J'obtiens l'erreur suivante en essayant d'acc\u00e9der \u00e0 mon espace de stockage.</p> <p>    Assurez vous d'acc\u00e9der \u00e0 l'espace de stockage \u00e0 partir de votre Bureau Virtuel Azure (BVA) et non directement \u00e0 partir de votre appareil de travail fourni par le gouvernement.</p>"},{"location":"BVAStockage/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>T\u00e9l\u00e9chargez l'Explorateur de stockage\u00a0Azure</li> <li>D\u00e9marrage rapide\u00a0: Charger, t\u00e9l\u00e9charger et lister les objets blob avec le portail\u00a0Azure</li> </ul>"},{"location":"BonnesPratiques/","title":"Bonnes pratiques","text":""},{"location":"BonnesPratiques/#quel-est-le-meilleur-format-de-fichier-a-utiliser-pour-les-fichiers-de-donnees-volumineux","title":"Quel est le meilleur format de fichier \u00e0 utiliser pour les fichiers de donn\u00e9es volumineux?","text":"<p>Il est recommand\u00e9 d'utiliser un format plus r\u00e9cent comme Parquet, car il enregistre des ensembles de dates plus volumineux dans un fichier plus petit par rapport \u00e0 un fichier CSV. Si vous n'acc\u00e9dez qu'\u00e0 certaines sections de l'ensemble de donn\u00e9es, il est \u00e9galement plus rapide d'utiliser Parquet car il utilise un format de stockage en colonnes.</p>"},{"location":"BonnesPratiques/#ai-je-besoin-dune-base-de-donnees-sql","title":"Ai-je besoin d'une base de donn\u00e9es SQL?","text":"<p>Dans de nombreux cas, une base de donn\u00e9es SQL n'est pas n\u00e9cessaire, les donn\u00e9es peuvent \u00eatre enregistr\u00e9es dans des fichiers sur le datalake.</p>"},{"location":"BonnesPratiques/#ai-je-besoin-dune-base-de-donnees-sql-lorsque-jutilise-power-bi","title":"Ai-je besoin d'une base de donn\u00e9es SQL lorsque j'utilise Power BI?","text":"<p>Il n'est pas n\u00e9cessaire d'avoir une base de donn\u00e9es SQL lors de l'utilisation de Power BI. Vous pouvez lire des fichiers \u00e0 partir du stockage Azure. Une base de donn\u00e9es n'est n\u00e9cessaire que lorsque vous utilisez un syst\u00e8me similaire \u00e0 un sch\u00e9ma en \u00e9toile plus complexe.</p> <p>Pour vous connecter au lac de donn\u00e9es interne avec Power BI Desktop, veuillez vous r\u00e9f\u00e9rer \u00e0 ce lien\u00a0: Comment puis je me connecter au compte de stockage interne data lake avec power bi desktop</p>"},{"location":"BonnesPratiques/#comment-devons-nous-structurer-le-conteneur-de-lac-de-donnees-de-nos-projets","title":"Comment devons-nous structurer le conteneur de lac de donn\u00e9es de nos projets?","text":"<p>Il y a 4 parties dans lesquelles structurer votre conteneur de lac de donn\u00e9es\u00a0:</p>"},{"location":"BonnesPratiques/#zone-bronzebrute","title":"Zone Bronze/Brute","text":"<p>Cette zone stocke le format d'origine de tous les fichiers ou fichiers/donn\u00e9es qui sont immuables. Les donn\u00e9es contenues dans cette zone sont g\u00e9n\u00e9ralement verrouill\u00e9es et ne sont accessibles qu'\u00e0 certains membres ou sont en lecture seule. Cette zone est \u00e9galement organis\u00e9e en diff\u00e9rents dossiers par syst\u00e8me source, chaque processus d'ingestion n'ayant un acc\u00e8s en \u00e9criture qu'\u00e0 son dossier associ\u00e9.</p>"},{"location":"BonnesPratiques/#zone-argentnettoyee","title":"Zone Argent/Nettoy\u00e9e","text":"<p>Cette zone est l'endroit o\u00f9 des parties de donn\u00e9es suppriment les colonnes inutiles des donn\u00e9es, valide, standardise et harmonise ces donn\u00e9es au sein de cette zone. Cette zone est principalement un dossier par projet. Toutes les donn\u00e9es auxquelles il faut acc\u00e9der dans cette zone b\u00e9n\u00e9ficient g\u00e9n\u00e9ralement d'un acc\u00e8s en lecture seule.</p>"},{"location":"BonnesPratiques/#zone-orcure","title":"Zone Or/Cur\u00e9","text":"<p>Cette zone est principalement destin\u00e9e \u00e0 l'analyse plut\u00f4t qu'\u00e0 l'ingestion ou au traitement de donn\u00e9es. Les donn\u00e9es de la zone organis\u00e9e sont stock\u00e9es dans des sch\u00e9mas en \u00e9toile. La mod\u00e9lisation dimensionnelle est g\u00e9n\u00e9ralement effectu\u00e9e \u00e0 l'aide de Spark ou de Data Factory au lieu de l'int\u00e9rieur du moteur de base de donn\u00e9es. Mais si la mod\u00e9lisation dimensionnelle est effectu\u00e9e \u00e0 l'ext\u00e9rieur du lac, il est pr\u00e9f\u00e9rable de publier le mod\u00e8le dans le lac. Cette zone est la mieux adapt\u00e9e pour ex\u00e9cuter des requ\u00eates et des analyses \u00e0 grande \u00e9chelle qui n'ont pas de besoins stricts en mati\u00e8re de rapports sensibles au temps.</p>"},{"location":"BonnesPratiques/#zone-laboratoire","title":"Zone Laboratoire","text":"<p>Cette zone est principalement destin\u00e9e \u00e0 l'exp\u00e9rimentation et \u00e0 l'exploration. Il est utilis\u00e9 pour le prototype et l'innovation en m\u00e9langeant \u00e0 la fois vos propres ensembles de donn\u00e9es avec des ensembles de donn\u00e9es de production. Cette zone ne remplace pas un lac de donn\u00e9es de d\u00e9veloppement ou de test requis pour un d\u00e9veloppement plus minutieux. Chaque projet de lac de donn\u00e9es wil aurait sa propre zone de laboratoire via un dossier. Les autorisations dans cette zone sont g\u00e9n\u00e9ralement en lecture et en \u00e9criture pour chaque utilisateur/projet.</p> <p>Pour plus d'informations sur la structuration du conteneur de lac de donn\u00e9es de vos projets\u00a0:</p> <p>Construire votre Data Lake sur Azure Data Lake Storage gen2 Concevoir Azure Data Lake Storage</p>"},{"location":"BonnesPratiques/#je-recois-une-exception-de-memoire-insuffisante-dans-databricks","title":"Je re\u00e7ois une exception de m\u00e9moire insuffisante dans Databricks?","text":""},{"location":"BonnesPratiques/#option-1","title":"Option 1:","text":"<p>Le moyen le plus rapide et le plus co\u00fbteux de r\u00e9soudre ce probl\u00e8me consiste \u00e0 augmenter la taille de votre cluster.</p> <p>Pour augmenter la taille du cluster, veuillez contacter l'\u00e9quipe d'assistance CAE pour augmenter la taille du cluster.</p>"},{"location":"BonnesPratiques/#option-2","title":"Option 2:","text":"<p>Pour une r\u00e9ponse plus programmatique, si vous utilisez des pandas, il est \u00e9galement sugg\u00e9r\u00e9 de basculer et d'utiliser pySpark ou koalas. PySpark et les koalas peuvent s'ex\u00e9cuter plus rapidement que les pandas, ils ont de meilleurs avantages \u00e0 utiliser des pipelines d'ingestion de donn\u00e9es et fonctionnent \u00e9galement efficacement car ils s'ex\u00e9cutent en parall\u00e8le sur diff\u00e9rents n\u0153uds d'un cluster.</p> <p>Op\u00e9rations Spark Dataframe</p>"},{"location":"BonnesPratiques/#option-3","title":"Option 3:","text":"<p>Pensez \u00e0 utiliser un sous-ensemble de vos donn\u00e9es lorsque vous effectuez des requ\u00eates si possible. Si vous ne travaillez qu'avec une certaine section de l'ensemble de donn\u00e9es mais que vous l'interrogez sur l'ensemble, il est possible d'utiliser uniquement le sous-ensemble.</p>"},{"location":"BonnesPratiques/#option-4","title":"Option 4:","text":"<p>Envisagez de changer le format de fichier en quelque chose comme Parquet ou Avro qui utilise moins d'espace qu'un fichier CSV traditionnel.</p> <p>Conversion de CSV en parquet:</p> <pre><code>%python\n\ntestConvert = spark.read.format('csv').options(header='true', inferSchema='true').load('/mnt/public-data/incoming/titanic.csv')\ntestConvert.write.parquet(\"/mnt/public-data/incoming/testingFile\")\n</code></pre> <p>Conversion de CSV en Avro:</p> <pre><code>%python\n\ndiamonds = spark.read.format('csv').options(header='true', inferSchema='true').load('/mnt/public-data/incoming/titanic.csv')\ndiamonds.write.format(\"avro\").save(\"/mnt/public-data/incoming/testingFile\")\n</code></pre>"},{"location":"BonnesPratiques/#comment-puis-je-facilement-convertir-le-code-sas-en-python-ou-r","title":"Comment puis-je facilement convertir le code SAS en Python ou R?","text":"<p>Il n'est pas possible de convertir facilement le code SAS en Python ou R automatiquement, le seul moyen connu de convertir est de faire manuellement la conversion.</p>"},{"location":"BonnesPratiques/#comment-puis-je-valider-que-je-developpe-mon-application-de-la-maniere-la-plus-rentable-dans-le-cloud-a-laide-des-technologies-microsoft-cae","title":"Comment puis-je valider que je d\u00e9veloppe mon application de la mani\u00e8re la plus rentable dans le cloud \u00e0 l'aide des technologies Microsoft (CAE)?","text":"<p>Il existe de nombreuses fa\u00e7ons de valider que votre d\u00e9veloppement est le plus rentable possible:</p> <ol> <li> <p>Profitez de Spark dans les databricks.</p> <p>a. Spark est un excellent ajout aux databricks qui s'ex\u00e9cutent plus rapidement et mieux, en particulier pour les grands ensembles de donn\u00e9es. Utiliser Spark co\u00fbterait moins cher car cela prend moins de temps pour faire sa t\u00e2che.</p> </li> <li> <p>Assurez-vous que votre cluster est en cours d'ex\u00e9cution pendant une dur\u00e9e minimale.</p> <p>a. Si le cluster n'est plus n\u00e9cessaire ou n'est pas utilis\u00e9, assurez-vous qu'il n'est pas en cours d'ex\u00e9cution et qu'il ne s'ex\u00e9cute que lorsqu'il est n\u00e9cessaire.</p> </li> <li> <p>Assurez-vous que votre cluster de briques de donn\u00e9es est correctement dimensionn\u00e9.</p> <p>a. Assurez-vous que vous devez corriger le nombre de travailleurs dans votre cluster, un trop grand nombre de clusters entra\u00eene un co\u00fbt plus \u00e9lev\u00e9.</p> </li> <li> <p>Supprimez les fichiers de donn\u00e9es que vous n'utilisez pas.</p> <p>a. Assurez-vous que tous les fichiers qui ne sont plus n\u00e9cessaires ou qui ne sont plus utilis\u00e9s sont supprim\u00e9s du conteneur.</p> </li> <li> <p>Essayez de ne pas effectuer de traitement sur une machine virtuelle cloud.</p> </li> <li> <p>Demandez un examen de votre architecture.</p> </li> <li> <p>Revue de code.</p> </li> <li> <p>Si vous utilisez des Pandas, c'est une bonne id\u00e9e de passer aux Koalas.</p> </li> <li> <p>Utilisez un format de fichier optimal pour votre charge de travail (par exemple, Parquet, Avro)</p> </li> </ol>"},{"location":"BonnesPratiques/#comment-les-donnees-doivent-elles-etre-structurees-si-nous-prevoyons-dutiliser-power-bi","title":"Comment les donn\u00e9es doivent-elles \u00eatre structur\u00e9es si nous pr\u00e9voyons d'utiliser Power BI?","text":"<p>Les donn\u00e9es doivent \u00eatre structur\u00e9es \u00e0 l'aide du sch\u00e9ma en \u00e9toile.</p> <p>Pour plus de d\u00e9tails sur l'utilisation de Star Schema, cliquez sur le lien ci-dessous pour en savoir plus sur l'utilisation de Star Schema et les avantages avec Power BI:</p> <p>Documentation du Star Schema</p>"},{"location":"BonnesPratiques/#comment-lire-dans-un-fichier-excel-depuis-databricks","title":"Comment lire dans un fichier Excel depuis Databricks?","text":"<p>Voici un exemple de lecture d'un fichier Excel \u00e0 l'aide de Python:</p> <pre><code>%python\nimport pandas as pd\npd.read_excel(\"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\", engine='openpyxl')\n</code></pre>"},{"location":"BonnesPratiques/#quels-types-de-fichiers-sont-les-meilleurs-a-utiliser-quand","title":"Quels types de fichiers sont les meilleurs \u00e0 utiliser quand?","text":""},{"location":"BonnesPratiques/#parquet","title":"Parquet","text":"<p>Il est bon \u00e0 utiliser pour de tr\u00e8s grands ensembles de donn\u00e9es. Il est \u00e9galement bon de l'utiliser si seule une section de l'ensemble de donn\u00e9es est n\u00e9cessaire pour lire les donn\u00e9es \u00e0 un rythme plus rapide.</p> <p>Lire:</p> <pre><code>%python\ndata = spark.read.parquet(\"/tmp/testParquet\")\ndisplay(data)\n</code></pre> <p>\u00c9crivez:</p> <pre><code>%python\n//Supposition qu'un cadre de donn\u00e9es a d\u00e9j\u00e0 \u00e9t\u00e9 cr\u00e9\u00e9\n\ndata.write.parquet(\"/tmp/tempFile\")\n</code></pre>"},{"location":"BonnesPratiques/#avro","title":"Avro","text":"<p>Tout comme Parquet, il est id\u00e9al pour les tr\u00e8s grands ensembles de donn\u00e9es. Pour comparer, il est pr\u00e9f\u00e9rable de l'utiliser pour \u00e9diter/\u00e9crire dans un ensemble de donn\u00e9es et pour interroger toutes les colonnes de l'ensemble de donn\u00e9es.</p> <p>Lire:</p> <pre><code>data = spark.read.format(\"avro\").load(\"/tmp/test_dataset\")\ndisplay(data)\n</code></pre> <p>\u00c9crivez:</p> <pre><code>%scala\nval ex = Seq((132, \"baseball\"),\n(148, \"softball\"),\n(172, \"slow pitch\")).toDF(\"players\", \"sport\")\nex.write.format(\"avro\").save(\"/tmp/testExample\")\n</code></pre>"},{"location":"BonnesPratiques/#csv","title":"CSV","text":"<p>Il convient de l'utiliser avec des ensembles de donn\u00e9es l\u00e9g\u00e8rement plus petits, car les fichiers CSV ne se chargent pas bien lorsque la taille du fichier est tr\u00e8s volumineuse. Mais avec des ensembles de donn\u00e9es plus petits, c'est simple et lisible par l'homme. Pour \u00e9crire dans un fichier CSV, il est \u00e9galement bon de noter que vous pouvez modifier le fichier avec Office.</p> <p>Lire:</p> <pre><code>%python\ndata = spark.read.format('csv').options(header='true', inferSchema='true').load('/tmp/test_dataCSV.csv')\ndisplay(data)\n</code></pre>"},{"location":"BonnesPratiques/#excel","title":"Excel","text":"<p>Veuillez voir ci-dessus comment utiliser Excel.</p> <p>Les autres formats ci-dessus sont pr\u00e9f\u00e9rables \u00e0 Excel.</p>"},{"location":"BonnesPratiques/#comment-convertir-des-fichiers-csv-text-json-en-parquet-a-laide-de-databricks","title":"Comment convertir des fichiers (CSV, Text, JSON) en parquet \u00e0 l'aide de databricks?","text":"<p>La r\u00e8gle de base lors de la conversion d'un fichier en parquet est de d'abord lire le fichier, puis d'\u00e9crire un nouveau fichier dans le parquet.</p> <p>CSV vers Parquet: </p> <pre><code>%python\n\ntestConvert = spark.read.format('csv').options(header='true', inferSchema='true').load('/mnt/public-data/incoming/titanic.csv')\ntestConvert.write.parquet(\"/mnt/public-data/incoming/testingFile\")\n</code></pre> <p>JSON vers Parquet:</p> <pre><code>%python\n\ntestConvert = spark.read.json('tmp/test.json')\ntestConvert.write.parquet('tmp/testingJson')\n</code></pre> <p>Text vers Parquet:</p> <pre><code>%python\n\ntestConvert = spark.read.text(\"/mnt/public-data/incoming/testing.txt\")\ntestConvert.write.parquet(\"/mnt/public-data/incoming/testingFile\")\n</code></pre>"},{"location":"BonnesPratiques/#puis-je-lire-un-document-word-dans-databricks","title":"Puis-je lire un document Word dans Databricks?","text":"<p>Il est pr\u00e9f\u00e9rable de lire les documents Word via Office \u00e0 la place.</p>"},{"location":"BonnesPratiques/#quand-devons-nous-utiliser-adf-ou-databricks-pour-lingestion-de-donnees","title":"Quand devons-nous utiliser ADF ou Databricks pour l'ingestion de donn\u00e9es?","text":"<p>Databricks est capable de diffuser en temps r\u00e9el via l'API Apache Spark qui peut g\u00e9rer les charges de travail d'analyse de streaming. Databricks n'a pas besoin que vous encapsulez le code python dans des fonctions ou des modules ex\u00e9cutables, tout le code peut fonctionner tel quel. Databricks prend \u00e9galement en charge le Machine Learning, ce qui facilite \u00e9galement l'ingestion de donn\u00e9es.</p> <p>Pour tout code qui se trouve d\u00e9j\u00e0 dans une fonction Azure ou qui est facilement traduit en un ex\u00e9cutable, l'utilisation de la fabrique de donn\u00e9es est utilisable. L'usine de donn\u00e9es est \u00e9galement bonne \u00e0 utiliser s'il s'agit d'un algorithme lourd qui n'est pas utilisable dans Databricks.</p>"},{"location":"BonnesPratiques/#quelle-est-la-difference-entre-les-tables-temporelles-de-la-base-de-donnees-sql-et-delta-lake","title":"Quelle est la diff\u00e9rence entre les tables temporelles de la base de donn\u00e9es SQL et Delta Lake?","text":"<p>Les tables temporelles SQL sont sp\u00e9cifiques \u00e0 SQL 2018 et ne sont actuellement pas disponibles dans Azure Synapse. D'autre part, Delta Lake est disponible \u00e0 la fois dans Azure Synapse et dans Databricks. Une autre diff\u00e9rence est que les tables temporelles SQL ne sont disponibles qu'avec des requ\u00eates SQL, tandis que le voyage dans le temps du lac Delta est disponible en Scala, Python et SQL.</p>"},{"location":"BonnesPratiques/#quand-utiliser-power-bi-ou-r-shiny","title":"Quand utiliser Power BI ou R-Shiny?","text":"<p>Il est recommand\u00e9 d'utiliser Power BI sur R-shiny car moins de codage est requis lors de l'utilisation de Power BI. L'utilisation de Power BI pr\u00e9sente de nombreux avantages, notamment la quantit\u00e9 suppl\u00e9mentaire de types de graphiques disponibles, la visualisation des donn\u00e9es dans des graphiques est plus facile \u00e0 utiliser dans Power BI par rapport \u00e0 R-Shiny, la cr\u00e9ation d'un tableau de bord est plus rapide dans PowerBI, et la facilit\u00e9 de connectivit\u00e9 avec d'autres applications au sein d'Azure.</p>"},{"location":"BonnesPratiques/#quel-est-le-bon-moment-pour-utiliser-azure-synapse-vs-adf-et-databricks","title":"Quel est le bon moment pour utiliser Azure Synapse vs ADF et Databricks?","text":"<p>Azure Synapse est utile pour effectuer des requ\u00eates et des analyses de donn\u00e9es via le lac de donn\u00e9es, effectuer des analyses SQL et un entreposage de donn\u00e9es, et utiliser des services suppl\u00e9mentaires comme Power BI. Il est facile d'interroger les donn\u00e9es du lac de donn\u00e9es \u00e0 l'aide d'Azure Snapse et vous n'avez pas besoin de monter le lac de donn\u00e9es sur l'espace de travail. En ce qui concerne les analyses de donn\u00e9es et l'entreposage de donn\u00e9es, synapse est pr\u00e9f\u00e9r\u00e9 car il permet des mod\u00e8les de donn\u00e9es r\u00e9els complets, fournit toutes les fonctionnalit\u00e9s SQL et utilise \u00e9galement Delta Lake. Synapse inclut \u00e9galement des services directs avec Power BI pour une facilit\u00e9 d'utilisation.</p> <p>D'autre part, Databricks est pr\u00e9f\u00e9r\u00e9 lors du d\u00e9veloppement de l'apprentissage automatique et des transformations en temps r\u00e9el. Databricks inclut son propre d\u00e9veloppement d'apprentissage automatique qui inclut des biblioth\u00e8ques populaires telles que PyTorch, g\u00e8re la version de MLflow. Databricks est \u00e9galement pr\u00e9f\u00e9r\u00e9 pour les transformations en temps r\u00e9el car il utilise le streaming structur\u00e9 Spark et il vous donne la possibilit\u00e9 de visualiser les modifications des autres utilisateurs en temps r\u00e9el.</p>"},{"location":"BonnesPratiques/#quand-devrions-nous-utiliser-un-entrepot-de-donnees-de-base-de-donnees-sql-par-rapport-a-delta-lake","title":"Quand devrions-nous utiliser un entrep\u00f4t de donn\u00e9es de base de donn\u00e9es SQL par rapport \u00e0 Delta Lake?","text":"<p>La meilleure pratique serait d'utiliser Delta Lake sur le serveur SQL car il n'utilise pas de ressources de calcul SQL suppl\u00e9mentaires et r\u00e9duira les co\u00fbts globaux du cloud.</p>"},{"location":"BonnesPratiques/#comment-puis-je-facilement-convertir-des-fichiers-sas-dans-un-autre-format","title":"Comment puis-je facilement convertir des fichiers SAS dans un autre format?","text":"<p>Les utilisateurs de Statcan peuvent utiliser SAS sur le r\u00e9seau interne stats-can pour le convertir en un format de fichier pris en charge. </p> <p>Vous pouvez convertir un fichier SAS en CSV ou JSON avec cette m\u00e9thode:</p> <ol> <li> <p>Ouvrez d'abord les databricks et installez le convertisseur sas7bdat dans votre ordinateur portable.</p> <p><code>python %pip install sas7bdat-converter</code></p> </li> <li> <p>\u00c0 l'aide de python et de l'\u00e9diteur de code de votre choix, saisissez ce code avec le r\u00e9pertoire du fichier dans lequel se trouve le fichier et le r\u00e9pertoire dans lequel vous souhaitez que le fichier de sortie se trouve.</p> <p>```python %python</p> <p>import sas7bdat_converter</p> <p>file_dicts = [{     'sas7bdat_file': '/dbfs/mnt/public-data/ToNetA/sas7bdat/tablea_1_10k.sas7bdat',     'export_file': '/dbfs/mnt/public-data/testFolder/testingConvert.csv', }]</p> <p>sas7bdat_converter.batch_to_csv(file_dicts) ```</p> </li> </ol> <p>Vous obtiendrez alors le fichier de sortie dans le r\u00e9pertoire que vous avez sp\u00e9cifi\u00e9.</p> <p>Pour plus d'informations sur le convertisseur, veuillez vous r\u00e9f\u00e9rer \u00e0 ce lien :</p> <p>Documentation du sas7bdat</p>"},{"location":"BonnesPratiques/#puis-je-convertir-un-document-word-en-bloc-notes","title":"Puis-je convertir un document Word en bloc-notes?","text":"<p>Il n'y a pas de moyen facile de convertir un document Word en bloc-notes.</p> <p>Une solution manuelle pour convertir un document Word en bloc-notes consiste \u00e0 copier le code contenu dans le document Word dans un bloc-notes.</p>"},{"location":"BonnesPratiques/#quelle-taille-de-table-dataframespark-peut-on-stocker-dans-lespace-de-travail","title":"Quelle taille de table dataframe/spark peut-on stocker dans l'espace de travail?","text":"<p>Les tables Spark sont stock\u00e9es en tant que fichiers parquet et sont stock\u00e9es dans le compte de stockage interne li\u00e9 \u00e0 l'espace de travail Databricks, mais il est recommand\u00e9 de supprimer la table si elle n'est plus utilis\u00e9e.</p>"},{"location":"BonnesPratiques/#quelle-est-la-meilleure-facon-dobtenir-des-fichiers-de-donnees-dans-azure-ml","title":"Quelle est la meilleure fa\u00e7on d'obtenir des fichiers de donn\u00e9es dans Azure ML?","text":"<p>Le meilleur moyen serait de t\u00e9l\u00e9charger vos fichiers sur le lac de donn\u00e9es. Si vous devez ajouter un nouveau compte de stockage cloud, contactez l'\u00e9quipe CAE pour ajouter le compte de stockage au studio Azure ML.</p>"},{"location":"BonnesPratiques/#quelle-est-la-difference-avec-le-machine-learning-dans-databricks-ou-dans-azure-ml","title":"Quelle est la diff\u00e9rence avec le Machine Learning dans Databricks ou dans Azure ML?","text":"<p>La principale diff\u00e9rence entre Azure ML et Databricks r\u00e9side dans le langage utilis\u00e9 par chaque application. Azure ML utilise des biblioth\u00e8ques bas\u00e9es sur python ou R tandis que Databricks utilise la plate-forme Apache Spark et MLFlow.</p> <p>Azure ML contient \u00e9galement un syst\u00e8me de suivi capable de suivre les ex\u00e9cutions individuelles de l'exp\u00e9rience et d'inclure les m\u00e9triques sp\u00e9cifiques de ce qui doit \u00eatre vu. Databricks inclut MLflow qui permet \u00e9galement le suivi mais n'offre pas autant de fonctionnalit\u00e9s qu'Azure ML.</p> <p>\u00c0 titre de recommandation, il est recommand\u00e9 d'utiliser Databricks pour la pr\u00e9paration des donn\u00e9es et pour les grands ensembles de donn\u00e9es, mais d'utiliser Azure ML pour leur syst\u00e8me de suivi, l'apprentissage automatique sur les ensembles de donn\u00e9es normaux, l'apprentissage profond sur les GPU et l'op\u00e9rationnalisation.</p>"},{"location":"BonnesPratiques/#comment-creer-une-table-dans-databricks","title":"Comment cr\u00e9er une table dans Databricks?","text":""},{"location":"BonnesPratiques/#option-1-utiliser-la-fonction-creer-une-table","title":"Option 1 : Utiliser la fonction Cr\u00e9er une table","text":"<p>Dans Databricks, s\u00e9lectionnez Donn\u00e9es et dans la base de donn\u00e9es que vous avez s\u00e9lectionn\u00e9e, cliquez sur Cr\u00e9er une table. </p> <p></p> <p>Pour plus d'informations sur cette option, veuillez consulter ce lien\u00a0:</p> <p>Databricks cr\u00e9er un tableau</p>"},{"location":"BonnesPratiques/#option-2-creer-une-table-a-partir-dune-table-dataframe","title":"Option\u00a02\u00a0:\u00a0Cr\u00e9er une table \u00e0 partir d'une table Dataframe","text":"<p>Python:</p> <pre><code>df.write.saveAsTable(\"Table-Name\")\n</code></pre> <p>SQL:</p> <pre><code>CREATE TABLE IF NOT EXISTS Table-Name AS SELECT * FROM df\n</code></pre>"},{"location":"BonnesPratiques/#option-3-create-table-programatically","title":"Option 3: Create Table Programatically","text":"<p>SQL:</p> <pre><code>CREATE TABLE example (id INT, name STRING, age INT) USING CSV;\n</code></pre>"},{"location":"BonnesPratiques/#quand-utiliser-spark-dataframe-ou-spark-table","title":"Quand utiliser Spark Dataframe ou Spark Table?","text":"<p>Il n'y a vraiment aucune diff\u00e9rence entre l'utilisation d'un Spark Dataframe ou Spark Table.</p> <p>Actuellement avec Databricks, la meilleure pratique en ce moment serait de stocker les tables en tant que tables delta car elles sont enregistr\u00e9es au format parquet et donnent les capacit\u00e9s de suivi.</p>"},{"location":"BonnesPratiques/#que-dois-je-faire-si-la-taille-de-la-table-diffusee-depasse-de-loin-les-estimations-et-depasse-la-limite-de-sparkdrivermaxresultsize-_____","title":"Que dois-je faire si la taille de la table diffus\u00e9e d\u00e9passe de loin les estimations et d\u00e9passe la limite de spark.driver.maxResultSize = _____?","text":"<p>Modifiez la configuration Spark \"spark.driver.maxResultSize\" en \"0\" (signifie pas de limite) ou quelque chose de plus grand que vos besoins.</p>"},{"location":"BonnesPratiques/#que-dois-je-faire-si-je-ne-peux-pas-diffuser-la-table-dont-la-taille-est-superieure-a-8gb","title":"Que dois-je faire si je ne peux pas diffuser la table dont la taille est sup\u00e9rieure \u00e0 8GB?","text":"<p>Cela se produit uniquement avec BroadcastHashJoin. Il y a 2 possibilit\u00e9s :</p> <ol> <li> <p>Remplacez la configuration Spark \"spark.sql.autoBroadcastJoinThreshold\" par \"-1\". Cela force Databricks \u00e0 effectuer un SortMergeJoin.</p> </li> <li> <p>\u00c9tapes pour \u00e9viter de modifier les configurations:</p> <p>a. Partitionner le DataFrame A en plusieurs parties.</p> <p>b. Effectuez des jointures avec chaque partition de DataFrame A avec DataFrame B (c'est simultan\u00e9ment le moyen le plus rapide mais peut n\u00e9cessiter l'\u00e9criture de Dataframes dans un fichier pour la lecture \u00e0 l'\u00e9tape suivante).</p> <p>c. Effectuez une union sur tous les DataFrames joints.</p> </li> </ol>"},{"location":"BonnesPratiques/#remarque-sur-la-modification-de-la-configuration-spark","title":"Remarque sur la modification de la configuration Spark","text":"<p>Avertissement\u00a0: La modification des configurations Spark peut entra\u00eener des erreurs de m\u00e9moire insuffisante</p> <p>Approche normale:</p> <pre><code>- spark.conf.set(\"configuration\", \"value\")\n</code></pre> <p>Si vous n'\u00eates pas autoris\u00e9 \u00e0 modifier certaines configurations, cela semble \u00eatre une solution:</p> <pre><code>- conf = spark.sparkContext._cibf,setAkk([(\"configuration\", \"value\"), (\"configuration\", \"value\")])\n</code></pre> <p>Comment obtenir la configuration Spark\u00a0:</p> <pre><code>- spark.conf.get(\"configuration\")\n</code></pre>"},{"location":"ContactezNous/","title":"Contactez-nous","text":""},{"location":"ContactezNous/#data-analyitics-services-das-portal","title":"Data Analyitics Services (DAS) Portal","text":"<p>Veuillez utiliser le bouton d'aide sur le portail de l'analyse de donn\u00e9es en tant que services (ADS)pour introduire une demande d'assistance.   </p>"},{"location":"ContactezNous/#commentaires","title":"Commentaires","text":"<p>Utilisez le formulaire Commentaires sur ce site Web :</p> <ul> <li>Feedback Form</li> </ul>"},{"location":"ContactezNous/#documentation","title":"Documentation","text":"<ul> <li>https://statcan.github.io/cae-eac/fr/</li> <li>Foire aux questions (FAQ)</li> <li>Bonnes pratiques</li> </ul>"},{"location":"ContactezNous/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Documentation Azure</li> </ul>"},{"location":"DataBricks/","title":"Azure Databricks","text":""},{"location":"DataBricks/#commencer","title":"Commencer","text":"<p>Une fois dans Databricks, vous pouvez cr\u00e9er un carnet ou ouvrir un carnet existant. Pour plus d'information, veuillez consulter le processus \u00e0 suivre pour acc\u00e9der \u00e0 Databricks pour la premi\u00e8re\u00a0fois.</p>"},{"location":"DataBricks/#creation-dun-cluster","title":"Cr\u00e9ation d'un cluster","text":"<p>Si aucun cluster n'a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous ou si vous avez besoin d'apporter des changements \u00e0 votre cluster, veuillez envoyer un message sur Slack, puisque vous n'avez pas la permission de cr\u00e9er un cluster.</p> <p>Note\u00a0: Vous devez avoir un cluster en mode actif avant de pouvoir ex\u00e9cuter le code dans votre carnet. Pour obtenir des renseignements sur la fa\u00e7on de d\u00e9marrer un cluster, consultez la section ci-dessous ou la FAQ.</p>"},{"location":"DataBricks/#creation-dun-carnet","title":"Cr\u00e9ation d'un carnet","text":"<ul> <li> <p>Une fa\u00e7on de cr\u00e9er un carnet consiste \u00e0 cliquer sur l'option\u00a0Nouveau carnet depuis la page principale de Databricks. Vous pouvez ensuite nommer votre carnet et choisir le langage par d\u00e9faut.</p> </li> <li> <p>Dans le champ \u00ab\u00a0Grappe\u00a0\u00bb, s\u00e9lectionnez parmis la liste propos\u00e9e le cluster auquel vous souhaitez attacher votre carnet.</p> <p></p> </li> <li> <p>Pour d\u00e9marrer un cluster ou le modifier \u00e0 partir d'un carnet, ouvrez le carnet et, dans le coin sup\u00e9rieur droit, cliquez sur le menu d\u00e9roulant pour cluster. Vous pourrez alors d\u00e9marrer le cluster ou le d\u00e9tacher et en attacher un autre.</p> </li> </ul>"},{"location":"DataBricks/#partage-de-carnets-dans-databricks","title":"Partage de carnets dans Databricks","text":"<p>Pour partager un carnet ou inviter d'autres collaborateurs, depuis le menu\u00a0Espace de travail, faites un clic droit sur le fichier ou le dossier du carnet souhait\u00e9 et s\u00e9lectionnez l'option\u00a0Autorisations. Vous pouvez \u00e9galement le faire \u00e0 partir d'un carnet, en cliquant sur le bouton\u00a0Autorisations. Une fois que le carnet aura \u00e9t\u00e9 partag\u00e9, plusieurs auteurs pourront le consulter et le modifier simultan\u00e9ment.</p> <p>Note\u00a0: Pour ajouter un utilisateur \u00e0 l'espace de travail\u00a0Databricks, veuillez envoyer un message\u00a0Slack.</p> <p></p>"},{"location":"DataBricks/#ingestion-de-donnees-dans-databricks","title":"Ingestion de donn\u00e9es dans Databricks","text":"<p>Les donn\u00e9es peuvent \u00eatre mont\u00e9es ou t\u00e9l\u00e9vers\u00e9es dans le Syst\u00e8me de fichiers\u00a0Databricks (DBFS), qui est un espace de stockage propre \u00e0 l'espace de travail\u00a0Databricks. Vous pouvez lire des donn\u00e9es d'une source de donn\u00e9es ou m\u00eame t\u00e9l\u00e9verser un fichier de donn\u00e9es (p.\u00a0ex. CSV) directement dans le DBFS.</p> <p>Note\u00a0: Le conteneur interne de lac de donn\u00e9es pour votre environnement a d\u00e9j\u00e0 \u00e9t\u00e9 mont\u00e9 pour vous, et vous pouvez travailler directement avec le conteneur. Si vous ne connaissez pas le nom de votre conteneur de lac de donn\u00e9es, veuillez envoyer un message Slack.</p>"},{"location":"DataBricks/#ajout-de-donnees-dans-databricks","title":"Ajout de donn\u00e9es dans Databricks","text":""},{"location":"DataBricks/#lecture-de-fichiers-montes","title":"Lecture de fichiers mont\u00e9s","text":"<p>Exemple\u00a0:</p> <pre><code>%python\ntestData = spark.read.format('csv').options(header='true', inferSchema='true').load('/mnt/mad-du/incoming/age-single-years-2018-census-csv.csv')\n\ndisplay(testData)\n</code></pre>"},{"location":"DataBricks/#modification-du-langage-par-defaut-dans-un-carnet","title":"Modification du langage par d\u00e9faut dans un carnet","text":""},{"location":"DataBricks/#utilisation-de-plusieurs-langages-dans-un-carnet","title":"Utilisation de plusieurs langages dans un carnet","text":"<p>Vous pouvez changer les param\u00e8tres de langage par d\u00e9faut en entrant la commande sp\u00e9ciale\u00a0% au d\u00e9but d'une cellule. Les commandes sp\u00e9ciales prises en charge sont les suivantes\u00a0: %python, %r, %scala et %sql.</p> <p>Note: Lorsque vous utilisez une commande\u00a0sp\u00e9ciale\u00a0Langage, celle-ci est distribu\u00e9e \u00e0 la valeur\u00a0REPL dans le contexte d'ex\u00e9cution du carnet. Les variables d\u00e9finies dans un langage (et par cons\u00e9quent dans la REPL pour ce langage) ne sont pas offertes dans la valeur\u00a0REPL d'un autre langage. Les valeurs REPL\u00a0permettent de partager l'\u00e9tat uniquement par l'interm\u00e9diaire de ressources externes, telles que des fichiers dans le DBFS ou des objets stock\u00e9s.</p> <p>Les carnets prennent \u00e9galement en charge quelques commandes\u00a0sp\u00e9ciales auxiliaires:</p> <ul> <li> <p>Vous permet d'ex\u00e9cuter du code\u00a0Shell dans votre carnet. Pour faire \u00e9chouer la cellule si la commande\u00a0Shell a un \u00e9tat de sortie diff\u00e9rent de z\u00e9ro, ajoutez l'-e\u00a0option. Cette commande s'ex\u00e9cute uniquement sur le pilote\u00a0Apache\u00a0Spark, et non sur les processus de travail. Pour ex\u00e9cuter une commande\u00a0Shell sur tous les n\u0153uds, utilisez un script d'initialisation (script\u00a0init).</p> </li> <li> <p>Vous permet d'utiliser des commandes de type syst\u00e8me de fichiers (dbutils).</p> </li> <li> <p>Vous permet d'inclure diff\u00e9rents types de documentation, notamment du texte, des images ainsi que des formules et des \u00e9quations math\u00e9matiques.</p> </li> </ul>"},{"location":"DataBricks/#demarrage-de-clusters-dans-databricks","title":"D\u00e9marrage de clusters dans Databricks","text":"<ol> <li> <p>Cliquez sur la liste d\u00e9roulante de clusters.</p> </li> <li> <p>S\u00e9lectionnez un cluster \u00e0 partir de cette liste.</p> </li> <li> <p>Cliquez sur le bouton\u00a0D\u00e9but pour d\u00e9marrer le cluster.</p> <p></p> </li> </ol>"},{"location":"DataBricks/#configuration-de-databricks-connect-sur-une-machine-virtuelle","title":"Configuration de Databricks Connect sur une machine virtuelle","text":"<p>Databricks connect permet l'acc\u00e8s \u00e0 un environnement Databricks sans avoir besoin de se connecter via le portail Azure ou l'IU Databricks. Il permet d'utiliser d'autres EDI pour travailler du code Databricks.</p> <p>Voici les \u00e9tapes pour installer et tester Databricks Connect sur votre machine virtuelle:</p> <ol> <li> <p>Il y a un conflit entre Databricks Connect et l'installation Pyspark qui se trouve sur les images Data Science Virtual Machine. Par d\u00e9faut, cette installation de Pyspark se trouve dans <code>C:\\dsvm\\tools\\spark-2.4.4-bin-hadoop2.7</code>. Veuillez supprimer ou d\u00e9placer ce dossier afin d'installer Databricks Connect.</p> </li> <li> <p>Avant d'installer Databricks Connect, cr\u00e9ez un environment conda. Pour ce faire, ouvrez une invite de commandes et execut\u00e9z les commandes suivantes:     <code>conda create --name dbconnect python=3.7     conda activate dbconnect     type pip install -U databricks-connect==X.Y.*</code> REMARQUE: Remplacez X et Y avec le num\u00e9ro de version de votre cluster Databricks. Vous pouvez trouvez cette valeur en ouvrant l'espace de travail Databricks du portail Azure. Cliquez sur Clusters dans le menu \u00e0 gauche, et notez la version Runtime pour votre cluster.</p> </li> <li> <p>Dans une invite de commandes, entrez databricks-connect configure, et entez les valeurs suivantes quand demand\u00e9es:</p> <ul> <li> <p>H\u00f4te Databricks: <code>https://canadacentral.azuredatabricks.net</code></p> </li> <li> <p>Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks</p> </li> <li> <p>ID du cluster : la valeur indiqu\u00e9e sous Instance de calcul --&gt; Options avanc\u00e9es--&gt; \u00c9tiquettes dans votre espace de travail Databricks</p> <p></p> </li> <li> <p>ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= </p> <p></p> </li> <li> <p>Port : conserver la valeur existante</p> </li> </ul> </li> <li> <p>Changez la valeur de la variable d'environnement <code>SPARK_HOME</code> \u00e0 <code>c:\\miniconda\\envs\\(conda env name))\\lib\\site-packages\\pyspark</code>, et red\u00e9marrez votre machine virtuelle. (Veuillez demander de l'aide via un message Slack si vous ne savez pas comment changer des variables d'environnement.)</p> </li> <li> <p>Testez la connectivit\u00e9 avec Azure Databricks en ex\u00e9cutant databricks-connect test dans une invite de commandes. Si votre cluster Databricks est arr\u00eat\u00e9 quand vous commencez ce test, vous recevrez des messages d'avertissement jusqu'\u00e0 ce qu'il ait d\u00e9marr\u00e9, ce qui peut prendre du temps.</p> </li> </ol>"},{"location":"DataBricks/#troubleshooting","title":"Troubleshooting :","text":"<p>1- Si vous utilisez databricks connect sur windows vous pouvez avoir cette erreur : Cannot find winutils.exe, Dans ce cas referez-vous a  https://docs.microsoft.com/en-us/azure/databricks/dev-toolsdatabricks-connect#cannot-find-winutilsexe-on-windows</p>"},{"location":"DataBricks/#installation-de-librairies","title":"Installation de librairies","text":""},{"location":"DataBricks/#cluster-databricks","title":"Cluster Databricks","text":"<p>Veuillez contacter le canal Slack pour que l'\u00e9quipe d'assistance puisse installer les librairies pour vous.</p>"},{"location":"DataBricks/#carnet","title":"Carnet","text":"<p>Veuillez utiliser les commandes suivantes pour installer une librairie dans une session de carnet.</p> <p>Python: </p> <pre><code>dbutils.library.installPyPI (\"pypipackage\", version = \"version\", repo = \"repo\", extras = \"extras\")\ndbutils.library.restartPython () # Supprime l'\u00e9tat Python, mais certaines biblioth\u00e8ques peuvent ne pas fonctionner sans appeler cette fonction\n</code></pre> <p>R Code:</p> <pre><code>install.packages(\"library\") </code></pre>"},{"location":"DataBricks/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Acc\u00e9der \u00e0 Databricks pour la premi\u00e8re\u00a0fois</li> <li>En savoir plus sur Databricks     (en anglais seulement)</li> <li>Databricks Connect (en anglais seulement)</li> <li>Installer des biblioth\u00e8ques dans la session active d'un carnet</li> <li>Gestion des biblioth\u00e8ques pour les administrateurs</li> </ul>"},{"location":"DataFactory/","title":"Azure Data Factory","text":""},{"location":"DataFactory/#acces-a-data-factory","title":"Acc\u00e8s \u00e0 Data\u00a0Factory","text":""},{"location":"DataFactory/#tableau-de-bord","title":"Tableau de bord","text":"<p>Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements.</p> <ol> <li> <p>Cliquez sur le menu Tableau de bord dans le portail\u00a0Azure.</p> <p></p> </li> </ol>"},{"location":"DataFactory/#adresse-url-dadf","title":"ADRESSE\u00a0URL D'ADF","text":"<ol> <li> <p>Rendez-vous \u00e0 https://adf.azure.com et s\u00e9lectionnez l'instance Data\u00a0Factory qui a \u00e9t\u00e9 cr\u00e9\u00e9e pour vous.</p> <p></p> </li> </ol>"},{"location":"DataFactory/#portail-azure","title":"Portail\u00a0Azure","text":"<ol> <li> <p>Dans la bo\u00eete de recherche du portail\u00a0Azure, recherchez Data\u00a0factories.</p> <p></p> </li> <li> <p>Vous devriez alors voir la liste des Data\u00a0Factories auxquelles vous avez obtenu la permission d'acc\u00e9der.</p> <p></p> </li> </ol>"},{"location":"DataFactory/#auteur","title":"Auteur","text":"<p>Cliquez sur Author &amp; Monitor.</p> <p></p> <p>Dans Data\u00a0Factory, vous avez la capacit\u00e9 de cr\u00e9er et de d\u00e9ployer des ressources.</p> <p></p> <p>Voir le document Cr\u00e9ation visuelle dans Azure\u00a0Data\u00a0Factory pour obtenir de plus amples renseignements.</p> <p>Vous pouvez \u00e9galement utiliser certains des divers assistants fournis sur la page d'aper\u00e7u (Overview) de Data\u00a0Factory.</p> <p>NOTE\u00a0: La configuration de SSIS\u00a0Integration n'est PAS recommand\u00e9e. Si vous avez des questions, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack.</p> <p></p> <p>Voir les tutoriels de la documentation\u00a0Azure pour obtenir plus de d\u00e9tails.</p>"},{"location":"DataFactory/#acces-a-data-lake-a-partir-dadf","title":"Acc\u00e8s \u00e0 Data\u00a0Lake \u00e0 partir d'ADF","text":"<p>Une connexion au compte de stockage Data\u00a0Lake a \u00e9t\u00e9 pr\u00e9configur\u00e9e pour votre environnement.</p> <ol> <li> <p>Cliquez sur l'ic\u00f4ne de la mallette.</p> </li> <li> <p>Cliquez sur Services li\u00e9s.</p> </li> <li> <p>Le service li\u00e9 au type Stockage\u00a0Azure\u00a0Data\u00a0Lake\u00a0Gen2 est votre compte de stockage Data\u00a0Lake.</p> <p></p> </li> </ol> <p>Note\u00a0: On vous a accord\u00e9 l'acc\u00e8s \u00e0 des contenants particuliers cr\u00e9\u00e9s dans le compte de stockage Data\u00a0Lake pour votre environnement.</p>"},{"location":"DataFactory/#acces-a-la-base-de-donnees-sql-azure","title":"Acc\u00e8s \u00e0 la Base de donn\u00e9es SQL\u00a0Azure","text":"<p>Certains projets ont une instance de Base de donn\u00e9es SQL\u00a0Azure.</p> <ol> <li> <p>Cliquez sur l'ic\u00f4ne de la mallette.</p> </li> <li> <p>Cliquez sur Services li\u00e9s.</p> </li> <li> <p>Les services li\u00e9s au type Base de donn\u00e9es SQL\u00a0Azure sont vos bases de donn\u00e9es.</p> <p></p> </li> </ol>"},{"location":"DataFactory/#enregistrement-ou-publication-de-vos-ressources-dans-data-factory","title":"Enregistrement ou publication de vos ressources dans Data\u00a0Factory","text":"<p>Azure\u00a0Data\u00a0Factory peut \u00eatre configur\u00e9 pour enregistrer votre travail dans les emplacements suivants:</p> <ol> <li>D\u00e9p\u00f4t\u00a0Git\u00a0</li> <li>Publier directement dans Data\u00a0Factory</li> </ol>"},{"location":"DataFactory/#git-lorsquaccessible","title":"Git (lorsqu'accessible)","text":"<p>Lorsque Git est activ\u00e9, vous pouvez voir votre configuration et enregistrer votre travail dans une branche particuli\u00e8re.</p> <ol> <li> <p>Cliquez sur l'ic\u00f4ne de la mallette.</p> </li> <li> <p>Cliquez sur Configuration de Git.</p> </li> <li> <p>V\u00e9rifiez la configuration de Git qui a \u00e9t\u00e9 mise en place pour vous.</p> <p></p> </li> <li> <p>Lorsque vous cr\u00e9ez un flux de travail, vous pouvez l'enregistrer dans votre branche. Cliquez sur +\u00a0Nouvelle branche dans le menu d\u00e9roulant des branches pour cr\u00e9er une     branche de fonctionnalit\u00e9s.</p> <p></p> </li> <li> <p>Lorsque vous serez pr\u00eat \u00e0 fusionner les changements de votre branche de fonctionnalit\u00e9s dans votre branche de collaboration (master), cliquez sur le menu d\u00e9roulant des branches et s\u00e9lectionnez Cr\u00e9er la demande de tirage (pull request). Cette action vous dirigera vers Azure\u00a0DevOps\u00a0Git, o\u00f9 vous pourrez cr\u00e9er des demandes de tirage, proc\u00e9der \u00e0 des revues du code et fusionner les modifications dans votre branche de collaboration (master) d\u00e8s que la demande aura \u00e9t\u00e9 approuv\u00e9e.</p> </li> <li> <p>Apr\u00e8s avoir fusionn\u00e9 les modifications dans la branche de collaboration (master), cliquez sur Publier pour publier les changements de votre code de la branche dans Azure\u00a0Data\u00a0Factory. Si vous obtenez un message d'erreur au moment de la publication, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack.</p> </li> </ol>"},{"location":"DataFactory/#service-data-factory","title":"Service Data\u00a0Factory","text":"<p>Lorsque Data\u00a0Factory n'est pas int\u00e9gr\u00e9 au contr\u00f4le source, vos flux de travail sont stock\u00e9s directement dans le service Data\u00a0Factory. Vous ne pouvez pas enregistrer les changements partiels, vous pouvez seulement utiliser l'option Tout publier, ce qui \u00e9crase l'\u00e9tat actuel de Data\u00a0Factory avec vos changements qui deviennent alors visibles \u00e0 tous.</p> <p></p>"},{"location":"DataFactory/#ingestion-et-transformation-des-donnees-avec-adf","title":"Ingestion et transformation des donn\u00e9es avec ADF","text":"<ul> <li> <p>Assistant de copie de donn\u00e9es</p> </li> <li> <p>Mappage de flux de donn\u00e9es\u00a0-- Processus ETC ax\u00e9 sur l'interface utilisateur graphique</p> </li> </ul>"},{"location":"DataFactory/#runtimes-dintegration","title":"Runtimes d'int\u00e9gration","text":""},{"location":"DataFactory/#autoresolveintegrationruntime","title":"AutoResolveIntegrationRuntime","text":"<p>Ne pas utiliser. Veuillez utiliser les runtimes d'int\u00e9gration canadaCentralIR-4nodesDataFlow ou selfHostedCovidIaaSVnet au lieu.</p> <p>Le runtime d'int\u00e9gration de r\u00e9solution automatique (\"auto resolve\") est cr\u00e9\u00e9 par d\u00e9faut avec le Data Factory, et va s\u00e9lectionner le centre de donn\u00e9es Azure le plus pr\u00e8s des donn\u00e9es, ce qui pourrait contrevenir aux politiques de r\u00e9sidence des donn\u00e9es.</p>"},{"location":"DataFactory/#canadacentralir-4nodesdataflow","title":"canadaCentralIR-4nodesDataFlow","text":"<p>Ceci est partag\u00e9 par tous les utilisateurs et fonctionne tout le temps.</p>"},{"location":"DataFactory/#peut-acceder","title":"Peut acc\u00e9der:","text":"<ul> <li>Lac de donn\u00e9es interne</li> <li>Compte de stockage externe</li> <li>Sources de donn\u00e9es externes (Internet)</li> </ul>"},{"location":"DataFactory/#ne-peut-pas-acceder","title":"Ne peut pas acc\u00e9der:","text":"<ul> <li>Base de donn\u00e9es Azure SQL</li> </ul>"},{"location":"DataFactory/#selfhostedcovidiaasvnet","title":"selfHostedCovidIaaSVnet","text":"<p>Situ\u00e9 \u00e0 l'int\u00e9rieur du r\u00e9seau virtuel interne.</p>"},{"location":"DataFactory/#peut-acceder_1","title":"Peut acc\u00e9der:","text":"<ul> <li>Lac de donn\u00e9es interne</li> <li>Base de donn\u00e9es Azure SQL</li> </ul>"},{"location":"DataFactory/#ne-peut-pas-acceder_1","title":"Ne peut pas acc\u00e9der:","text":"<ul> <li>Compte de stockage externe</li> <li>Sources de donn\u00e9es externes (Internet)</li> </ul>"},{"location":"DataFactory/#exemple-comment-se-connecter-aux-donnees-de-john-hopkins","title":"Exemple\u00a0: Comment se connecter aux donn\u00e9es de John\u00a0Hopkins","text":"<ol> <li> <p>Il y a un exemple de flux de travail qui montre la fa\u00e7on d'ing\u00e9rer des donn\u00e9es \u00e0 partir de GitHub \u00e0 l'aide d'un pipeline de Data\u00a0Factory.</p> <p></p> </li> <li> <p>Les donn\u00e9es peuvent \u00eatre filtr\u00e9es depuis Data\u00a0Factory.</p> <p></p> </li> <li> <p>Il est aussi possible d'extraire des donn\u00e9es de GitHub au moyen d'un code dans un notebook de Databricks.</p> <p></p> </li> </ol>"},{"location":"DataFactory/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Pr\u00e9sentation d'Azure\u00a0Data\u00a0Factory\u00a0--  Azure\u00a0Data\u00a0Factory</li> <li>Cr\u00e9er une fabrique de donn\u00e9es\u00a0Azure \u00e0 l'aide de l'interface utilisateur d'Azure\u00a0Data\u00a0Factory\u00a0--  Azure\u00a0Data\u00a0Factory</li> <li>Copier des donn\u00e9es avec l'outil d'Azure Copier des donn\u00e9es\u00a0--  Azure\u00a0Data\u00a0Factory</li> <li>Cr\u00e9er un flux de donn\u00e9es de mappage\u00a0--  Azure\u00a0Data\u00a0Factory</li> <li>Fonctions d'expression dans le flux de donn\u00e9es de mappage\u00a0--Azure\u00a0Data\u00a0Factory</li> <li>Mode de d\u00e9bogage du mappage de flux de donn\u00e9es\u00a0-- Azure\u00a0Data\u00a0Factory</li> <li>Supervision visuelle du flux de donn\u00e9es de mappage\u00a0-- Azure\u00a0Data\u00a0Factory</li> </ul>"},{"location":"DataFactory/#video-youtube-en-anglais-seulement","title":"Vid\u00e9o\u00a0YouTube (en anglais seulement)","text":"<ul> <li>Ingest, prepare &amp; transform using Azure\u00a0Databricks &amp; Data\u00a0Factory Azure\u00a0Friday</li> <li>Azure\u00a0Friday Visually build pipelines for Azure\u00a0Data\u00a0Factory\u00a0V2</li> <li>How to prepare data using wrangling data flows in Azure\u00a0Data\u00a0Factory Azure\u00a0Friday</li> <li>How to develop and debug with Azure\u00a0Data\u00a0Factory Azure\u00a0Friday</li> <li>Building Data Flows in  Azure\u00a0Data\u00a0Factory</li> </ul>"},{"location":"DeltaLake/","title":"Delta Lake","text":"<p>Delta Lake est une couche de stockage \u00e0 code source ouvert qui s\u2019ex\u00e9cute au-dessus d\u2019un lac de donn\u00e9es existant, ajoutant les capacit\u00e9s des propri\u00e9t\u00e9s et des transactions ACID (atomicit\u00e9, coh\u00e9rence, isolation, durabilit\u00e9). Delta Lake est enti\u00e8rement compatible avec Apache Spark dans Azure Databricks et Azure Synapse.</p> <p>Azure Data Lake n\u2019est pas conforme \u00e0 la norme ACID. Il convient donc d\u2019utiliser Delta Lake lorsque l\u2019int\u00e9grit\u00e9 et la fiabilit\u00e9 des donn\u00e9es sont essentielles, ou lorsqu\u2019il existe un risque de mauvaises donn\u00e9es.</p>"},{"location":"DeltaLake/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Pr\u00e9sentation de Delta Lake</li> <li>Delta Lake sur Azure</li> </ul>"},{"location":"DeltaLake/#documents-officielle","title":"Documents Officielle","text":"<ul> <li>Documentation Delta Lake</li> </ul>"},{"location":"DeltaLake/#comment-fonctionne-le-delta-lake","title":"Comment fonctionne le Delta Lake","text":"<p>Un lac delta est essentiellement un dossier \u00e0 l'int\u00e9rieur du lac de donn\u00e9es contenant des fichiers journaux (dans le sous-dossier _delta_log) et des fichiers de donn\u00e9es (stock\u00e9s au format parquet dans le dossier racine) pour chaque version d'un tableau. Tant que les fichiers journaux et de donn\u00e9es existent, vous pouvez utiliser la fonction de voyage dans le temps pour interroger les versions pr\u00e9c\u00e9dentes d'une table delta et afficher l'historique de cette table.</p> <p>Si les fichiers journaux sont supprim\u00e9s, vous ne pourrez pas du tout lire le tableau. Pour r\u00e9soudre ce probl\u00e8me, vous devrez vider le dossier du Delta Lake (supprimer tout ce qu'il contient), puis y \u00e9crire votre fichier de donn\u00e9es d'origine pour recommencer.</p> <p>Delta fonctionne au niveau des tables, ce qui signifie que les requ\u00eates et les jointures sur plusieurs tables ne sont pas prises en charge.</p>"},{"location":"DeltaLake/#quand-utiliser-delta-lake","title":"Quand utiliser Delta Lake","text":"<p>Delta Lake est pr\u00e9f\u00e9rable:</p> <ul> <li>Pour toute table permanente dans Databricks;</li> <li>Pour les grandes quantit\u00e9s de donn\u00e9es semi-structur\u00e9es (10 millions d\u2019enregistrements ou plus pour obtenir les meilleurs avantages sur le plan de la performance);</li> <li>Lorsque vous souhaitez un contr\u00f4le de version ou un suivi de l\u2019acc\u00e8s aux donn\u00e9es (les fichiers journaux delta permettent de savoir chaque fois que les donn\u00e9es sont modifi\u00e9es et par qui).</li> </ul>"},{"location":"DeltaLake/#deplacement-dans-le-temps","title":"D\u00e9placement dans le temps","text":"<p>Vous pouvez utiliser le d\u00e9placement dans le temps pour interroger un ancien instantan\u00e9 d\u2019une table, soit par num\u00e9ro de version, soit par horodatage. Par d\u00e9faut, les fichiers de donn\u00e9es sont conserv\u00e9s pendant 30 jours.</p> <p>Exemple:</p> <p>SQL</p> <pre><code>SELECT * FROM example_table TIMESTAMP AS OF '2018-10-18T22:15:12.013Z'\nSELECT * FROM delta.`/delta/example_table` VERSION AS OF 12\n</code></pre> <p>Python</p> <pre><code>df1 = spark.read.format(\"delta\").option(\"timestampAsOf\", 2020-03-13).load(\"/delta/example_table\")\ndf2 = spark.read.format(\"delta\").option(\"timestampAsOf\", 2019-01-01T00:00:00.000Z).load(\"/delta/example_table\")\ndf3 = spark.read.format(\"delta\").option(\"versionAsOf\", version).load(\"/delta/example_table\")\n</code></pre>"},{"location":"DeltaLake/#suppression-des-anciens-fichiers-de-donnees","title":"Suppression des anciens fichiers de donn\u00e9es","text":"<p>Pour supprimer les anciens fichiers de donn\u00e9es (pas les fichiers journaux) qui ne sont plus r\u00e9f\u00e9renc\u00e9s par une table delta, vous pouvez ex\u00e9cuter la commande vacuum.</p> <p>Exemple:</p> <p>SQL</p> <pre><code>VACUUM example_table   -- fichiers vacuum non requis par les versions ant\u00e9rieures \u00e0 la p\u00e9riode de r\u00e9tention par d\u00e9faut\n\nVACUUM '/data/example_table' -- fichiers vides dans une table bas\u00e9e sur les chemins\n\nVACUUM delta.`/data/example_table/`\n\nVACUUM delta.`/data/example_table/` RETAIN 100 HOURS  -- fichiers vides non requis par les versions de plus de 100 heures\n\nVACUUM example_table DRY RUN    -- faire un essai \u00e0 sec pour obtenir la liste des fichiers \u00e0 supprimer\n</code></pre> <p>Python</p> <pre><code>from delta.tables import *\n\ndeltaTable = DeltaTable.forPath(spark, pathToTable)\n\ndeltaTable.vacuum()        # fichiers vacuum non requis par les versions ant\u00e9rieures \u00e0 la p\u00e9riode de r\u00e9tention par d\u00e9faut\n\ndeltaTable.vacuum(100)     # fichiers vides non requis par les versions de plus de 100 heures\n</code></pre> <p>Scala</p> <pre><code>import io.delta.tables._\n\nval deltaTable = DeltaTable.forPath(spark, pathToTable)\n\ndeltaTable.vacuum()        // fichiers vacuum non requis par les versions ant\u00e9rieures \u00e0 la p\u00e9riode de r\u00e9tention par d\u00e9faut\n\ndeltaTable.vacuum(100)     // fichiers vides non requis par les versions de plus de 100 heures\n</code></pre>"},{"location":"DeltaLake/#revenir-a-une-version-anterieure","title":"Revenir \u00e0 Une Version Ant\u00e9rieure","text":"<p>Vous pouvez revenir \u00e0 une version pr\u00e9c\u00e9dente de votre table et y travailler en utilisant la fonction de voyage dans le temps pour lire votre version cible en tant que trame de donn\u00e9es, puis la r\u00e9\u00e9crire dans le dossier delta lake.</p> <p>Cela cr\u00e9era une nouvelle version identique \u00e0 la version cible, \u00e0 partir de laquelle vous pourrez ensuite travailler. Les autres versions pr\u00e9c\u00e9dentes restent intactes.</p> <p>Exemple:</p> <p>Python</p> <pre><code># lire dans l'ancienne version du tableau\ndf = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\n\n# r\u00e9\u00e9crire dans la nouvelle version de la table, doit d\u00e9finir le mode sur \"overwrite\"\ndf.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\n</code></pre>"},{"location":"DeltaLake/#documents-officiels","title":"Documents officiels","text":"<ul> <li>Interroger un ancien instantan\u00e9 d'une table (voyage dans le temps)</li> <li>Supprimer les fichiers qui ne sont plus r\u00e9f\u00e9renc\u00e9s par une table delta</li> </ul>"},{"location":"DeltaLake/#utilisation-de-delta-lake-dans-databricks","title":"Utilisation de Delta Lake dans Databricks","text":"<p>Databricks prend en charge en natif Delta Lake et peut ex\u00e9cuter des requ\u00eates \u00e0 l'aide de Python, R, Scala et SQL.</p> <ol> <li> <p>Vous devez d'abord cr\u00e9er un r\u00e9pertoire pour stocker les fichiers delta et noter le chemin d'acc\u00e8s \u00e0 ce r\u00e9pertoire.</p> </li> <li> <p>Lisez votre fichier de donn\u00e9es, puis \u00e9crivez-le au format \"delta\" et enregistrez-le dans le r\u00e9pertoire cr\u00e9\u00e9 ci-dessus.     ```     # lire le fichier de donn\u00e9es     testData = spark.read.format('json').options(header='true', inferSchema='true', multiline='true').load('/mnt/public-data/incoming/covid_tracking.json')</p> </li> <li> <p>Facultatif (pas une bonne pratique)\u00a0: cr\u00e9ez une table SQL \u00e0 l'aide de delta:     <code>spark.sql(\"CREATE TABLE sample_table USING DELTA LOCATION '/mnt/public-data/delta/'\")</code></p> </li> <li> <p>Vous pouvez maintenant ex\u00e9cuter des requ\u00eates SQL sur votre table delta, y compris des requ\u00eates par num\u00e9ro de version ou horodatage pour \"voyager dans le temps\" vers les versions pr\u00e9c\u00e9dentes de vos donn\u00e9es. Si vous avez cr\u00e9\u00e9 une table \u00e0 l'\u00e9tape 3, vous pouvez ex\u00e9cuter des requ\u00eates en utilisant le nom de la table. Sinon (meilleure pratique), \u00e0 la place du nom de la table, vous pouvez utiliser delta.`{delta_table_path}` (remplacez {delta_table_path} par le chemin r\u00e9el).     ```     %sql     SELECT * FROM sample_table VERSION AS OF 0</p> <p>SELECT * FROM delta.<code>/mnt/public-data/delta/</code> ```</p> </li> </ol>"},{"location":"DeltaLake/#ecrire-au-format-delta","title":"\u00e9crire au format delta","text":"<p>testData.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/public-data/delta\") ```</p>"},{"location":"DeltaLake/#documentation-microsoft_1","title":"Documentation Microsoft","text":"<ul> <li>D\u00e9marrage rapide du Delta Lake</li> </ul>"},{"location":"DeltaLake/#utilisation-de-delta-dans-azure-synapse","title":"Utilisation de Delta dans Azure Synapse","text":"<p>Delta Lake est compatible avec Azure Synapse. Les tables delta peuvent \u00eatre cr\u00e9\u00e9es et interrog\u00e9es dans les blocs-notes Synapse de la m\u00eame mani\u00e8re que Databricks, avec la prise en charge du langage pour PySpark, Scala et .NET (C#). Notez que SQL n'est pas pris en charge avec la version actuelle.</p> <ol> <li> <p>Lisez votre fichier de donn\u00e9es.     <code>data = spark.read.format('csv').options(header='true', inferSchema='true', multiline='true').load('abfss://public-data@statsconviddsinternal.dfs.core.windows.net/incoming/data_duplicate.csv')</code></p> </li> <li> <p>\u00c9crivez au format delta et enregistrez dans votre r\u00e9pertoire de table delta.     <code>data.write.format(\"delta\").save(delta_table_path)</code></p> </li> <li> <p>Facultatif\u00a0: cr\u00e9ez une table SQL \u00e0 l'aide de delta (requis uniquement si vous souhaitez ex\u00e9cuter des requ\u00eates SQL, pas n\u00e9cessaire si vous utilisez uniquement Python, Scala ou C#).     <code>spark.sql(\"CREATE TABLE example USING DELTA LOCATION '{0}'\".format(delta_table_path))</code></p> </li> <li> <p>Vous pouvez maintenant ex\u00e9cuter des requ\u00eates sur vos donn\u00e9es.</p> </li> </ol>"},{"location":"DeltaLake/#documentation-microsoft_2","title":"Documentation Microsoft","text":"<ul> <li>Travailler avec Delta Lake</li> </ul>"},{"location":"DeltaLake/#utilisation-de-delta-lake-dans-data-factory","title":"Utilisation de Delta Lake dans Data Factory","text":"<p>Vous pouvez utiliser Azure Data Factory pour copier des donn\u00e9es vers et depuis un Delta Lake stock\u00e9 dans Azure Data Lake.</p>"},{"location":"DeltaLake/#exemple-copier-des-donnees-dans-delta-lake","title":"Exemple\u00a0: copier des donn\u00e9es dans Delta Lake","text":"<ol> <li>Cr\u00e9ez un nouveau flux de donn\u00e9es et ajoutez une source.</li> <li>Sous l'onglet Param\u00e8tres source, ajoutez l'ensemble de donn\u00e9es \u00e0 partir duquel vous souhaitez copier. Configurez tous les autres param\u00e8tres pertinents.</li> <li>Cliquez sur le bouton plus \u00e0 droite de votre source et ajoutez un r\u00e9cepteur.</li> <li>Sous l'onglet R\u00e9cepteur, choisissez En ligne comme type de r\u00e9cepteur et Delta comme type de jeu de donn\u00e9es en ligne.</li> <li>Sous l'onglet Param\u00e8tres, d\u00e9finissez le chemin du dossier (le chemin vers lequel vos fichiers delta seront stock\u00e9s).</li> </ol>"},{"location":"DeltaLake/#documentation-microsoft_3","title":"Documentation Microsoft","text":"<ul> <li>Format Delta dans Azure Data Factory</li> </ul>"},{"location":"DeltaLake/#utilisation-de-delta-avec-power-bi","title":"Utilisation de Delta avec Power BI","text":"<p>Pour lire les tables delta de mani\u00e8re native dans Power BI, veuillez consulter cette documentation sur GitHub.</p>"},{"location":"DeltaLake/#delta-dans-azure-machine-learning","title":"Delta dans Azure Machine Learning","text":"<p>Le Delta Lake n'est actuellement pas pris en charge dans Azure ML.</p>"},{"location":"ExtMachinesVirtuelles/","title":"Machines Virtuelles","text":""},{"location":"ExtMachinesVirtuelles/#machine-virtuelle","title":"Machine Virtuelle","text":"<p>Avant d'acc\u00e9der \u00e0 votre machine virtuelle, vous devez vous connecter au portail du service d'analyse des donn\u00e9es </p> <ol> <li> <p>Vous pourrez voir les machines auxquelles vous avex acc\u00e8s en bas du guichet des SAD. A partir du portail, vous serez en mesure d'effectuer les trois actions suivantes:</p> </li> <li> <p>D\u00e9marrer la machine virtuelle</p> </li> <li>Arr\u00eater la machine virtuelle</li> <li>Vous connecter \u00e0 la machine virtuelle</li> </ol> <p>Chaque action effectu\u00e9e modifiera l'\u00e9tat de la machine virtuelle.      </p> <ol> <li> <p>D\u00e9marrer la machine virtuelle: Quand la machine virtuelle est \u00e0 l'arr\u00eat, le bouton d\u00e9marrer est selectionnable. Vous pouvez alors la d\u00e9marrer et son statut passera \u00e0 D\u00e9marrage en cours. le bouton d\u00e9marrer n'est alors plus s\u00e9lectionnable. Cela peut prendre quelques minutes \u00e0 la machine pour \u00eatre en mode Ex\u00e9cution en cours.  Le bouton de connexion au navigateur est alors s\u00e9lectionnable.      </p> </li> <li> <p>Se connecter \u00e0 la machine virtuelle: Une fois la machine d\u00e9marr\u00e9e, le bouton de connexion au navigateur est s\u00e9lectionnable. Il faut cliquer sur ce bouton pour pouvoir se connecter;       </p> </li> <li> <p>Une nouvelle page s'affichera, et il vous sera demand\u00e9 d'entrer vos nom d'utilisateur et mot de passe fournis par Statistique Canada. Cliquez apr\u00e8s cela sur le bouton Login.</p> <p></p> </li> </ol>"},{"location":"ExtMachinesVirtuelles/#bonnes-pratiques","title":"Bonnes pratiques","text":"<ol> <li>Les machines virtuelles entra\u00eenent des co\u00fbts uniquement quand elles sont en marche.\\    Pour \u00e9viter les d\u00e9penses inutiles, vous devez arr\u00eater votre machine virtuelle lorsque vous ne l'utilisez pas.</li> <li>Tout les soirs, les machines sont mises \u00e0 l'arr\u00eat \u00e0 19H heure de l'EST.</li> <li>Il est d\u00e9conseill\u00e9 de de communiquer son mot de passe \u00e0 qui que ce soit.</li> </ol>"},{"location":"ExtMachinesVirtuelles/#questions-frequemment-posees-faq","title":"Questions fr\u00e9quemment pos\u00e9es (FAQ)","text":"<ol> <li>Je ne vois aucune machine virtuelle?\\     Veuillez utiliser le bouton d'aide \u00e0 partir du portail des SAD pour nous contacter afin d'obtenir une machine virtuelle.</li> <li>J'ai oubli\u00e9 mon mot de passe du compte ext.statcan.ca?\\     Veuillez utiliser le bouton d'aide \u00e0 partir du portail des SAD pour nous contacter et soumettre une demande d'assistance.</li> <li>J'ai oubli\u00e9 mon nom d'utilisateur et mon mot de passe pour acc\u00e9der \u00e0 ma machine virtuelle?\\     Veuillez utiliser le bouton d'aide \u00e0 partir du portail des SAD pour nous contacter et soumettre une demande d'assistance.</li> </ol>"},{"location":"ExtPortail/","title":"Portail d'Analyse de donn\u00e9es","text":""},{"location":"ExtPortail/#portail-des-services-danalyse-de-donneessad","title":"Portail des Services d'analyse de donn\u00e9es(SAD)","text":""},{"location":"ExtPortail/#se-connecter","title":"Se connecter","text":"<ol> <li> <p>en tant qu'utilisateur externe, vous aurez besoin d'un compte utilisateur externe: firstname.lastname@ext.statcan.ca pour pouvoir acc\u00e9der \u00e0 votre machine virtuelle ainsi qu'aux ressources n\u00e9cessaires. Veuillez nous contacter pour demander un compte utilisateur.</p> </li> <li> <p>A partir de votre navigateur, acc\u00e9dez au lien suivant</p> <ul> <li>https://www.statcan.gc.ca/data-analytics-services</li> </ul> </li> <li> <p>Cliquez sur le bouton de connexion.   </p> <p></p> </li> </ol> <p>Note: En vous connectant la premi\u00e8re fois, il vous sera demand\u00e9 de modifier votre mot de passe.</p> <ol> <li> <p>Une fois connect\u00e9, vous serez dans la page du guichet des services d'analyse de donn\u00e9es (SAD). Vous pouvez acc\u00e9der \u00e0 cette page en cliquant sur la fl\u00eache situ\u00e9e \u00e0 c\u00f4t\u00e9 du nom d'utilisateur et en s\u00e9lectionnant Guichet des SAD.   </p> <p></p> </li> </ol>"},{"location":"ExtPortail/#acceder-aux-machines-virtuelles","title":"Acc\u00e9der aux Machines Virtuelles","text":"<p>Utilisez la page Machines Virtuelles pour avoir les instructions n\u00e9cessaires pour se connecter \u00e0 votre machine virtuelle.</p>"},{"location":"ExtPortail/#accedez-aux-services","title":"Acc\u00e9dez aux services","text":"<p>Pour acc\u00e9der aux services, vous devez vous assurer que vous \u00eates:</p> <ol> <li>Connect\u00e9 au portail du Service d'analyse des donn\u00e9es (SAD).</li> <li>Connect\u00e9 \u00e0 votre machine virtuelle Virtual Machines</li> </ol> <p>Note: Tout les services list\u00e9 ci-apr\u00e8s ne seront accessibles que de votre machine virtuelle.</p>"},{"location":"ExtPortail/#azure-synapse","title":"Azure Synapse","text":"<ol> <li>A partir de votre machine virtuelle, vous pouvez vous connecter au portail du service d'analyse des donn\u00e9es (SAD) pour acc\u00e9der au lien pour Azure Synapse.</li> </ol> <ol> <li>A partir de votre machine virtuelle, vous pouvez acc\u00e9der au lien suivant: https://web.azuresynapse.net/, vous connecter avec votre compte utilisateur et selectionner l'espace de travail Synapse qui vous est accessible.  </li> </ol>"},{"location":"ExtPortail/#stockage-azure-blob","title":"Stockage Azure Blob","text":"<p>Veuillez consulter la page Storage pour plus d'informations sur comment acc\u00e9der aux stockage.</p>"},{"location":"ExtPortail/#azure-data-lakes","title":"Azure Data Lakes","text":"<p>Veuillez consulter la page Storage pour plus d'informations sur comment acc\u00e9der aux stockage.</p>"},{"location":"ExtPortail/#azure-sql-database","title":"Azure SQL Database","text":"<p>Veuillez consulter la page SQL Server pour plus d'information sur comment acc\u00e9der au Server SQL.</p>"},{"location":"ExtPortail/#azure-data-factory","title":"Azure Data Factory","text":"<p>Les services de Data Factory sont disponible \u00e0 partir de Azure Synapse pour les utilisateurs externes.</p>"},{"location":"ExtPortail/#azure-databricks","title":"Azure Databricks","text":"<ol> <li>A partir de votre machine virtuelle, vous pouvez vous connecter au portail du service d'analyse des donn\u00e9es (SAD) pour acc\u00e9der au lien pour Azure Databricks.</li> </ol> <ol> <li> <p>A partir de votre machine virtuelle, vous pouvez acc\u00e9der au lien suivant: https://canadacentral.azuredatabricks.net/, vous connecter avec votre compte utilisateur et selectionner l'espace de travail Databricks qui vous est accessible. </p> <p></p> </li> </ol>"},{"location":"ExtPortail/#microsoft-power-bi","title":"Microsoft Power BI","text":"<p>Documentation Coming Soon!</p>"},{"location":"ExtPortail/#azure-machine-learning","title":"Azure Machine Learning","text":"<ol> <li>A partir de votre machine virtuelle, vous pouvez vous connecter au portail du service d'analyse des donn\u00e9es (SAD) pour acc\u00e9der au lien pour Azure Databricks.</li> </ol> <ol> <li> <p>A partir de votre machine virtuelle, vous pouvez acc\u00e9der au lien suivant: https://ml.azure.com/, vous connecter avec votre compte utilisateur et selectionner l'espace de travail Databricks qui vous est accessible. </p> <p></p> </li> </ol>"},{"location":"ExtPortail/#machines-virtuelles-azure","title":"Machines Virtuelles Azure","text":"<p>Utilisez le Portail pour acc\u00e9der \u00e0 votre Machine Virtuelle</p>"},{"location":"ExtPortail/#questions-frequemment-posees","title":"QUestions fr\u00e9quemment pos\u00e9es","text":"<ol> <li> <p>Comment puis-je obtenir un compte ou un acc\u00e8s?     Veuillez nous contacter et indiquez que vous d\u00e9sirez obtenir des acc\u00e8s</p> </li> <li> <p>Comment puis-je changer mon mot de passe?     Veuillez utiliser le bouton d'aide \u00e0 partir du portail des SAD pour nous contacter et soumettez une requ\u00eate indiquant que vous voulez changer votre mot de passe.</p> </li> </ol>"},{"location":"FAQ/","title":"FAQ","text":""},{"location":"FAQ/#ingestion-de-donnees","title":"Ingestion de donn\u00e9es","text":"<p>x</p>"},{"location":"FAQ/#comment-puis-je-ingerer-des-donnees-y-compris-des-fichiers-volumineux-dans-la-plateforme","title":"Comment puis-je ing\u00e9rer des donn\u00e9es (y compris des fichiers volumineux) dans la plateforme?","text":""},{"location":"FAQ/#compte-de-stockage-externe","title":"Compte de stockage externe","text":"<p>Les fichiers peuvent \u00eatre t\u00e9l\u00e9vers\u00e9s dans dans le conteneur inbox ou to-vers-int d'un compte de stockage externe, comme indiqu\u00e9 dans l'[ Explorateur de stockage\u00a0Azure ] (AzureStorage.md). Ces fichiers seront alors automatiquement transf\u00e9r\u00e9s dans un compte de stockage interne (Data\u00a0Lake) et rendus accessibles \u00e0 partir des services autoris\u00e9s.</p> <p></p> <p>Remarque: Les comptes de stockage externe ont la convention de d\u00e9nomination statsproject-acronymexternal.</p>"},{"location":"FAQ/#service-de-transfert-electronique-de-fichiers-tef","title":"Service de transfert \u00e9lectronique de fichiers (TEF)","text":"<p>Les employ\u00e9s de Statistique Canada peuvent utiliser le TEF pour transf\u00e9rer des fichiers de / vers les r\u00e9seaux sur site (R\u00e9s. A ou B) vers / depuis l'environnement infonuagique Azure. Veuillez Nous Contacter pour plus d'information sur ce processus.</p>"},{"location":"FAQ/#outils-de-plateforme","title":"Outils de plateforme","text":"<p>Des outils de plateforme comme Databricks ou Data\u00a0Factory peuvent \u00eatre utilis\u00e9s pour ing\u00e9rer des donn\u00e9es provenant de sources dedonn\u00e9es publiques.</p>"},{"location":"FAQ/#explorateur-de-stockage","title":"Explorateur de stockage","text":""},{"location":"FAQ/#comment-puis-je-configurer-les-parametres-du-proxy-de-lexplorateur-de-stockage-azure-sur-un-vdi-du-reseau-b","title":"Comment puis-je configurer les param\u00e8tres du proxy de l'Explorateur de stockage\u00a0Azure sur un VDI du r\u00e9seau\u00a0B?","text":"<p>Pour les employ\u00e9s de Statistique\u00a0Canada seulement </p> <ol> <li> <p>La configuration des param\u00e8tres du proxy est n\u00e9cessaire, si vous recevez le message d'erreur suivant\u00a0:</p> <p></p> </li> <li> <p>Dans l'Explorateur de stockage\u00a0Azure, allez \u00e0 Modifier</p> </li> <li> <p>Param\u00e8tres du proxy. Entrez les param\u00e8tres du proxy n\u00e9cessaires et cliquez sur OK.</p> <p></p> </li> </ol>"},{"location":"FAQ/#comment-puis-je-demander-un-nouveau-jeton-sap-requis-pour-lexplorateur-de-stockage-azure-sur-un-vdi-du-reseau-b","title":"Comment puis-je demander un nouveau jeton\u00a0SAP (requis pour l'Explorateur de stockage\u00a0Azure sur un VDI du r\u00e9seau\u00a0B)?","text":"<p>Pour les employ\u00e9s de Statistique\u00a0Canada seulement</p> <p>Veuillez Nous Contacter pour demander un jeton\u00a0SAP temporaire.</p>"},{"location":"FAQ/#pourquoi-est-ce-que-jobtiens-un-message-derreur-lorsque-jaccede-au-compte-de-stockage-interne-data-lake","title":"Pourquoi est-ce que j'obtiens un message d'erreur lorsque j'acc\u00e8de au compte de stockage interne Data\u00a0Lake?","text":"<p>Le compte de stockage interne Data\u00a0Lake n'est accessible qu'\u00e0 partir d'une machine virtuelle dans l'Environnement d'analyse collaboratif (EAC). Il n'est pas accessible \u00e0 partir de votre ordinateur personnel, ni de votre ordinateur portable de travail, ni du VDI du r\u00e9seau\u00a0B, ni d'une autre machine virtuelle sur nuage.</p>"},{"location":"FAQ/#controle-de-code-source","title":"Contr\u00f4le de code source","text":""},{"location":"FAQ/#comment-puis-je-relier-mon-compte-visual-studio-a-mon-compte-infonuagique-de-statcan","title":"Comment puis-je relier mon compte Visual\u00a0Studio \u00e0 mon compte infonuagique de StatCan?","text":"<ol> <li> <p>Connectez-vous \u00e0 votre compte Visual\u00a0Studio sur le site\u00a0https://visualstudio.microsoft.com/fr/subscriptions/ en     utilisant l'adresse \u00e9lectronique de votre organisation. Pour les employ\u00e9s de StatCan, il s'agit de votre adresse \u00e9lectronique qui se termine par \u00ab\u00a0canada.ca\u00a0\u00bb.</p> <p></p> </li> <li> <p>Ajoutez votre compte infonuagique comme compte secondaire. Vous pourrez ainsi utiliser vos licences pour Visual\u00a0Studio et Azure\u00a0DevOps dans l'EAC.</p> <p></p> </li> </ol> <p>Pour les employ\u00e9s de Statistique\u00a0Canada\u00a0: Si vous n'avez pas d'abonnement Visual\u00a0Studio, veuillez communiquer avec votre superviseur. S'il d\u00e9cide que vous avez besoin d'un abonnement, il pourra alors soumettre une demande de soutien en votre nom aupr\u00e8s de la Gestion des biens logiciels de StatCan pour vous obtenir une licence.</p>"},{"location":"FAQ/#machines-virtuelles","title":"Machines virtuelles","text":""},{"location":"FAQ/#que-dois-je-faire-si-jai-oublie-le-mot-de-passe-de-ma-machine-virtuelle","title":"Que dois-je faire si j'ai oubli\u00e9 le mot de passe de ma machine virtuelle?","text":"<p>Si vous oubliez le mot de passe de votre machine virtuelle, veuillez Nous Contacter pour r\u00e9initialiser votre mot de passe.</p> <p>Vous pouvez \u00e9galement supprimer votre machine virtuelle, puis en cr\u00e9er une autre. Ce faisant, vous perdrez malheureusement les donn\u00e9es et les logiciels sur votre ancienne machine.</p>"},{"location":"FAQ/#que-dois-je-faire-si-je-dois-executer-un-travail-de-longue-duree-sur-ma-machine-virtuelle","title":"Que dois-je faire si je dois ex\u00e9cuter un travail de longue dur\u00e9e sur ma machine virtuelle?","text":"<p>Les machines sont arr\u00eat\u00e9es tous les jours \u00e0\u00a019\u00a0h\u00a0(HNE), afin de r\u00e9duire les frais d'exploitation. Pour ex\u00e9cuter un travail de longue dur\u00e9e, il est recommand\u00e9 d'utiliser Databricks ou Data\u00a0Factory.</p> <p>AVERTISSEMENT\u00a0: Il n'est pas recommand\u00e9 de d\u00e9sactiver l'arr\u00eat automatique, car cela pourrait entra\u00eener des frais importants.</p> <p>Pour d\u00e9sactiver l'arr\u00eat automatique\u00a0:</p> <ol> <li> <p>Acc\u00e9dez \u00e0 votre machine virtuelle dans le portail\u00a0Azure.</p> </li> <li> <p>D\u00e9sactivez l'arr\u00eat automatique.</p> <p></p> </li> </ol>"},{"location":"FAQ/#comment-puis-je-apporter-des-changements-a-ma-machine-virtuelle","title":"Comment puis-je apporter des changements \u00e0 ma machine virtuelle?","text":"<p>Si la machine virtuelle que vous utilisez actuellement ne r\u00e9pond pas \u00e0 vos besoins, veuillez Nous Contacter.</p>"},{"location":"FAQ/#databricks","title":"Databricks","text":""},{"location":"FAQ/#pourquoi-suis-je-incapable-dexecuter-le-code-a-partir-de-mon-notebook-dans-databricks","title":"Pourquoi suis-je incapable d'ex\u00e9cuter le code \u00e0 partir de mon notebook dans Databricks?","text":"<p>Vous devez d'abord d\u00e9marrer un cluster dans Databricks qui a d\u00e9j\u00e0 \u00e9t\u00e9 cr\u00e9\u00e9 pour vous\u00a0: 1. Cliquez sur Clusters.</p> <ol> <li> <p>Naviguez vers votre cluster et cliquez sur le bouton D\u00e9marrer (ic\u00f4ne de la fl\u00e8che).</p> <p></p> </li> </ol>"},{"location":"FAQ/#quels-types-de-clusters-sont-disponibles-dans-databricks","title":"Quels types de clusters sont disponibles dans Databricks?","text":"<p>Voir le lien suivant pour les diff\u00e9rents types de clusters disponibles: https://docs.microsoft.com/en-us/azure/databricks/release-notes/runtime/releases#:~:text=Supported%20Databricks%20runtime%20releases%20and%20support%20schedule%20,Sep%2002%2C%202021%20%2022%20more%20rows%20</p>"},{"location":"FAQ/#que-se-passe-t-il-lorsque-les-clusters-sont-mis-a-niveau","title":"Que se passe-t-il lorsque les clusters sont mis \u00e0 niveau?","text":"<p>LTS (support \u00e0 long terme) a un support pendant 1-2 ans. Ils devront \u00eatre p\u00e9riodiquement mis \u00e0 jour vers une version plus r\u00e9cente. Lors de la mise \u00e0 niveau, tout le code doit \u00eatre r\u00e9ex\u00e9cut\u00e9 pour s'assurer qu'il n'y a pas de probl\u00e8mes lors de la mise \u00e0 jour d'un cluster.</p>"},{"location":"FAQ/#comment-lire-un-fichier-excel-avec-databrickspython","title":"Comment lire un fichier excel avec databricks/python?","text":"<p>Voici un exemple de lecture dans un fichier excel :</p> <pre><code>%python\nimport pandas as pd\npd.read_excel(\"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\", engine='openyxl')\n</code></pre>"},{"location":"FAQ/#tableau-de-bord","title":"Tableau de bord","text":""},{"location":"FAQ/#comment-changer-mon-abonnement-pour-voir-mes-ressources","title":"Comment changer mon abonnement pour voir mes ressources?","text":"<ol> <li> <p>Dans le portail Azure, cliquez sur l'ic\u00f4ne R\u00e9pertoire + abonnement.</p> <p></p> </li> <li> <p>S\u00e9lectionnez l'abonnement vdl.</p> </li> </ol>"},{"location":"FAQ/#autre","title":"Autre","text":""},{"location":"FAQ/#comment-puis-je-me-connecter-au-compte-de-stockage-interne-data-lake-avec-power-bi-desktop","title":"Comment puis-je me connecter au compte de stockage interne Data Lake avec Power BI Desktop?","text":"<p>Pr\u00e9requis: -  Une machine virtuelle dans l'Environnement d'analyse collaborative (EAC). -  Power\u00a0BI\u00a0Desktop. (Offert par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine.)</p> <p>\u00c9tapes:</p> <ol> <li>Connectez-vous \u00e0 votre machine virtuelle dans l'EAC.</li> <li>Lancez Power BI Desktop.</li> <li>Suivez les \u00e9tapes dans Analysez des donn\u00e9es dans Azure Data Lake Storage Gen2 avec Power BI - Cr\u00e9er un rapport dans Power BI Desktop (document anglais). S.v.p. Nous Contacter si vous ne connaissez pas l'URL du Azure Data Lake Storage Gen2.</li> </ol>"},{"location":"FAQ/#comment-les-employes-de-statistique-canada-peuvent-ils-transferer-des-fichiers-de-leur-centre-de-donnees","title":"Comment les employ\u00e9s de Statistique Canada peuvent-ils transf\u00e9rer des fichiers de leur centre de donn\u00e9es?","text":"<p>Pour les employ\u00e9s de Statistique Canada, ils peuvent se r\u00e9f\u00e9rer \u00e0 cette documentation interne: Data Ingestion</p>"},{"location":"FAQ/#comment-puis-je-ajouter-une-question-a-la-faq","title":"Comment puis-je ajouter une question \u00e0 la FAQ?","text":"<p>Veuillez Nous Contacter pour nous faire part de vos suggestions.</p>"},{"location":"Geo/","title":"G\u00e9ospatial","text":""},{"location":"Geo/#environnement-danalyse-geospatial-ega-acces-multiplateforme","title":"Environnement d'analyse g\u00e9ospatial (EGA) - Acc\u00e8s multiplateforme","text":""},{"location":"Geo/#mise-en-route","title":"Mise en route","text":"<p>IMPORTANT: Pr\u00e9requis</p> <pre><code>1. Un projet int\u00e9gr\u00e9 avec acc\u00e8s \u00e0  DAS GAE ArcGIS Portal    2. Un id client ArcGIS Portal (cl\u00e9 API)\n</code></pre> <p>ArcGIS Enterprise Portal est accessible dans AAW ou CAE \u00e0 l'aide de l'API, \u00e0 partir de n'importe quel service qui exploite le langage de programmation Python. </p> <p>Par exemple, dans AAW et l'utilisation de Jupyter Notebooks dans l'espace, ou dans CAE l'utilisation de Databricks, DataFactory, etc.</p> <p>Le portail Das GAE ArcGIS Enterprise est accessible directement ici</p> <p>[Pour obtenir de l'aide sur l'auto-inscription en tant qu'utilisateur du portail g\u00e9ospatial DAS] (https://statcan.github.io/gae-eag/french/portalFR/)</p>"},{"location":"Geo/#utilisation-darcgis-api-interface-de-programmation-dapplication-for-python","title":"Utilisation d'ArcGIS API (interface de programmation d'application) for Python","text":""},{"location":"Geo/#connexion-a-arcgis-enterprise-portal-a-laide-de-lapi-arcgis","title":"Connexion \u00e0 ArcGIS Enterprise Portal \u00e0 l'aide de l'API ArcGIS","text":"<ol> <li> <p>Installer les packages :</p> <p><code>python conda install -c esri arcgis</code></p> <p>ou en utilisant Artifactory</p> <p><code>python3333 conda install -c https://jfrog.aaw.cloud.statcan.ca/artifactory/api/conda/esri-remote arcgis</code></p> </li> <li> <p>Importez les biblioth\u00e8ques n\u00e9cessaires dont vous aurez besoin dans le Bloc-notes.     <code>python     from arcgis.gis import GIS     from arcgis.gis import Item</code></p> </li> <li> <p>Acc\u00e9der au portail     Votre groupe de projet recevra un ID client lors de l'int\u00e9gration. Collez l'ID client entre les guillemets <code>client_id='######'</code>. </p> <p><code>python gis = GIS(\"https://geoanalytics.cloud.statcan.ca/portal\", client_id=' ') print(\"succ\u00e8s: \" + gis.properties.user.username)</code></p> </li> <li> <ul> <li>Le r\u00e9sultats vous redirigera vers un portail de connexion.</li> <li>Utilisez l'option connexion Azure de StatCan et votre ID cloud </li> <li>Apr\u00e8s une connexion r\u00e9ussie, vous recevrez un code pour vous connecter \u00e0 l'aide de SAML. </li> <li>Collez ce code dans le r\u00e9sultat (en anglais seulement). </li> </ul> <p> (en anglais seulement)</p> </li> </ol>"},{"location":"Geo/#afficher-les-informations-de-lutilisateur","title":"Afficher les informations de l'utilisateur","text":"<p>En utilisant la fonction 'me', nous pouvons afficher diverses informations sur l'utilisateur connect\u00e9.</p> <pre><code>me = gis.users.me\nusername = me.username\ndescription = me.description\ndisplay(me)\n</code></pre>"},{"location":"Geo/#recherche-de-contenu","title":"Recherche de contenu","text":"<p>Recherchez le contenu que vous avez h\u00e9berg\u00e9 sur le portail g\u00e9ographique DAaaS. En utilisant la fonction \u00c2\u00ab\u00c2 me\u00c2 \u00c2\u00bb, nous pouvons rechercher tout le contenu h\u00e9berg\u00e9 sur le compte. Il existe plusieurs fa\u00e7ons de rechercher du contenu. Deux m\u00e9thodes diff\u00e9rentes sont d\u00e9crites ci-dessous.</p> <p>Rechercher tous vos itmes h\u00e9berg\u00e9s dans le portail g\u00e9ographique DAaaS.</p> <pre><code>my_content = me.items()\nmy_content\n</code></pre> <p>Recherchez le contenu sp\u00e9cifique que vous poss\u00e9dez dans le portail g\u00e9ographique DAaaS.</p> <p>Ceci est similaire \u00c3  l'exemple ci-dessus, mais si vous connaissez le titre de la couche qu'ils souhaitez utiliser, vous pouvez l'enregistrer en tant que fonction.</p> <pre><code>my_items = me.items()\nfor items in my_items:\n    print(items.title, \" | \", items.type)\n    if items.title == \"Flood in Sorel-Tracy\":\n        flood_item = items\n\n    else:\n        continue\nprint(flood_item)\n</code></pre> <p>Recherchez tout le contenu auquel vous avez acc\u00e8s, pas seulement le v\u00f4tre.</p> <pre><code>flood_item = gis.content.search(\"tags: flood\", item_type =\"Feature Service\")\nflood_item\n</code></pre>"},{"location":"Geo/#obtenir-du-contenu","title":"Obtenir du contenu","text":"<p>Nous devons obtenir l'\u00e9l\u00e9ment du portail g\u00e9ographique SAD afin de l'utiliser dans le bloc-notes Jupyter. Pour ce faire, vous fournissez le num\u00e9ro d'identification unique de l'\u00e9l\u00e9ment que vous souhaitez utiliser. Trois exemples sont d\u00e9crits ci-dessous, tous acc\u00e9dant \u00c3  la couche identique.</p> <pre><code>item1 = gis.content.get(my_content[5].id) #\u00c0 partir de la recherche de votre contenu ci-dessus\ndisplay(item1)\n\nitem2 = gis.content.get(flood_item.id) #De l'exemple ci-dessus - recherche de contenu sp\u00e9cifique\ndisplay(item2)\n\nitem3 = gis.content.get('edebfe03764b497f90cda5f0bfe727e2') #Le num\u00e9ro d'identification de l'article\ndisplay(item3)\n</code></pre>"},{"location":"Geo/#effectuer-une-analyse","title":"Effectuer une analyse","text":"<p>Une fois les couches introduites dans le bloc-notes Jupyter, nous sommes en mesure d'effectuer des types d'analyse similaires que vous vous attendez \u00c3  trouver dans un logiciel SIG tel qu'ArcGIS. Il existe de nombreux modules contenant de nombreux sous-modules dont peuvent effectuer plusieurs types d'analyses. </p> <p>\u00c0 l'aide du module arcgis.features, importez le sous-module use_proximity <code>from arcgis.features import use_proximity</code>. Ce sous-module nous permet de '.create_buffers' - zones de distance \u00e9gale par rapport aux entit\u00e9s. Ici, nous sp\u00e9cifions la couche que nous voulons utiliser, la distance, les unit\u00e9s et le nom en sortie (vous pouvez \u00e9galement sp\u00e9cifier d'autres caract\u00e9ristiques telles que le champ, le type d'anneau, le type d'extr\u00e9mit\u00e9 et autres). En sp\u00e9cifiant un nom en sortie, apr\u00e8s avoir ex\u00e9cut\u00e9 la commande de zone tampon, une nouvelle couche sera automatiquement t\u00e9l\u00e9charg\u00e9e dans le portail GEO DAaaS contenant la nouvelle fonctionnalit\u00e9 que vous venez de cr\u00e9er. </p> <pre><code>buffer_lyr = use_proximity.create_buffers(item1, distances=[1], \n                                          units = \"Kilometers\", \n                                          output_name='item1_buffer')\n\ndisplay(item1_buffer)\n</code></pre> <p>Certains utilisateurs pr\u00e9f\u00e8rent travailler avec des packages Open Source.  La traduction d'ArcGIS vers spatial Dataframes est simple.</p> <pre><code># create a Spatially Enabled DataFrame object\nsdf = pd.DataFrame.spatial.from_layer(feature_layer)\n</code></pre>"},{"location":"Geo/#mettre-a-jour-les-elements","title":"Mettre \u00e0 jour les \u00e9l\u00e9ments","text":"<p>En obtenant l'\u00e9l\u00e9ment comme nous l'avons fait similaire \u00e0 l'exemple ci-dessus, nous pouvons utiliser la fonction '.update' pour mettre \u00e0 jour l'\u00e9l\u00e9ment existant dans le portail DAaaS GEO. Nous pouvons mettre \u00e0 jour les propri\u00e9t\u00e9s des \u00e9l\u00e9ments, les donn\u00e9es, les vignettes et les m\u00e9tadonn\u00e9es.</p> <pre><code>item1_buffer = gis.content.get('c60c7e57bdb846dnbd7c8226c80414d2')\nitem1_buffer.update(item_properties={'title': 'Enter Title'\n                                     'tags': 'tag1, tag2, tag3, tag4',\n                                     'description': 'Enter description of item'}\n</code></pre>"},{"location":"Geo/#visualisez-vos-donnees-sur-une-carte-interactive","title":"Visualisez vos donn\u00e9es sur une carte interactive","text":"<p>Exemple : Biblioth\u00e8que MatplotLib Dans le code ci-dessous, nous cr\u00e9ons un objet ax, qui est un trac\u00e9 de style carte. Nous tra\u00e7ons ensuite notre colonne de changement de donn\u00e9es ('Changement de population') sur les axes</p> <pre><code>import matplotlib.pyplot as plt\nax = sdf.boundary.plot(figsize=(10, 5))\nshape.plot(ax=ax, column='Population Change', legend=True)\nplt.show()\n</code></pre> <p>Exemple : biblioth\u00e8que ipyleaflet Dans cet exemple, nous utiliserons la biblioth\u00e8que 'ipyleaflet' pour cr\u00e9er une carte interactive. Cette carte sera centr\u00e9e autour de Toronto, en Ontario. Les donn\u00e9es utilis\u00e9es seront d\u00e9crites ci-dessous. Commencez par coller <code>conda install -c conda-forge ipyleaflet</code> vous permettant d'installer des biblioth\u00e8ques ipyleaflet dans l'environnement Python.  Importez les biblioth\u00e8ques n\u00e9cessaires.</p> <pre><code>import ipyleaflet \nfrom ipyleaflet import *\n</code></pre> <p>Maintenant que nous avons import\u00e9 le module ipyleaflet, nous pouvons cr\u00e9er une carte simple en sp\u00e9cifiant la latitude et la longitude de l'emplacement que nous voulons, le niveau de zoom et le fond de carte (plus de fonds de carte) (en anglais seulement).  Des contr\u00f4les suppl\u00e9mentaires ont \u00e9t\u00e9 ajout\u00e9s, tels que des couches et des mises \u00c3  l'\u00e9chelle.</p> <pre><code>toronto_map = Map(center=[43.69, -79.35], zoom=11, basemap=basemaps.Esri.WorldStreetMap)\n\ntoronto_map.add_control(LayersControl(position='topright'))\ntoronto_map.add_control(ScaleControl(position='bottomleft'))\ntoronto_map\n</code></pre> <p></p>"},{"location":"Geo/#en-savoir-plus-sur-arcgis-api-for-python","title":"En savoir plus sur ArcGIS API for Python","text":"<p>La documentation compl\u00e8te de l'API ArGIS peut \u00eatre trouv\u00e9e ici (en anglais seulement)</p>"},{"location":"Geo/#en-savoir-plus-sur-lenvironnement-analytique-geospatial-ega-et-les-services-du-das","title":"En savoir plus sur l'environnement analytique g\u00e9ospatial (EGA) et les services du DAS","text":"<p>Guide d'aide du GAE</p>"},{"location":"GitHubCommencer/","title":"Commencer","text":"<p>GitHub.com est une plateforme en ligne utilis\u00e9e \u00e0 des fins de collaboration ainsi que pour assurer le suivi des modifications et des versions pour divers types de projets.</p> <p>Ce document montre la fa\u00e7on de commencer \u00e0 utiliser Git avec divers services Azure dont l\u2019int\u00e9gration Git est d\u00e9j\u00e0 configur\u00e9e. Voir GitHub - Configuration pour obtenir des instructions sur la fa\u00e7on de configurer ce syst\u00e8me.</p> <p>Important : ne stockez pas de donn\u00e9es class\u00e9es Prot\u00e9g\u00e9 B sur GitHub.</p>"},{"location":"GitHubCommencer/#creation-dun-compte-github","title":"Cr\u00e9ation d\u2019un compte GitHub","text":"<p>Des renseignements sur la cr\u00e9ation d\u2019un compte GitHub (ou sur l\u2019utilisation de votre compte existant) se trouvent \u00e0 l\u2019adresse Des renseignements sur la cr\u00e9ation d\u2019un compte GitHub (ou sur l\u2019utilisation de votre compte existant) se trouvent \u00e0 l\u2019adresse https://digital.statcan.gc.ca/drafts/guides-platforms-github.</p>"},{"location":"GitHubCommencer/#azure-data-factory","title":"Azure Data Factory","text":"<p>Si l\u2019int\u00e9gration Git est configur\u00e9e pour votre Data Factory, chaque fois que vous enregistrez ou que vous publiez des modifications, celles-ci seront automatiquement synchronis\u00e9es avec le d\u00e9p\u00f4t GitHub.</p> <p>Pour changer la division dans laquelle vous travaillez (la division de collaboration par d\u00e9faut est main [principale]), cliquez sur la fl\u00e8che orient\u00e9e vers le bas, \u00e0 c\u00f4t\u00e9 du nom de la division, en haut \u00e0 gauche de l\u2019\u00e9cran. \u00c0 partir de l\u00e0, vous pouvez s\u00e9lectionner une autre division ou en cr\u00e9er une nouvelle. </p>"},{"location":"GitHubCommencer/#databricks","title":"Databricks","text":""},{"location":"GitHubCommencer/#configuration-dun-jeton-dacces-personnel","title":"Configuration d\u2019un jeton d\u2019acc\u00e8s personnel","text":"<p>Avant de pouvoir travailler avec les d\u00e9p\u00f4ts GitHub dans Databricks, vous devez d\u2019abord configurer un jeton d\u2019acc\u00e8s personnel (ce qui permet \u00e0 Databricks d\u2019acc\u00e9der \u00e0 votre compte GitHub).</p> <ol> <li> <p>Dans Databricks, ouvrez User Settings (param\u00e8tres d\u2019utilisateur), puis cliquez sur l\u2019onglet Git integration (int\u00e9gration de Git). </p> <p></p> </li> <li> <p>Sous Git provider (fournisseur Git), s\u00e9lectionnez GitHub. Entrez votre nom d\u2019utilisateur GitHub.</p> </li> <li> <p>\u00c0 partir de votre compte GitHub, suivez les instructions pour cr\u00e9er un jeton d\u2019acc\u00e8s personnel, en vous assurant que la case de permission repo (d\u00e9p\u00f4t) est coch\u00e9e. Si vous avez fix\u00e9 une date d\u2019expiration, vous devrez r\u00e9p\u00e9ter ce processus pour cr\u00e9er un nouveau jeton une fois la date fix\u00e9e pass\u00e9e. </p> <p></p> </li> <li> <p>Copiez le jeton et collez-le dans Databricks. Cliquez sur Save (enregistrer).</p> </li> </ol>"},{"location":"GitHubCommencer/#creation-et-modification-de-divisions","title":"Cr\u00e9ation et modification de divisions","text":"<p>Une pratique exemplaire consiste \u00e0 effectuer tous vos travaux dans votre propre branche division (et non pas dans la division principale), puis \u00e0 fusionner vos modifications avec la division principale une fois que vous \u00eates pr\u00eat \u00e0 publier vos travaux.</p> <ol> <li> <p>Pour cr\u00e9er une nouvelle division ou modifier une division existante, cliquez sur l\u2019onglet Repos (d\u00e9p\u00f4ts). \u00c0 partir de l\u00e0, cliquez sur le dossier contenant le d\u00e9p\u00f4t GitHub pour l\u2019ouvrir. Cliquez sur la fl\u00e8che orient\u00e9e vers le bas, \u00e0 c\u00f4t\u00e9 du nom de la division, puis cliquez sur Git.... </p> <p></p> </li> <li> <p>Cliquez sur la fl\u00e8che orient\u00e9e vers le bas pour trouver une division existante, ou cliquez sur le signe \u00ab plus \u00bb pour en cr\u00e9er une nouvelle. Votre division doit inclure votre nom. </p> <p></p> </li> <li> <p>Une fois votre branche cr\u00e9\u00e9e, recherchez-la dans le menu d\u00e9roulant et cliquez dessus pour y basculer. Cliquez sur fermer. Tout votre travail sera d\u00e9sormais enregistr\u00e9 dans cette branche, \u00e0 moins que vous ne le changiez \u00e0 nouveau plus tard.</p> </li> </ol>"},{"location":"GitHubCommencer/#creation-deplacement-et-clonage-de-blocs-notes","title":"Cr\u00e9ation, d\u00e9placement et clonage de blocs-notes","text":"<ul> <li> <p>Pour cr\u00e9er un nouveau bloc-notes dans le r\u00e9f\u00e9rentiel, dans le menu d\u00e9roulant \u00e0 c\u00f4t\u00e9 du nom de votre branche, survolez Cr\u00e9er, puis cliquez sur Bloc-notes. Vous pouvez \u00e9galement cr\u00e9er des dossiers de cette fa\u00e7on.</p> <p></p> </li> <li> <p>Pour cloner un bloc-notes existant de votre espace de travail, naviguez jusqu\u2019au bloc-notes (dans l\u2019onglet Workspace [espace de travail]), cliquez sur la fl\u00e8che orient\u00e9e vers le bas, \u00e0 c\u00f4t\u00e9 du nom du bloc-notes, puis cliquez sur Clone (cloner) pour cr\u00e9er une copie du bloc-notes dans le d\u00e9p\u00f4t. Pour d\u00e9placer le bloc-notes de l\u2019espace de travail au d\u00e9p\u00f4t, s\u00e9lectionnez Move (d\u00e9placer). Trouvez le d\u00e9p\u00f4t dans le menu contextuel et naviguez jusqu\u2019au dossier dans lequel vous souhaitez cloner ou d\u00e9placer le bloc-notes. Cliquez sur Clone/Select (cloner/s\u00e9lectionner).</p> </li> </ul>"},{"location":"GitHubCommencer/#validation-et-acheminement-des-modifications","title":"Validation et acheminement des modifications","text":"<ol> <li> <p>Dans l\u2019onglet Repos (d\u00e9p\u00f4ts), cliquez sur le dossier contenant le d\u00e9p\u00f4t GitHub pour l\u2019ouvrir. Cliquez sur la fl\u00e8che orient\u00e9e vers le bas, \u00e0 c\u00f4t\u00e9 du nom de la division, puis cliquez sur Git....</p> </li> <li> <p>Assurez-vous que toutes les modifications que vous souhaitez apporter sont coch\u00e9es. Saisissez un bref r\u00e9sum\u00e9 d\u00e9crivant les modifications apport\u00e9es, puis cliquez sur Commit &amp; Push (valider et acheminer). </p> <p></p> </li> </ol>"},{"location":"GitHubCommencer/#azure-synapse","title":"Azure Synapse","text":"<p>Voir Azure Data Factory plus haut.</p>"},{"location":"GitHubCommencer/#visual-studio-code","title":"Visual Studio Code","text":""},{"location":"GitHubCommencer/#comment-cloner-un-depot","title":"Comment cloner un d\u00e9p\u00f4t","text":"<ol> <li> <p>Cliquez sur l\u2019onglet Source Control (contr\u00f4le de la source). Vous pouvez alors soit ouvrir un dossier contenant un d\u00e9p\u00f4t Git si vous en avez d\u00e9j\u00e0 un sur votre machine virtuelle (MV) en nuage, soit cloner un d\u00e9p\u00f4t \u00e0 partir de l\u2019adresse d\u2019une page Web (URL). </p> <p></p> </li> <li> <p>Pour cloner un d\u00e9p\u00f4t, cliquez sur Clone Repository (cloner le d\u00e9p\u00f4t). Copiez l\u2019adresse URL du d\u00e9p\u00f4t depuis GitHub (par exemple, https://github.com/nom d\u2019utilisateur/nom du d\u00e9p\u00f4t), collez-la dans la bo\u00eete de texte et cliquez sur Clone from URL (cloner \u00e0 partir de l\u2019URL). </p> <p></p> </li> <li> <p>Choisissez un dossier sur votre MV en nuage o\u00f9 le d\u00e9p\u00f4t Git sera stock\u00e9 localement. Vous serez peut-\u00eatre invit\u00e9 \u00e0 vous connecter \u00e0 votre compte GitHub.</p> </li> <li> <p>Une fois le d\u00e9p\u00f4t clon\u00e9 sur votre machine, vous pouvez ouvrir le dossier local dans Visual Studio Code.</p> </li> </ol>"},{"location":"GitHubCommencer/#comment-valider-des-modifications","title":"Comment valider des modifications","text":"<ol> <li> <p>Avant de pouvoir valider des modifications, vous devez configurer votre nom d\u2019utilisateur et votre adresse \u00e9lectronique. Ouvrez une fen\u00eatre de terminal (cliquez sur Terminal, puis sur New Terminal [nouveau terminal] dans la barre de menus). Dans le terminal, tapez ce qui suit :     <code>git config user.name \"First Last\"     git config user.email \"pr\u00e9nom.nom@canada.ca\"</code> </p> <p></p> </li> <li> <p>Lorsque vous \u00eates pr\u00eat \u00e0 publier vos modifications sur GitHub, tapez un message de validation dans l\u2019onglet Source control (contr\u00f4le de la source), puis cliquez sur la coche. </p> <p></p> </li> <li> <p>Cliquez sur le bouton du menu de contr\u00f4le de la source, puis sur Push (acheminer). Vous obtiendrez un message d\u2019erreur si votre copie locale du d\u00e9p\u00f4t n\u2019est pas \u00e0 jour par rapport \u00e0 la version stock\u00e9e sur GitHub. Dans ce cas, cliquez sur Pull, puis Push (r\u00e9cup\u00e9rer, puis acheminer) pour fusionner vos modifications. </p> <p></p> </li> </ol>"},{"location":"GitHubCommencer/#r-studio","title":"R Studio","text":"<p>Remarque: les instructions sont les m\u00eames, que vous utilisiez la version de bureau de R-Studio \u00e0 partir d\u2019une MV en nuage ou la version Web via Databricks.</p>"},{"location":"GitHubCommencer/#configuration","title":"Configuration","text":"<ol> <li> <p>Dans le menu File (fichier), cliquez sur New Project... (nouveau projet), puis s\u00e9lectionnez Version Control(contr\u00f4le de version). </p> <p></p> </li> <li> <p>S\u00e9lectionnez Git. Saisissez l\u2019adresse URL du d\u00e9p\u00f4t GitHub que vous souhaitez cloner. Choisissez un dossier o\u00f9 seront stock\u00e9s les fichiers locaux, puis cliquez sur Create project (cr\u00e9er le projet). </p> <p></p> </li> <li> <p>Si vous \u00eates invit\u00e9 \u00e0 vous connecter \u00e0 votre compte GitHub, saisissez votre nom d\u2019utilisateur GitHub et un jeton d\u2019acc\u00e8s personnel comme mot de passe.</p> </li> </ol>"},{"location":"GitHubCommencer/#comment-valider-des-modifications_1","title":"Comment valider des modifications","text":"<ol> <li> <p>Lorsque vous \u00eates pr\u00eat \u00e0 publier vos modifications sur GitHub, cliquez sur l\u2019onglet Git. Ensuite, cliquez sur Commit (valider). </p> <p></p> </li> <li> <p>Cliquez sur la case \u00e0 cocher pour chacune des modifications que vous souhaitez valider. Saisissez un message de validation d\u00e9crivant bri\u00e8vement vos modifications, puis cliquez sur Commit (valider). Une fen\u00eatre contextuelle s\u2019affichera pour confirmer que votre validation a fonctionn\u00e9. Cliquez sur Close (fermer). </p> <p></p> </li> <li> <p>Cliquez sur le bouton Push (acheminer) pour t\u00e9l\u00e9charger vos modifications sur GitHub. Une fen\u00eatre contextuelle s\u2019affichera pour confirmer que l\u2019acheminement a fonctionn\u00e9. Vous obtiendrez un message d\u2019erreur si votre copie locale du d\u00e9p\u00f4t n\u2019est pas \u00e0 jour par rapport \u00e0 la version stock\u00e9e sur GitHub. Dans ce cas, cliquez sur Pull, puis Push (r\u00e9cup\u00e9rer, puis acheminer) pour fusionner vos modifications.</p> </li> </ol>"},{"location":"GitHubCommencer/#faq","title":"FAQ","text":"<p>J\u2019obtiens une erreur lorsque j\u2019essaie d\u2019acheminer les modifications. Pourquoi?</p> <p>Cela peut signifier que votre copie locale du d\u00e9p\u00f4t n\u2019est pas \u00e0 jour par rapport \u00e0 la copie stock\u00e9e sur GitHub. Essayez d\u2019abord de cliquer sur pull (r\u00e9cup\u00e9rer), puis d\u2019acheminer vos modifications. Une pratique exemplaire consiste \u00e0 toujours ex\u00e9cuter une commande de r\u00e9cup\u00e9ration avant de commencer \u00e0 travailler avec un d\u00e9p\u00f4t afin de s\u2019assurer que vous travaillez sur la derni\u00e8re version, et qu\u2019une seule personne peut modifier le m\u00eame fichier en m\u00eame temps.</p> <p>Comment revenir \u00e0 une validation ant\u00e9rieure?</p> <p>Cette op\u00e9ration doit \u00eatre effectu\u00e9e \u00e0 partir de Visual Studio (VS) Code (accessible par une machine virtuelle en nuage), quel que soit l\u2019endroit o\u00f9 vous utilisez principalement Git.</p> <ol> <li>Dans VS Code, suivez les \u00e9tapes pour cloner un d\u00e9p\u00f4t si vous ne l\u2019avez pas d\u00e9j\u00e0 fait.</li> <li>Ouvrez un terminal (cliquez sur Terminal, puis New Terminal [terminal, puis nouveau terminal]).</li> <li>Dans la fen\u00eatre du terminal, tapez git revert HEAD~n --no-edit et appuyez sur Entr\u00e9e (remplacez n par le nombre de validations que vous souhaitez r\u00e9tablir, en commen\u00e7ant par 0). Remarque : vous pouvez trouver l\u2019historique de vos validations sur GitHub en cliquant sur x commits (x validations) en haut \u00e0 droite de votre d\u00e9p\u00f4t.</li> <li>S\u2019il y a des conflits de fusion, cliquez sur Accept incoming change (accepter la modification entrante), puis validez et acheminez les modifications comme d\u2019habitude (voir les instructions d\u00e9taill\u00e9es sur la fa\u00e7on de le faire dans VS Code).</li> </ol>"},{"location":"GitHubConfiguration/","title":"Configuration","text":"<p>GitHub.com est une plateforme en ligne utilis\u00e9e \u00e0 des fins de collaboration ainsi que pour assurer le suivi des modifications et des versions pour divers types de projets</p> <p>Important : Ne stockez pas de donn\u00e9es class\u00e9es Prot\u00e9g\u00e9 B sur GitHub.com</p>"},{"location":"GitHubConfiguration/#creation-dun-compte-github","title":"Cr\u00e9ation d\u2019un compte GitHub","text":"<p>Des renseignements sur la cr\u00e9ation d\u2019un compte GitHub (ou sur l\u2019utilisation de votre compte existant) se trouvent \u00e0 l\u2019adresse: https://digital.statcan.gc.ca/drafts/guides-platforms-github.</p>"},{"location":"GitHubConfiguration/#azure-data-factory","title":"Azure Data Factory","text":"<ol> <li> <p>Dans l\u2019onglet Manage (g\u00e9rer), cliquez sur Git configuration (configuration de Git).</p> <p></p> </li> <li> <p>Cliquez sur Configure (configurer). Sous Repository type (type de d\u00e9p\u00f4t), s\u00e9lectionnez GitHub, puis entrez le nom d\u2019utilisateur de votre compte GitHub. Cliquez sur Continue (continuer). </p> <p></p> </li> <li> <p>Une fen\u00eatre contextuelle s\u2019affiche. Cliquez sur Authorize Azure Data Factory (autoriser Azure Data Factory), puis saisissez le mot de passe de votre compte GitHub.</p> </li> <li> <p>Configurez un d\u00e9p\u00f4t. Vous pouvez soit s\u00e9lectionner un d\u00e9p\u00f4t dont vous \u00eates propri\u00e9taire, soit saisir un lien vers un d\u00e9p\u00f4t. Pr\u00e9cisez tout param\u00e8tre suppl\u00e9mentaire, puis cliquez sur Apply (appliquer). </p> <p></p> </li> <li> <p>D\u00e9finissez votre division de travail. Vous pouvez soit cr\u00e9er une nouvelle division, soit utiliser une division existante. Cliquez ensuite sur Save (enregistrer).</p> </li> </ol> <p>Pour supprimer l\u2019int\u00e9gration GitHub, cliquez sur Disconnect (d\u00e9connecter) \u00e0 l\u2019\u00e9cran Git configuration (configuration de Git). Entrez le nom de l\u2019usine de donn\u00e9es, puis cliquez de nouveau sur Disconnect (d\u00e9connecter) pour confirmer.  </p> <p></p>"},{"location":"GitHubConfiguration/#azure-databricks","title":"Azure Databricks","text":""},{"location":"GitHubConfiguration/#configuration-de-lintegration-de-git","title":"Configuration de l\u2019int\u00e9gration de Git","text":"<ol> <li> <p>Ouvrez User Settings (param\u00e8tres d\u2019utilisateur), puis cliquez sur l\u2019onglet Git integration (int\u00e9gration de Git). </p> <p></p> </li> <li> <p>Sous Git provider (fournisseur Git), s\u00e9lectionnez GitHub. Entrez votre nom d\u2019utilisateur GitHub.</p> </li> <li> <p>\u00c0 partir de votre compte GitHub, suivez les instructions pour cr\u00e9er un jeton d\u2019acc\u00e8s personnel, ensuring that the repo permission is checked.</p> <p></p> </li> <li> <p>Copiez le jeton et collez-le dans Databricks. Cliquez sur Save (enregistrer).</p> </li> </ol>"},{"location":"GitHubConfiguration/#ajout-dun-depot-git","title":"Ajout d\u2019un d\u00e9p\u00f4t Git","text":"<ol> <li> <p>Dans l\u2019onglet Repos (d\u00e9p\u00f4ts), cliquez sur Add Repo (ajouter un d\u00e9p\u00f4t). </p> <p></p> </li> <li> <p>S\u00e9lectionnez Clone remote Git repo (cloner un d\u00e9p\u00f4t Git \u00e0 distance), entrez l\u2019adresse (URL) de la page Web de votre d\u00e9p\u00f4t GitHub. Le fournisseur Git et le nom du d\u00e9p\u00f4t devraient s\u2019afficher automatiquement. Cliquez sur Create (cr\u00e9er).</p> </li> </ol>"},{"location":"GitHubConfiguration/#machines-virtuelles-de-lenvironnement-danalyse-collaborative","title":"Machines virtuelles de l\u2019environnement d\u2019analyse collaborative","text":""},{"location":"GitHubConfiguration/#visual-studio-code","title":"Visual Studio Code","text":"<p>Pour apprendre \u00e0 utiliser GitHub avec Visual Studio Code, consultez la documentation  GitHub - Getting Started.</p>"},{"location":"GitHubConfiguration/#r-studio","title":"R-Studio","text":"<ol> <li> <p>Dans le menu File (fichier), cliquez sur New Project... (nouveau projet), puis s\u00e9lectionnez Version Control (contr\u00f4le de version). </p> <p></p> </li> <li> <p>S\u00e9lectionnez Git. Saisissez l\u2019URL du d\u00e9p\u00f4t GitHub que vous souhaitez cloner, choisissez un dossier sur votre machine virtuelle (MV) o\u00f9 seront enregistr\u00e9s les fichiers locaux, puis cliquez sur Create Project (cr\u00e9er un projet). </p> <p></p> </li> </ol>"},{"location":"GitHubConfiguration/#azure-machine-learning","title":"Azure Machine Learning","text":"<ol> <li> <p>Cr\u00e9ez une instance de calcul, puis ouvrez un terminal. </p> <p></p> </li> <li> <p>Dans la fen\u00eatre du terminal, entrez ce qui suit (remplacez l\u2019exemple de courriel par le v\u00f4tre) : <code>ssh-keygen -t rsa -b 4096 -C \"pr\u00e9nom.nom@canada.ca\"</code></p> </li> <li> <p>Appuyez sur Enter (entrer) jusqu\u2019\u00e0 ce que votre cl\u00e9 soit g\u00e9n\u00e9r\u00e9e. </p> <p></p> </li> <li> <p>Entrez dans le terminal : cat ~/.ssh/id_rsa.pub. S\u00e9lectionnez l\u2019extrant et copiez-le dans le presse-papiers. </p> <p></p> </li> <li> <p>Allez dans les param\u00e8tres de votre compte GitHub (sur GitHub.com), cliquez sur SSH and GPG keys (cl\u00e9s SSH et GPG), puis sur New SSH key (nouvelle cl\u00e9 SSH). Collez la cl\u00e9 que vous venez de copier, puis cliquez sur Add SSH key (ajouter une cl\u00e9 SSH). </p> <p></p> </li> <li> <p>Dans la fen\u00eatre du terminal, tapez : git clone [url] (remplacez [url] par l\u2019url SSH de votre d\u00e9p\u00f4t GitHub, par exemple, git@github.com:nom d\u2019utilisateur/nom du d\u00e9p\u00f4t.git).</p> </li> <li> <p>Lorsque vous y \u00eates invit\u00e9, tapez yes (oui).</p> </li> </ol>"},{"location":"GitHubConfiguration/#microsoft-documentation","title":"Microsoft Documentation","text":"<ul> <li>Int\u00e9gration de Git pour Azure Machine Learning</li> </ul>"},{"location":"GitHubConfiguration/#azure-synapse","title":"Azure Synapse","text":"<ol> <li> <p>Dans l\u2019onglet Manage (g\u00e9rer), cliquez sur Git configuration (configuration de Git). </p> <p></p> </li> <li> <p>Cliquez sur Configure (configurer). Sous Repository type (type de d\u00e9p\u00f4t), s\u00e9lectionnez GitHub, puis entrez le nom d\u2019utilisateur de votre compte GitHub. Cliquez sur Continue (continuer).</p> </li> <li> <p>Une fen\u00eatre contextuelle s\u2019affiche. Entrez les renseignements de connexion de votre compte GitHub, puis cliquez sur Authorize Azure Synapse (autoriser Azure Synapse).</p> </li> <li> <p>Configurez un d\u00e9p\u00f4t. Vous pouvez soit s\u00e9lectionner un d\u00e9p\u00f4t dont vous \u00eates propri\u00e9taire, soit saisir un lien vers un d\u00e9p\u00f4t. Pr\u00e9cisez tout param\u00e8tre suppl\u00e9mentaire, puis cliquez sur Apply (appliquer).</p> </li> <li> <p>D\u00e9finissez votre division de travail. Vous pouvez soit cr\u00e9er une nouvelle division, soit utiliser une division existante. Cliquez ensuite sur Save (enregistrer).</p> </li> </ol> <p>Pour supprimer l\u2019int\u00e9gration de GitHub : \u00e0 l\u2019\u00e9cran de configuration de Git, cliquez sur Disconnect (d\u00e9connecter). Entrez le nom de l\u2019espace de travail, puis cliquez de nouveau sur Disconnect (d\u00e9connecter) pour confirmer.</p>"},{"location":"InscrivezProjet/","title":"Inscrivez votre projet","text":"<p>Inscrivez-vous ici pour faire partie de la Communaut\u00e9 des premiers utilisateurs de l'Analyse des donn\u00e9es en tant que service (ADS). Allez au portail de l'analyse de donn\u00e9es en tant que service et cliquez sur le bouton \"Commencer\".</p> <p>https://www.statcan.gc.ca/data-analytics-services</p> <p>Cliquez sur le bouton \u00abFran\u00e7ais (Canada)\u00bb du formulaire pour changer la langue en fran\u00e7ais.</p> <p>Si vous avez d\u00e9j\u00e0 obtenu l'acc\u00e8s \u00e0 la plateforme, consultez les directives pour savoir comment ouvrir une session.</p> <p>Avant de vous connecter vous aurez acc\u00e8s au boutton Commencer. En cliquant sur le boutton il vous sera demand\u00e9 de vous connecter.             </p> <p>Une fois sur la page principale, vos pourrez enregistrer un nouveau projet en cliquant sur le bouton Start a New project </p>"},{"location":"Langue/","title":"Langue","text":"<p>Le document d\u00e9crit la fa\u00e7on de changer la langue dans les diff\u00e9rents services offerts.</p>"},{"location":"Langue/#portail-azure","title":"Portail Azure","text":"<p>Pour modifier les param\u00e8tres de langue du portail Azure, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale.</p> </li> <li> <p>Cliquez sur l'onglet Langue et r\u00e9gion.</p> </li> <li> <p>Utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9.</p> </li> <li> <p>Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional.</p> <p></p> </li> </ol>"},{"location":"Langue/#tableau-de-bord","title":"Tableau de bord","text":"<p>Pour acc\u00e9der au tableau de bord en fran\u00e7ais de l\u2019environnement d\u2019Analyse collaborative (EAC), voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>\u00c0 partir de la liste des tableaux de bords, cliquez sur la fl\u00e8che correspondant au nom du tableau de bord.</p> </li> <li> <p>S\u00e9lectionnez le tableau de bord Environnement d\u2019Analyse Collaborative dans la liste affich\u00e9e.</p> <p>Note: Si ce tableau de bord n'est pas dans la liste, cliquez sur Parcourir tous les tableaux de bord pour acc\u00e9der \u00e0 la liste compl\u00e8te des tableaux de bord.</p> <p></p> </li> </ol>"},{"location":"Langue/#machines-virtuelles","title":"Machines Virtuelles","text":""},{"location":"Langue/#serveur-windows","title":"Serveur Windows","text":"<p>Pour configurer la langue d'affichage dans une machine virtuelle Windows, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Selectionnez Param\u00e8tres.</p> <p></p> </li> <li> <p>S\u00e9lectionnez Heure et langue.</p> <p></p> </li> <li> <p>S\u00e9lectionnez Langue. Utilisez le menu d\u00e9roulant sous l'en-t\u00eate Langue d\u2019affichage de Windows pour choisir la langue d\u00e9sir\u00e9e.  </p> <p></p> </li> <li> <p>La zone de langue d'affichage de Windows doit maintenant comprendre la langue choisie. Pour \u00eatre en mesure d'appliquer la nouvelle langue, d\u00e9connectez-vous de la session Windows actuelle, puis reconnectez-vous.</p> </li> </ol>"},{"location":"Langue/#serveur-ubuntu","title":"Serveur Ubuntu","text":"<p>Si vous utilisez l'application X2GO pour acc\u00e9der \u00e0 l'interface graphique de votre machine Ubuntu, notez que par d\u00e9faut la session est disponible en anglais uniquement. Il sera donc necessaire d'installer des modules supplementaires de langue manuellement.</p>"},{"location":"Langue/#azure-apprentissage-automatique","title":"Azure Apprentissage automatique","text":"<p>Pour modifier les param\u00e8tres de langue dans l\u2019espace de travail d'apprentissage automatique Microsoft Azure, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale.</p> </li> <li> <p>Sous Langue et formats, utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9.</p> </li> <li> <p>Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional.</p> <p></p> </li> </ol>"},{"location":"Langue/#azure-apprentissage-automatique-jupyter-lab","title":"Azure Apprentissage automatique - Jupyter Lab","text":"<ol> <li> <p>Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML:     <code>sh     pip install jupyterlab==3</code></p> </li> <li> <p>Red\u00e9marrez l'instance de calcul</p> </li> <li> <p>Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML:     <code>sh     pip install git+https://github.com/StatCan/jupyterlab-language-pack-fr_FR</code></p> </li> <li> <p>Dans JupyterLab, s\u00e9lectionnez Param\u00e8tres - Langue - Fran\u00e7ais</p> </li> </ol>"},{"location":"Langue/#slack","title":"Slack","text":"<p>Pour modifier les param\u00e8tres de langue dans l\u2019application Slack, voici les \u00e9tapes \u00e0 suivre: 1. Cliquez sur l\u2019ic\u00f4ne de profil dans l'en-t\u00eate de la page principale.</p> <ol> <li> <p>Cliquez sur Pr\u00e9f\u00e9rences.</p> <p></p> </li> <li> <p>S\u00e9lectionnez l\u2019onglet Langue et r\u00e9gion.</p> </li> <li> <p>Sous Langue, utilisez le menu d\u00e9roulant pour choisir la langue pr\u00e9f\u00e9r\u00e9e.  </p> <p></p> </li> <li> <p>Fermez la fen\u00eatre Pr\u00e9f\u00e9rences.</p> </li> </ol>"},{"location":"Langue/#explorateur-de-stockage-microsoft-azure","title":"Explorateur de stockage Microsoft Azure","text":"<p>Par d\u00e9faut, cette application d\u00e9termine la langue d'utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur.</p> <p>Pour modifier les param\u00e8tres de langue dans l\u2019Explorateur de stockage Microsoft Azure, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Cliquez sur Modifier.</p> </li> <li> <p>Cliquez sur Param\u00e8tres.</p> <p></p> </li> <li> <p>Dans la page des param\u00e8tres, s\u00e9lectionnez Application. Sous Param\u00e8tres r\u00e9gionaux, utilisez le menu d\u00e9roulant pour choisir votre langue pr\u00e9f\u00e9r\u00e9e.</p> <p></p> </li> <li> <p>Pour appliquer la nouvelle langue, fermez puis relancer l\u2019application.</p> </li> </ol>"},{"location":"Langue/#power-bi","title":"Power BI","text":"<p>Pour obtenir plus de renseignements, vous pouvez consulter l\u2019article \u00ab\u00a0Langues et pays/r\u00e9gions pris en charge pour Power BI \u00bb.</p>"},{"location":"Langue/#service-power-bi","title":"Service Power BI","text":"<p>Par d\u00e9faut, le service Power BI d\u00e9termine la langue d\u2019utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur. Les \u00e9tapes \u00e0 suivre pour afficher et modifier ces pr\u00e9f\u00e9rences peuvent varier selon votre syst\u00e8me d\u2019exploitation et votre fureteur.</p> <p>Pour changer la langue du menu dans le service Power BI, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Dans le service Power BI, cliquez sur l\u2019ic\u00f4ne Param\u00e8tres, puis s\u00e9lectionnez Param\u00e8tres.</p> <p> </p> </li> <li> <p>Sous l\u2019onglet G\u00e9n\u00e9ral, s\u00e9lectionnez Langue.</p> <p> </p> </li> <li> <p>S\u00e9lectionnez votre langue pr\u00e9f\u00e9r\u00e9e, puis cliquez sur Appliquer.</p> </li> </ol> <p>Pour obtenir plus de renseignements, consultez l\u2019article \u00ab\u00a0Langues disponibles pour le service Power BI \u00bb.</p>"},{"location":"Langue/#power-bi-desktop","title":"Power BI Desktop","text":"<p>Par d\u00e9faut, - la Langue de l'application est fond\u00e9e sur la Langue de Windows - la Langue du mod\u00e8le est fond\u00e9e sur  la Langue de l'application - les \u00e9tapes de la requ\u00eate sont fond\u00e9es sur  la Langue de l'application</p> <p>Il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States).</p> <p>La langue du mod\u00e8le s'applique seulement au moment de la cr\u00e9ation du rapport et ne peut pas \u00eatre chang\u00e9e dans les rapports existants. Ainsi, il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States), sauf si vous avez besoin d\u2019utiliser une autre langue pour le mod\u00e8le de rapport. Les comparaisons de cha\u00eene de caract\u00e8res et les champs de date internes sont affect\u00e9s par cette configuration.</p> <p>Pour changer la langue du menu et la langue du mod\u00e8le dans Power BI Desktop, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Ouvrez le menu Options.</p> <p> </p> </li> <li> <p>Sous GLOBAL, cliquez sur Param\u00e8tres r\u00e9gionaux, et fixez la langue de l\u2019application et la langue du mod\u00e8le \u00e0 la langue souhait\u00e9e.</p> <p> </p> </li> </ol> <p>NOTE: La langue d'importation des donn\u00e9es est fix\u00e9e s\u00e9par\u00e9ment dans les  Param\u00e8tres r\u00e9gionaux de la section FICHIER ACTIF. Vous devez la changer seulement si vous importez des fichiers de donn\u00e9es comportant des nombres ou des dates suivant des param\u00e8tres r\u00e9gionaux pr\u00e9cis (p. ex. le format de date JJ/MM/AAAA de l\u2019anglais du Canada et le format de date MM/JJ/AAAA de l\u2019anglais des \u00c9tats-Unis).</p>"},{"location":"Langue/#azure-databricks","title":"Azure Databricks","text":"<p>Pour modifier les param\u00e8tres de langue dans Databricks:</p> <ol> <li> <p>S\u00e9lectionnez le menu d\u00e9roulant de l'utilisateur en haut \u00e0 droite et s\u00e9lectionnez Param\u00e8tres utilisateur.</p> <p></p> </li> <li> <p>Sur la page, s\u00e9lectionnez Param\u00e8tres de langue.</p> <p></p> </li> <li> <p>Cliquez sur la liste d\u00e9roulante et s\u00e9lectionnez la langue de votre choix.</p> </li> </ol>"},{"location":"Langue/#azure-data-factory","title":"Azure Data Factory","text":"<p>Pour configurer la langue, voici les \u00e9tapes \u00e0 suivre:</p> <ol> <li> <p>Dans Azure Data Factory, s\u00e9lectionnez Param\u00e8tres.</p> </li> <li> <p>S\u00e9lectionnez Fran\u00e7ais. </p> </li> <li> <p>Cliquez sur Appliquer.</p> <p> </p> </li> </ol>"},{"location":"Langue/#jupyterlab","title":"JupyterLab","text":"<p>Pour modifier les param\u00e8tres de langue dans JupyterLab:</p> <ol> <li> <p>Dans JupyterLab, ouvrez une console ou un terminal. </p> </li> <li> <p>Installez l'exemple de langue de votre choix \u00e0 l'aide de pip. </p> <p>Exemple: <code>python pip install jupyterlab-language-pack-fr-FR</code></p> </li> <li> <p>Sous settings, mettez en surbrillance Language et s\u00e9lectionnez la langue que vous avez install\u00e9e.</p> <p></p> </li> <li> <p>Cliquez sur OK pour rafra\u00eechir la page, vous verrez le changement de langue.</p> </li> </ol> <p>Pour plus d'informations sur le changement de langue:</p> <p>https://jupyterlab.readthedocs.io/en/stable/user/language.html#changing-the-display-language</p>"},{"location":"Langue/#visual-studio-code-vscode","title":"Visual Studio Code (VSCode)","text":"<p>Pour changer la langue d'affichage dans VSCode:</p> <ol> <li> <p>Ouvrez VSCode et ouvrez la palette de commandes (Ctrl+Maj+P).</p> </li> <li> <p>Dans la palette de commandes, tapez \"affichage\" et s\u00e9lectionnez installer des langues suppl\u00e9mentaires </p> <p></p> <p>Remarque : si vous avez d\u00e9j\u00e0 install\u00e9 la langue souhait\u00e9e, vous pouvez la s\u00e9lectionner dans la liste d\u00e9roulante. </p> </li> <li> <p>Sur le c\u00f4t\u00e9 gauche de VSCode, les langues qui peuvent \u00eatre install\u00e9es appara\u00eetront, s\u00e9lectionnez la langue de votre choix. </p> </li> <li> <p>Une fen\u00eatre contextuelle peut appara\u00eetre en bas \u00e0 droite de l'\u00e9cran dans laquelle vous pouvez changer la langue et red\u00e9marrera VSCode. </p> <p></p> </li> </ol>"},{"location":"Langue/#visual-studio","title":"Visual Studio","text":"<p>Si vous avez d\u00e9j\u00e0 install\u00e9 des packages de langue dans Visual Studio:</p> <ol> <li> <p>Dans la barre sup\u00e9rieure, s\u00e9lectionnez Outils puis Options. </p> <p></p> </li> <li> <p>Dans le menu, sous l'onglet Environnement, s\u00e9lectionnez Param\u00e8tres internationaux </p> <p></p> </li> <li> <p>Dans le menu d\u00e9roulant sous Langue, s\u00e9lectionnez la langue de votre choix. </p> </li> </ol> <p>Si vous n'avez pas install\u00e9 d'autres packages de langue dans Visual Studio :</p> <ol> <li> <p>Sur votre ordinateur, ouvrez le programme d'installation de Visual Studio.</p> </li> <li> <p>Dans le programme d'installation, s\u00e9lectionnez le bouton Modifier. </p> <p></p> </li> <li> <p>Dans la nouvelle fen\u00eatre, s\u00e9lectionnez Packs linguistiques. S\u00e9lectionnez toutes les langues que vous souhaitez ajouter, puis s\u00e9lectionnez modifier. </p> <p></p> </li> <li> <p>\u00c0 partir de l\u00e0, vous pouvez suivre les \u00e9tapes d'utilisation des packages de langue install\u00e9s dans Visual Studio. </p> </li> </ol> <p>Pour configurer RStudio dans une autre langue :</p> <ol> <li> <p>Ouvrez RStudio et ouvrez la console.</p> </li> <li> <p>Dans la console, tapez \"Sys.getenv(LANGUAGE = \"fr\") Note : \"fr\" est pour la langue fran\u00e7aise, pour une liste d'autres langues qui peuvent \u00eatre utilis\u00e9es :</p> </li> </ol> <p>https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes</p> <ol> <li>Pour le tester, vous pouvez taper \"2+x\" et cela devrait donner une erreur dans la langue saisie.</li> </ol>"},{"location":"Langue/#fureteurs-web","title":"Fureteurs Web","text":"<ul> <li>Chrome</li> <li>Safari</li> <li>Edge</li> <li>Firefox</li> <li>Opera (en anglais seulement)</li> </ul>"},{"location":"MachinesVirtuelle/","title":"MachinesVirtuelle","text":""},{"location":"MachinesVirtuelle/#trouvez-votre-laboratoire-devtest","title":"Trouvez votre laboratoire\u00a0DevTest","text":"<ol> <li> <p>Dans le portail Azure, cliquez sur le laboratoire\u00a0DevTest dans le tableau de bord personnalis\u00e9 de votre projet. </p> </li> <li> <p>S\u00e9lectionnez le DevTest Lab qui a \u00e9t\u00e9 attribu\u00e9.</p> </li> </ol>"},{"location":"MachinesVirtuelle/#creez-votre-machine-virtuelle","title":"Cr\u00e9ez votre machine virtuelle","text":"<p>Note\u00a0: Dans certains cas, une machine virtuelle aura \u00e9t\u00e9 cr\u00e9\u00e9e au pr\u00e9alable pour vous et vous n'aurez pas l'autorisation d'en cr\u00e9er une. Si vous devez apporter des changements \u00e0 votre machine virtuelle, consultez la FAQ.</p> <ol> <li> <p>\u00c0 partir de la page Vue d'ensemble du laboratoire\u00a0DevTest, cliquez sur le bouton + Ajouter.</p> </li> <li> <p>Choisissez une base appropri\u00e9e pour votre machine virtuelle (p.\u00a0ex. Data Science Virtual Machine - Windows Server\u00a02019). Pour en savoir plus sur le logiciel inclus dans l'image de machine virtuelle pour la science des donn\u00e9es (Data Science Virtual Machine), veuillez cliquer ici.</p> </li> <li> <p>Entrez un nom pour votre machine virtuelle ainsi qu'un nom d'utilisateur et un mot de passe que vous utiliserez pour vous connecter \u00e0 la machine virtuelle. D\u00e9cochez les cases Utiliser un secret enregistr\u00e9 et Enregistrer comme mot de passe par d\u00e9faut.</p> </li> <li> <p>Vous pouvez cliquer sur le lien Changer la taille pour modifier la taille de votre machine virtuelle si vous le souhaitez. Laissez les autres champs par d\u00e9faut et cliquez sur le bouton Cr\u00e9er.</p> <p></p> </li> </ol>"},{"location":"MachinesVirtuelle/#trouvez-votre-machine-virtuelle","title":"Trouvez votre machine virtuelle","text":"<ol> <li>Faites d\u00e9filer la page Vue d'ensemble du laboratoire\u00a0DevTest jusqu'\u00e0 ce que vous voyiez votre machine virtuelle sous Mes machines virtuelles. Cliquez sur votre machine virtuelle pour en afficher la Vue d'ensemble.</li> </ol>"},{"location":"MachinesVirtuelle/#demarrez-votre-machine-virtuelle","title":"D\u00e9marrez votre machine virtuelle","text":"<ol> <li> <p>\u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton D\u00e9marrer.</p> <p> </p> </li> <li> <p>Le demarrage de la machine virtuelle prendra quelques minutes. Surveillez l'avancement du d\u00e9marrage en cliquant sur l'ic\u00f4ne\u00a0Notifications dans le coin sup\u00e9rieur droit de la fen\u00eatre.</p> <p></p> </li> </ol>"},{"location":"MachinesVirtuelle/#connectez-vous-a-votre-machine-virtuelle","title":"Connectez-vous \u00e0 votre machine virtuelle","text":"<ol> <li> <p>\u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur Connexion du navigateur (si vous ne voyez pas ce bouton, vous devrez peut-\u00eatre cliquer sur le bouton Connecter, puis choisir Bastion dans le menu d\u00e9roulant).</p> <p></p> </li> <li> <p>Veuillez \u00e0 cocher la case Ouvrir dans une nouvelle fen\u00eatre, puis entrez le nom d'utilisateur et le mot de passe que vous avez utilis\u00e9 au moment de cr\u00e9er votre machine virtuelle, et cliquez sur le bouton Connecter. Votre machine virtuelle devrait s'ouvrir dans un nouvel onglet du navigateur.</p> <p>Note : Par d\u00e9faut, la machine virtuelle Ubuntu s'ouvre en mode Serveur Terminal. Vous pouvez acceder \u00e0 l\u2019interface graphique de votre machine Ubuntu \u00e0 l'aide de l'application X2Go, \u00e0 partir de votre machine Windows.</p> <p>Note : Apr\u00e8s avoir tent\u00e9 de vous connecter pour la premi\u00e8re fois, une erreur peut appara\u00eetre indiquant qu'un bloqueur de fen\u00eatres contextuelles emp\u00eache l'ouverture d'une nouvelle fen\u00eatre. Pour le d\u00e9sactiver, une ic\u00f4ne appara\u00eetra dans la barre de recherche du navigateur, s\u00e9lectionnez le bouton et cliquez sur toujours autoriser.</p> <p></p> </li> </ol>"},{"location":"MachinesVirtuelle/#arretez-votre-machine-virtuelle","title":"Arr\u00eatez votre machine virtuelle","text":"<p>Les machines virtuelles entra\u00eenent des co\u00fbts uniquement quand elles sont en marche. Pour \u00e9viter les d\u00e9penses inutiles, vous devez arr\u00eater votre machine virtuelle lorsque vous ne l'utilisez pas. 1. \u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton Arr\u00eater.</p> <p></p>"},{"location":"PostgreSQL/","title":"Base de donn\u00e9es Azure Postgres","text":"<p>English</p>"},{"location":"PostgreSQL/#acces-a-une-base-de-donnees-azure-postgresql","title":"Acc\u00e8s \u00e0 une base de donn\u00e9es Azure PostgreSQL","text":""},{"location":"PostgreSQL/#azure-data-factory","title":"Azure Data Factory","text":"<p>On peut cr\u00e9er un service li\u00e9 dans Azure Data Factory. Le nom d'utilisateur est votre compte cloud ou groupe AD si l'acc\u00e8s a \u00e9t\u00e9 donn\u00e9 \u00e0 un groupe auquel vous appartenez, suivi du nom du serveur. Le mot de passe est un jeton d'acc\u00e8s d'Azure AD tel que d\u00e9crit ci-dessous au point 6 de la section pgAdmin</p> <p> ou </p> <p>Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com si vous avez besoin d'aide.</p>"},{"location":"PostgreSQL/#machine-virtuelle","title":"Machine virtuelle","text":"<p>Vous pouvez vous connecter \u00e0 une base de donn\u00e9es Azure PostgreSQL \u00e0 partir de votre machine virtuelle en infonuagique, en utilisant une application telle que:  1. pgAdmin 2. Azure Data Studio 3. Visual Studio Code</p>"},{"location":"PostgreSQL/#prerequis","title":"Pr\u00e9requis","text":"<ol> <li>Une machine virtuelle dans l'EAC. Voir la page Machines Virtuelles pour plus d'informations.</li> <li>pgAdmin ou un autre outil tel que Azure Data Studio and Visual Studio Code. Ces deux derniers sont disponibles par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine.</li> </ol>"},{"location":"PostgreSQL/#pgadmin","title":"pgAdmin","text":"<p>Ceci est l'un des outils les plus connus pour la gestion et l'administration de base de donn\u00e9es Azure PostgreSQL.</p> <ol> <li> <p>Dans votre machine virtuelle installez pgAdmin disponible depuis https://www.pgadmin.org/download/</p> </li> <li> <p>Connectez-vous \u00e0 votre machine virtuelle dans l'EAC et lancez pgAdmin.</p> <p></p> </li> <li> <p>Avec le bouton droit de la souris, ajouter le serveur auquel vous devez vous connecter dans le coin sup\u00e9rieur gauche.</p> <p></p> </li> <li> <p>Dans l'onglet General, entrez un nom pour le server. Vous pouvez entrer le nom de votre serveur PostgreSQL     Dans l'onglet Connection, entrez le nom complet de votre serveur PostgreSQL puis entrez votre compte Cloud comme nom d'utilisateur suivi par le nom du serveur     ou le nom du groupe AD auquel vous appartenez suivi par le nom du serveur si l'acc\u00e8s au serveur a \u00e9t\u00e9 accord\u00e9 \u00e0 ce groupe.</p> <p></p> </li> <li> <p>Vous pouvez maintenant  voir le nouveau serveur que vous venez d'ajouter dans la liste des serveurs.      Cliquez dessus pour vous connecter et il vous sera demand\u00e9 d'entrer un mot de passe</p> <p></p> </li> <li> <p>Le mot de passe que vous devez entrer est un jeton d'acc\u00e8s d'Azure AD qui sera g\u00e9n\u00e9r\u00e9 pour un usager authentifi\u00e9      \u00c0 l'aide de PowerShell, vous pouvez g\u00e9n\u00e9rer le jeton d'acc\u00e8s en entrant la commande suivante</p> <p>az account get-access-token --resource https://ossrdbms-aad.database.windows.net</p> <p>Le r\u00e9sultat se pr\u00e9sente comme suit o\u00f9 vous devez copier la valeur de accessToken et vous en servir comme mot de passe dans pgAdmin</p> <p></p> </li> </ol>"},{"location":"PostgreSQL/#azure-data-studio","title":"Azure Data Studio","text":"<ol> <li>Connectez-vous \u00e0 votre machine virtuelle dans l'EAC et lancez Azure Data Studio.</li> </ol> <ol> <li>Les d\u00e9tails de connexion se pr\u00e9sentent comme suit,    Avec le nom d'utilisateur qui peut \u00eatre votre compte Cloud suivi du nom du serveur:</li> </ol> <p>firstname.lastname@cloud.statcan.ca@servername.postgres.database.azure.com    ou    firstname.lastname@cloud.statcan.ca@servername</p> <p>Si l'acc\u00e8s au serveur a \u00e9t\u00e9 accord\u00e9 \u00e0 un groupe AD auquel vous appartenez,</p> <p>AD-Group@servername.postgres.database.azure.com    ou    AD-Group@servername</p> <p></p>"},{"location":"R-Shiny/","title":"R-Shiny","text":"<p>Ce document d\u00e9crit comment acc\u00e9der R-Shiny \u00e0 partir de l'application Rstudio.</p>"},{"location":"R-Shiny/#commencer","title":"Commencer","text":"<p>Afin d'utiliser R-Shiny, s.v.p. envoyer un message\u00a0Slack \u00e0 l'\u00e9quipe de l'EAC pour activer RStudio dans votre cluster Databricks.</p> <p>Avertissement : Les clusters R-Shiny s'\u00e9teignent tous les jours \u00e0 19h. Pour r\u00e9duire vos co\u00fbts, veuillez arr\u00eater vos clusters R-Shiny lorsque vous ne les utilisez pas.</p>"},{"location":"R-Shiny/#acces-a-r-shiny","title":"Acc\u00e8s \u00e0 R-Shiny","text":"<ol> <li> <p>\u00c0 partir du portail Azure, lancer l'espace de travail Databricks qui vous a \u00e9t\u00e9 cr\u00e9\u00e9.</p> </li> <li> <p>\u00c0 partir de l'espace de travail Databricks, cliquez sur Cluster.</p> <p></p> </li> <li> <p>\u00c0 partir de la liste de clusters disponibles, selectionnez le cluster sur lequel RStudio a \u00e9t\u00e9 install\u00e9.</p> <p></p> <p>Note: Le cluster doit \u00eatre active pour acc\u00e9der \u00e0 l'application RStudio. Consulter la section Databricks pour plus de d\u00e9tails \u00e0 propos du d\u00e9marrage d'un cluster.</p> </li> <li> <p>Selectionnez l'onglet Apps.</p> <p></p> </li> <li> <p>Cliquez sur Set up RStudio.</p> <p> </p> </li> <li> <p>Un mot de passe \u00e0 usage unique est g\u00e9n\u00e9r\u00e9 pour vous, cliquez sur show pour l'afficher et le copier.</p> <p></p> </li> <li> <p>Cliquez sur Open RStudio.</p> <p></p> </li> <li> <p>Une nouvelle fen\u00eatre s'ouvre, entrez le nom d'utilisateur et le mot de passe fournis (\u00c9tape 6) dans le formulaire de connexion afin de d\u00e9marrer RStudio.</p> <p></p> </li> <li> <p>\u00c0 partir de l'interface RStudio, entrez la commande library(shiny) dans la console afin d'importer la librarie Shiny.</p> <p></p> </li> </ol>"},{"location":"R-Shiny/#exemple-dune-application-r-shiny","title":"Exemple d'une application R-Shiny","text":"<p>Vous pouvez utiliser l'exemple Hello Shiny pour explorer la structure d'une application Shiny.</p> <ol> <li> <p>Lancer l'application \u00e0 partir de votre session RStudio en entrant les commandes suivantes:     <code>library(shiny)     runExample(\"01_hello\")</code></p> </li> <li> <p>Votre application devrait correspondre \u00e0 l'image ci-dessous.</p> <p></p> </li> </ol>"},{"location":"R-Shiny/#acces-aux-fichiers-a-partir-du-lac-de-donnees","title":"Acc\u00e8s aux fichiers \u00e0 partir du lac de donn\u00e9es","text":"<p>Par d\u00e9faut, le r\u00e9pertoire de travail dans RStudio se trouve sur le noeud du pilote du cluster Databricks. Pour conserver votre travail, vous devrez utiliser DBFS.</p> <ol> <li> <p>Pour avoir acc\u00e8s au DBFS dans l'explorateur de fichiers, cliquez sur le bouton ... \u00e0 droite et entrez /dbfs/mnt/.</p> <p></p> </li> <li> <p>Le lac de donn\u00e9es sera disponible et vous pourrez y acc\u00e9der et stocker vos fichiers. Lorsque votre cluster s'\u00e9teint \u00e0 la fin de votre session, votre travail reste disponible \u00e0 votre retour.</p> </li> </ol> <p>NOTE: Voici des exemples de code pour acc\u00e9der \u00e0 vos fichiers \u00e0 partir du lac de donn\u00e9es.</p> <pre><code>library(SparkR)\nsparkR.session()\ntestData = as.data.frame(read.df(\"/mnt/le chemin du fichier\", source = \"l'extension du fichier\", header=\"true\", inferSchema = \"true\"))\nstr(testData)\n</code></pre> <pre><code>setwd(\"/dbfs/mnt/le chemin du fichier\")\ntestData = read.csv(\"le nom du fichier\")\nstr(testData)\n</code></pre>"},{"location":"SeConnecter/","title":"Se connecter","text":""},{"location":"SeConnecter/#prerequis","title":"Pr\u00e9requis","text":"<ul> <li>Un compte de l'infonuagique StatCan ou un compte d'utilisateur invit\u00e9. L'acc\u00e8s avec un compte du r\u00e9seau de StatCan est pr\u00e9sentement seulement disponible pour le service Power BI, mais pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC).</li> </ul>"},{"location":"SeConnecter/#notes","title":"Notes","text":"<p>Il est recommand\u00e9 d'utiliser Chrome, Chromium or Edge (non Internet Explorer) pour acc\u00e8der au portail Azure, les services Azure ou le service Power BI. Lors de la connexion aux services infonuagiques Azure, vous pourrez soit acc\u00e9der avec votre:</p> <ul> <li> <p>Compte infonuagique de StatCan (c.-\u00e0-d. prenom.nomfamille@cloud.statcan.ca) ou</p> </li> <li> <p>Informations d\u2019identification d'autres d\u00e9partements ou chercheurs (c.-\u00e0-d. prenom.nom@dept-d\u00e9pt.gc.ca or nom@gov.prov.ca) ou</p> </li> <li> <p>Compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) pour les employ\u00e9s de StatCan utilisant le service Power BI seulement.</p> </li> </ul> <p>Suivre les instructions pour votre type de compte afin de compl\u00e9ter votre connexion.</p>"},{"location":"SeConnecter/#compte-infonuagique-de-statcan-prenomnomfamillecloudstatcanca","title":"Compte infonuagique de StatCan (prenom.nomfamille@cloud.statcan.ca)","text":"<p>S'applique \u00e0 tous les services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.)</p> <ol> <li> <p>En utilisant Chrome, Chromium ou Edge, ouvrir soit:</p> <ul> <li> <p>Le tableau de bord Azure de l'Environnement d'Analyse Collaborative</p> </li> <li> <p>Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI </p> </li> </ul> </li> <li> <p>En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION.  </p> <p> </p> </li> <li> <p>On vous demandera ensuite soit d\u2019entrer ou de choisir un compte:</p> <ul> <li> <p>La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous.   </p> <p> </p> </li> <li> <p>Entrez votre compte infonuagique (prenom.nomfamille@cloud.statcan.ca), et cliquez sur Suivant.  </p> </li> <li> <p>Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte cloud.statcan.ca.  </p> <p> </p> </li> </ul> </li> <li> <p>On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique.  Une fois entr\u00e9, cliquez sur Connexion.  </p> <p> </p> </li> <li> <p>Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. </p> <p> </p> </li> </ol>"},{"location":"SeConnecter/#informations-didentification-dautres-departements-ou-chercheurs","title":"Informations d\u2019identification d'autres d\u00e9partements ou chercheurs","text":"<p>S'applique \u00e0 la majorit\u00e9 des services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.)</p> <ol> <li> <p>En utilisant Chrome, Chromium ou Edge, ouvrir soit:</p> <ul> <li> <p>Le tableau de bord Azure de l'Environnement d'Analyse Collaborative</p> </li> <li> <p>Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI </p> </li> <li> <p>Azure Databricks </p> </li> <li> <p>Azure Data Factory </p> </li> </ul> </li> <li> <p>En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION.  </p> <p> </p> </li> <li> <p>On vous demandera ensuite soit d\u2019entrer ou de choisir un compte :  </p> <ul> <li> <p>La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous.  </p> <p> </p> </li> <li> <p>Connectez-vous avec vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca), et cliquez sur Suivant.  </p> </li> <li> <p>Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca).  </p> <p> </p> </li> </ul> </li> <li> <p>On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique.  Une fois entr\u00e9, cliquez sur Connexion.  </p> <p> </p> <ul> <li> <p>Si votre adresse \u00e9lectronique officielle ne prend pas en charge ce type de connexion, vous recevrez automatiquement par courrier \u00e9lectronique un code \u00e0 saisir en lieu et place d'un mot de passe, puis vous cliquerez sur Connexion.</p> <p> </p> </li> <li> <p>Le courriel que vous recevez ressemblera \u00e0 ce qui suit. Si vous ne le recevez pas, v\u00e9rifiez qu'il n'a pas \u00e9t\u00e9 envoy\u00e9 dans votre dossier Spam ou Junk. </p> <p> </p> </li> </ul> </li> <li> <p>Accepter les autorisations de r\u00e9vision (consentement pour la premi\u00e8re fois uniquement).  </p> <p> </p> </li> <li> <p>Vous recevrez alors le message suivant. Attendez jusqu\u2019\u00e0 la fin.  </p> <p> </p> </li> <li> <p>Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte de l\u2019infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. </p> <p> </p> <p> </p> </li> </ol>"},{"location":"SeConnecter/#compte-du-reseau-de-statcan-prenomnomfamillestatcangcca","title":"Compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca)","text":"<p>S'applique seulement au service Power BI pour les employ\u00e9s de Statistique Canada. Pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC).</p> <p>Veuillez noter que l\u2019\u00e9tape 5 (mot de passe d\u2019Internet) ci-dessous peut arriver \u00e0 n\u2019importe quel moment.</p> <ol> <li> <p>\u00c0 partir du r\u00e9seau B ou du OZ, et en utilisant Chrome, Chromium ou Edge, ouvrir soit:    </p> <ul> <li>Le lien URL de l\u2019application Power BI (si fourni), ou  </li> <li>https://powerbi.microsoft.com/fr-fr/landing/signin/  </li> </ul> </li> <li> <p>Vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION.   </p> <p> </p> </li> <li> <p>On vous demandera ensuite soit d\u2019entrer soit de choisir un compte:</p> <ul> <li> <p>La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous.   </p> <p> </p> </li> <li> <p>Entrez votre compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca), et cliquez sur Suivant. </p> </li> <li> <p>Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte statcan.gc.ca. </p> <p> </p> </li> </ul> </li> <li> <p>Vous allez ensuite recevoir le message de Microsoft \u201cVous allez \u00eatre redirig\u00e9 vers la page de connexion de votre organisation\u201c. </p> </li> <li> <p>Vous serez peut-\u00eatre amen\u00e9 \u00e0 entrer votre nom d\u2019utilisateur et votre mot de passe d\u2019Internet comme montr\u00e9 ci-dessous. Une fois entr\u00e9s, cliquez sur Ouvrir une session.   </p> <p> </p> </li> <li> <p>On vous demandera ensuite de vous connecter \u00e0 votre compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) et d\u2019entrer votre mot de passe du r\u00e9seau A. Une fois entr\u00e9s, cliquez sur Ouvrir une session.    </p> <p> </p> </li> <li> <p>Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte du r\u00e9seau de StatCan. </p> <p>Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. </p> <p> </p> </li> </ol>"},{"location":"SeConnecter/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Documentation du Portail Azure</li> </ul>"},{"location":"TableauxDeBord/","title":"Tableaux de bord","text":"<p>Les tableaux de bord affichent vos ressources infonuagiques dans le portail Azure de fa\u00e7on pr\u00e9cise et organis\u00e9e. Ils servent d'espace de travail o\u00f9 vous pouvez rapidement lancer des t\u00e2ches pour les op\u00e9rations quotidiennes et surveiller les ressources. Par exemple, vous pouvez cr\u00e9er des tableaux de bord personnalis\u00e9s en fonction des projets, des t\u00e2ches ou des r\u00f4les des utilisateurs.</p> <p>Le portail Azure fournit un tableau de bord par d\u00e9faut comme point de d\u00e9part. Vous pouvez modifier ce dernier, cr\u00e9er et personnaliser des tableaux de bord suppl\u00e9mentaires, ainsi qu'en publier et en partager avec d'autres utilisateurs.</p>"},{"location":"TableauxDeBord/#acceder-au-tableau-de-bord-de-lenvironnement-danalyse-collaborative","title":"Acc\u00e9der au tableau de bord de l'Environnement d'analyse collaborative","text":"<ol> <li> <p>Dans le menu du portail Azure, s\u00e9lectionnez Tableau de bord. Votre affichage par d\u00e9faut pourrait d\u00e9j\u00e0 \u00eatre r\u00e9gl\u00e9 au tableau de bord.</p> <p></p> </li> <li> <p>S\u00e9lectionnez la fl\u00e8che \u00e0 c\u00f4t\u00e9 du nom du tableau de bord.</p> </li> <li> <p>S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste affich\u00e9e. Si ce tableau de bord n'est pas dans la liste\u00a0:</p> <p>a.  S\u00e9lectionnez Parcourir tous les tableaux de bord.</p> <p></p> <p>b.  Dans le champ Type, s\u00e9lectionnez Tableaux de bord partag\u00e9s.</p> <p> </p> <p>c.  Assurez-vous que \u00ab\u00a0vdl\u00a0\u00bb se trouve parmi les abonnements s\u00e9lectionn\u00e9s. Vous pouvez aussi saisir du texte pour filtrer les tableaux de bord par leur nom.</p> <p>d.  S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste des tableaux de bord partag\u00e9s.</p> <p></p> </li> </ol>"},{"location":"TableauxDeBord/#acceder-a-databricks","title":"Acc\u00e9der \u00e0 Databricks","text":"<ol> <li> <p>Choisissez l'espace de travail Databricks auquel vous avez acc\u00e8s.     </p> </li> <li> <p>\u00c0 partir de la page d'accueil, vous pouvez cliquer sur le lien tel qu'indiqu\u00e9 ci-dessous     </p> </li> <li> <p>Important: Ne pas cliquer sur le bouton Lancer l'espace de travail, un message d'erreur pourrait s'afficher.</p> </li> </ol>"},{"location":"TableauxDeBord/#acceder-a-synapse","title":"Acc\u00e9der \u00e0 Synapse","text":"<p>Choisissez l'espace de travail Synapse auquel vous avez acc\u00e8s.     </p>"},{"location":"TableauxDeBord/#acceder-a-azure-machine-learning-ml","title":"Acc\u00e9der \u00e0 Azure Machine Learning (ML)","text":"<p>Choisissez l'espace de travail Azure Machine Learning auquel vous avez acc\u00e8s.     </p>"},{"location":"TableauxDeBord/#acceder-a-azure-storage","title":"Acc\u00e9der \u00e0 Azure Storage","text":"<p>Choisissez l'espace de stockage auquel vous avez acc\u00e8s.     </p>"},{"location":"TableauxDeBord/#acceder-au-devtest-labs","title":"Acc\u00e9der au DevTest Labs","text":"<p>Choisissez le DevTest Lab auquel vous avez acc\u00e8s.     </p>"},{"location":"TableauxDeBord/#documentation-microsoft","title":"Documentation Microsoft","text":"<ul> <li>Cr\u00e9er un tableau de bord dans le portail Azure</li> </ul>"},{"location":"VideoTest/","title":"VideoTest","text":""},{"location":"VideoTest/#video-test","title":"Vid\u00e9o Test","text":""},{"location":"VideoTest/#comment-se-connecter-au-portal-azure","title":"Comment se Connecter au Portal Azure","text":"Comment se Connecter au Portal Azure - Transcription   Allez sur portal.azure.com dans votre navigateur web. Entrez votre identifiant et votre mot de passe. Pour les utilisateurs internes de Statcan, utilisez votre compte cloud. Pour les utilisateurs externes, utilisez votre compte externe. La premi\u00e8re fois vous connectez, vous serez invit\u00e9 \u00e0 saisir vos questions de s\u00e9curit\u00e9. Pour l'authentification multifacteur, vous pouvez utiliser l'application Microsoft Authenticator sur votre t\u00e9l\u00e9phone portable."},{"location":"external/","title":"External","text":""},{"location":"external/#utilisateurs-externes-firstnamelastnameextstatcanca","title":"Utilisateurs Externes (firstname.lastname@ext.statcan.ca)","text":"<p>En tant qu'utilisateur externe, vous aurez besoin d'un compte pour utilisateur externe: firstname.lastname@ext.statcan.ca pour \u00eatre en mesure d'acc\u00e9der \u00e0 votre machine virtuelle et aux ressources dont vous avez besoin. Contactez-nous pour obtenir un compte utilisateur.</p>"}]}