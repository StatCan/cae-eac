{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"English Environnement d'analyse collaborative (EAC) L'Environnement d'Analyse Collaborative (EAC) fournit des services infonuagiques pour l'ingestion, la transformation, la pr\u00e9paration, l'exploration et le traitement des donn\u00e9es. Il comprend des outils d'analyse collaborative, des environnements d'apprentissage machine et des fonctions de visualisation des donn\u00e9es. Les environnements de bloc-notes et les machines virtuelles offrent des capacit\u00e9s d'analyse par l'entremise de divers logiciels statistiques comme R, Python et SAS. L'EAC exploite la plateforme Microsoft Azure comme service (PaaS) et les offres de logiciel-service (SaaS). Aper\u00e7u de l'environnement Nous mettons actuellement \u00e0 l'essai diff\u00e9rents cas d'utilisation de la plateforme. Chaque cas d'utilisation peut \u00eatre int\u00e9gr\u00e9 \u00e0 l'environnement principal . Sinon, il est possible de cr\u00e9er un nouvel environnement priv\u00e9 . Environnement principal (partag\u00e9) L'environnement est partag\u00e9 avec les utilisateurs de plusieurs cas d'utilisation. Lorsqu'ils ont acc\u00e8s \u00e0 cet environnement, les utilisateurs peuvent visualiser et partager les donn\u00e9es de ces cas d'utilisation. Environnement priv\u00e9 Un environnement priv\u00e9 configur\u00e9 sur demande qui permet l'acc\u00e8s aux fichiers de l'espace de travail seulement aux utilisateurs d\u00e9sign\u00e9s. Ingestion de donn\u00e9es Les donn\u00e9es int\u00e8grent la plateforme au moyen d'un compte de stockage externe. Une fois dans la plateforme, elles sont stock\u00e9es dans un compte de stockage interne (Data Lake). Les sources de donn\u00e9es accessibles au public peuvent \u00eatre ing\u00e9r\u00e9es directement \u00e0 l'aide de l'un des outils de la plateforme. Compte de stockage externe Les utilisateurs pourront acc\u00e9der au compte de stockage externe \u00e0 partir d'Internet et s'en servir pour t\u00e9l\u00e9verser et t\u00e9l\u00e9charger des donn\u00e9es \u00e0 partir ou vers l'environnement. Dans certains environnements priv\u00e9s, des restrictions ou des processus de contr\u00f4le suppl\u00e9mentaires peuvent \u00eatre mis en \u0153uvre pour le t\u00e9l\u00e9versement ou le t\u00e9l\u00e9chargement de donn\u00e9es. Compte de stockage interne (Data Lake) Les fichiers qui sont t\u00e9l\u00e9vers\u00e9s dans le compte de stockage externe sont automatiquement d\u00e9plac\u00e9s vers un compte de stockage interne. Ce compte de stockage interne se trouve dans un r\u00e9seau virtuel s\u00e9curis\u00e9 et est uniquement accessible \u00e0 partir des services des machines virtuelles de la plateforme. Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"En avant!"},{"location":"#environnement-danalyse-collaborative-eac","text":"L'Environnement d'Analyse Collaborative (EAC) fournit des services infonuagiques pour l'ingestion, la transformation, la pr\u00e9paration, l'exploration et le traitement des donn\u00e9es. Il comprend des outils d'analyse collaborative, des environnements d'apprentissage machine et des fonctions de visualisation des donn\u00e9es. Les environnements de bloc-notes et les machines virtuelles offrent des capacit\u00e9s d'analyse par l'entremise de divers logiciels statistiques comme R, Python et SAS. L'EAC exploite la plateforme Microsoft Azure comme service (PaaS) et les offres de logiciel-service (SaaS).","title":"Environnement d'analyse collaborative (EAC)"},{"location":"#apercu-de-lenvironnement","text":"Nous mettons actuellement \u00e0 l'essai diff\u00e9rents cas d'utilisation de la plateforme. Chaque cas d'utilisation peut \u00eatre int\u00e9gr\u00e9 \u00e0 l'environnement principal . Sinon, il est possible de cr\u00e9er un nouvel environnement priv\u00e9 .","title":"Aper\u00e7u de l'environnement"},{"location":"#environnement-principal-partage","text":"L'environnement est partag\u00e9 avec les utilisateurs de plusieurs cas d'utilisation. Lorsqu'ils ont acc\u00e8s \u00e0 cet environnement, les utilisateurs peuvent visualiser et partager les donn\u00e9es de ces cas d'utilisation.","title":"Environnement principal (partag\u00e9)"},{"location":"#environnement-prive","text":"Un environnement priv\u00e9 configur\u00e9 sur demande qui permet l'acc\u00e8s aux fichiers de l'espace de travail seulement aux utilisateurs d\u00e9sign\u00e9s.","title":"Environnement priv\u00e9"},{"location":"#ingestion-de-donnees","text":"Les donn\u00e9es int\u00e8grent la plateforme au moyen d'un compte de stockage externe. Une fois dans la plateforme, elles sont stock\u00e9es dans un compte de stockage interne (Data Lake). Les sources de donn\u00e9es accessibles au public peuvent \u00eatre ing\u00e9r\u00e9es directement \u00e0 l'aide de l'un des outils de la plateforme.","title":"Ingestion de donn\u00e9es"},{"location":"#compte-de-stockage-externe","text":"Les utilisateurs pourront acc\u00e9der au compte de stockage externe \u00e0 partir d'Internet et s'en servir pour t\u00e9l\u00e9verser et t\u00e9l\u00e9charger des donn\u00e9es \u00e0 partir ou vers l'environnement. Dans certains environnements priv\u00e9s, des restrictions ou des processus de contr\u00f4le suppl\u00e9mentaires peuvent \u00eatre mis en \u0153uvre pour le t\u00e9l\u00e9versement ou le t\u00e9l\u00e9chargement de donn\u00e9es.","title":"Compte de stockage externe"},{"location":"#compte-de-stockage-interne-data-lake","text":"Les fichiers qui sont t\u00e9l\u00e9vers\u00e9s dans le compte de stockage externe sont automatiquement d\u00e9plac\u00e9s vers un compte de stockage interne. Ce compte de stockage interne se trouve dans un r\u00e9seau virtuel s\u00e9curis\u00e9 et est uniquement accessible \u00e0 partir des services des machines virtuelles de la plateforme.","title":"Compte de stockage interne (Data\u00a0Lake)"},{"location":"#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"Access/","text":"English Demande d'acc\u00e8s Si vous avez d\u00e9j\u00e0 obtenu l'acc\u00e8s \u00e0 la plateforme, consultez les directives pour savoir comment ouvrir une session . Sinon, faites une demande d'acc\u00e8s par l'interm\u00e9diaire du canal slack . Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Demande d'acc\u00e8s"},{"location":"Access/#demande-dacces","text":"Si vous avez d\u00e9j\u00e0 obtenu l'acc\u00e8s \u00e0 la plateforme, consultez les directives pour savoir comment ouvrir une session . Sinon, faites une demande d'acc\u00e8s par l'interm\u00e9diaire du canal slack .","title":"Demande d'acc\u00e8s"},{"location":"Access/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"Aide/","text":"English Aide FAQ Voir la FAQ Canaux de Slack Abonnez-vous au canal de Slack suivant : https://cae-eac.slack.com. Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Aide/Contact"},{"location":"Aide/#aide","text":"","title":"Aide"},{"location":"Aide/#faq","text":"Voir la FAQ","title":"FAQ"},{"location":"Aide/#canaux-de-slack","text":"Abonnez-vous au canal de Slack suivant : https://cae-eac.slack.com.","title":"Canaux de Slack"},{"location":"Aide/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"AzureML/","text":"English Azure Machine Learning Nouveau: Veuillez acc\u00e9der \u00e0 Azure ML \u00e0 partir de votre machine virtuelle de l'EAC. Acc\u00e8s \u00e0 Azure Machine Learning Tableau de bord Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements.. 1. Cliquez sur le menu Tableau de bord du portail Azure. L\u2019affichage par d\u00e9faut pourrait d\u00e9j\u00e0 correspondre au tableau de bord. Sous Machine Learning (apprentissage automatique), s\u00e9lectionnez l\u2019espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous. Si l\u2019espace de travail que vous souhaitez ouvrir n\u2019est pas r\u00e9pertori\u00e9, cliquez sur Plus\u2026 pour acc\u00e9der \u00e0 la liste compl\u00e8te. Portail Azure Dans la bo\u00eete de recherche du portail Azure, cherchez Machine Learning . Vous devriez voir une liste des espaces de travail Machine Learning auxquels vous avez \u00e9t\u00e9 autoris\u00e9 \u00e0 acc\u00e9der. S\u00e9lectionnez l\u2019 espace de travail Machine Learning auquel vous souhaitez acc\u00e9der Adresse de Machine Learning Allez sur https://ml.azure.com/, connectez-vous avec les justificatifs d\u2019identit\u00e9 de votre compte d\u2019infonuagique, puis s\u00e9lectionnez l\u2019abonnement vdl et l\u2019 espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous. Pour commencer \u00c0 la page Vue d\u2019ensemble de l\u2019apprentissage automatique, cliquez sur Lancer le studio . Utilisez le menu d\u00e9roulant pour s\u00e9lectionner l\u2019abonnement vdl et l\u2019 espace de travail Machine Learning auquel vous souhaitez acc\u00e9der, puis cliquez sur D\u00e9marrer. Une fois dans votre espace de travail Machine Learning, vous pouvez former, d\u00e9ployer et g\u00e9rer des mod\u00e8les d\u2019apprentissage automatique, utiliser AutoML et utiliser des pipelines. Voir le Guide de d\u00e9marrage rapide pour obtenir de plus amples renseignements. Utilisation de la fonction ind\u00e9pendante notebook d\u2019Azure Machine Learning Exigences Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --> Instances de calcul . Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack . \u00c9tapes Sous Notebooks , cr\u00e9ez un nouveau notebook dans votre r\u00e9pertoire d\u2019utilisateur. Vous pouvez ensuite saisir le code \u00e0 ex\u00e9cuter. S\u00e9lectionnez l\u2019 instance de calcul qui vous est attribu\u00e9e. Cliquez sur le bouton D\u00e9marrer le calcul et ex\u00e9cuter toutes les cellules pour ex\u00e9cuter votre code. Utilisation de Databricks Connect comme ordinateur \u00e0 distance Avertissement : Veuillez noter que la configuration de Databricks Connect pr\u00e9sent\u00e9e ci-dessous est en cours de r\u00e9vision et qu\u2019elle changera probablement dans un avenir proche. Exigences Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --> Instances de calcul . Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack . \u00c9tapes Sous Notebooks , ouvrez Terminal . S\u00e9lectionnez votre instance de calcul dans le menu d\u00e9roulant \u00e0 c\u00f4t\u00e9 de Calculer . Ex\u00e9cutez le code \u00e0 partir de la page Databricks Connect Setup dans le terminal tout en suivant les directives pour continuer selon les besoins. Ce code installe Python 3.7 et met en place un nouveau noyau pour les notebooks d\u2019Azure Machine Learning. Lorsque vous y \u00eates invit\u00e9, entrez les valeurs suivantes pour configurer Databricks Connect : H\u00f4te : l\u2019URL de la page Vue d\u2019ensemble pour votre espace de travail Databricks Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks ID de grappe : la valeur indiqu\u00e9e sous Instance de calcul --> Options avanc\u00e9es--> \u00c9tiquettes dans votre espace de travail Databricks ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= Port : conserver la valeur existante Ex\u00e9cutez le code suivant dans le terminal pour tester la connexion avec Azure Databricks. databricks-connect test (databricks - test de connexion) Cr\u00e9ez un nouveau notebook avec l\u2019espace de travail Azure Machine Learning et s\u00e9lectionnez noyau Python 3. La version Python 3.7.9 devrait maintenant s\u2019afficher. Databricks Connect devrait maintenant \u00eatre configur\u00e9! Essayez le code \u00e9chantillon Databricks Connect dans le bloc-notes, en rempla\u00e7ant public-data/incoming/1test.txt par le chemin d\u2019acc\u00e8s \u00e0 un fichier dans votre conteneur de lac de donn\u00e9es. Demander un calcul Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal slack pour demander un calcul dans Azure Machine Learning. Vous recevrez l'erreur suivante si vous proc\u00e9dez \u00e0 la cr\u00e9ation par vous-m\u00eame: Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Azure Machine Learning"},{"location":"AzureML/#azure-machine-learning","text":"Nouveau: Veuillez acc\u00e9der \u00e0 Azure ML \u00e0 partir de votre machine virtuelle de l'EAC.","title":"Azure Machine Learning"},{"location":"AzureML/#acces-a-azure-machine-learning","text":"","title":"Acc\u00e8s \u00e0 Azure Machine Learning"},{"location":"AzureML/#tableau-de-bord","text":"Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements.. 1. Cliquez sur le menu Tableau de bord du portail Azure. L\u2019affichage par d\u00e9faut pourrait d\u00e9j\u00e0 correspondre au tableau de bord. Sous Machine Learning (apprentissage automatique), s\u00e9lectionnez l\u2019espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous. Si l\u2019espace de travail que vous souhaitez ouvrir n\u2019est pas r\u00e9pertori\u00e9, cliquez sur Plus\u2026 pour acc\u00e9der \u00e0 la liste compl\u00e8te.","title":"Tableau de bord"},{"location":"AzureML/#portail-azure","text":"Dans la bo\u00eete de recherche du portail Azure, cherchez Machine Learning . Vous devriez voir une liste des espaces de travail Machine Learning auxquels vous avez \u00e9t\u00e9 autoris\u00e9 \u00e0 acc\u00e9der. S\u00e9lectionnez l\u2019 espace de travail Machine Learning auquel vous souhaitez acc\u00e9der","title":"Portail Azure"},{"location":"AzureML/#adresse-de-machine-learning","text":"Allez sur https://ml.azure.com/, connectez-vous avec les justificatifs d\u2019identit\u00e9 de votre compte d\u2019infonuagique, puis s\u00e9lectionnez l\u2019abonnement vdl et l\u2019 espace de travail Machine Learning qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous.","title":"Adresse de Machine Learning"},{"location":"AzureML/#pour-commencer","text":"\u00c0 la page Vue d\u2019ensemble de l\u2019apprentissage automatique, cliquez sur Lancer le studio . Utilisez le menu d\u00e9roulant pour s\u00e9lectionner l\u2019abonnement vdl et l\u2019 espace de travail Machine Learning auquel vous souhaitez acc\u00e9der, puis cliquez sur D\u00e9marrer. Une fois dans votre espace de travail Machine Learning, vous pouvez former, d\u00e9ployer et g\u00e9rer des mod\u00e8les d\u2019apprentissage automatique, utiliser AutoML et utiliser des pipelines. Voir le Guide de d\u00e9marrage rapide pour obtenir de plus amples renseignements.","title":"Pour commencer"},{"location":"AzureML/#utilisation-de-la-fonction-independante-notebook-dazure-machine-learning","text":"","title":"Utilisation de la fonction ind\u00e9pendante notebook d\u2019Azure Machine Learning"},{"location":"AzureML/#exigences","text":"Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --> Instances de calcul . Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack .","title":"Exigences"},{"location":"AzureML/#etapes","text":"Sous Notebooks , cr\u00e9ez un nouveau notebook dans votre r\u00e9pertoire d\u2019utilisateur. Vous pouvez ensuite saisir le code \u00e0 ex\u00e9cuter. S\u00e9lectionnez l\u2019 instance de calcul qui vous est attribu\u00e9e. Cliquez sur le bouton D\u00e9marrer le calcul et ex\u00e9cuter toutes les cellules pour ex\u00e9cuter votre code.","title":"\u00c9tapes"},{"location":"AzureML/#utilisation-de-databricks-connect-comme-ordinateur-a-distance","text":"Avertissement : Veuillez noter que la configuration de Databricks Connect pr\u00e9sent\u00e9e ci-dessous est en cours de r\u00e9vision et qu\u2019elle changera probablement dans un avenir proche.","title":"Utilisation de Databricks Connect comme ordinateur \u00e0 distance"},{"location":"AzureML/#exigences_1","text":"Une instance de calcul dans Azure Machine Learning est n\u00e9cessaire. Vous devriez la voir sous Calculer --> Instances de calcul . Note : Si une instance de calcul n\u2019a pas \u00e9t\u00e9 cr\u00e9\u00e9e pour vous, veuillez communiquer avec l\u2019\u00e9quipe de soutien au moyen de Slack .","title":"Exigences"},{"location":"AzureML/#etapes_1","text":"Sous Notebooks , ouvrez Terminal . S\u00e9lectionnez votre instance de calcul dans le menu d\u00e9roulant \u00e0 c\u00f4t\u00e9 de Calculer . Ex\u00e9cutez le code \u00e0 partir de la page Databricks Connect Setup dans le terminal tout en suivant les directives pour continuer selon les besoins. Ce code installe Python 3.7 et met en place un nouveau noyau pour les notebooks d\u2019Azure Machine Learning. Lorsque vous y \u00eates invit\u00e9, entrez les valeurs suivantes pour configurer Databricks Connect : H\u00f4te : l\u2019URL de la page Vue d\u2019ensemble pour votre espace de travail Databricks Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks ID de grappe : la valeur indiqu\u00e9e sous Instance de calcul --> Options avanc\u00e9es--> \u00c9tiquettes dans votre espace de travail Databricks ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= Port : conserver la valeur existante Ex\u00e9cutez le code suivant dans le terminal pour tester la connexion avec Azure Databricks. databricks-connect test (databricks - test de connexion) Cr\u00e9ez un nouveau notebook avec l\u2019espace de travail Azure Machine Learning et s\u00e9lectionnez noyau Python 3. La version Python 3.7.9 devrait maintenant s\u2019afficher. Databricks Connect devrait maintenant \u00eatre configur\u00e9! Essayez le code \u00e9chantillon Databricks Connect dans le bloc-notes, en rempla\u00e7ant public-data/incoming/1test.txt par le chemin d\u2019acc\u00e8s \u00e0 un fichier dans votre conteneur de lac de donn\u00e9es.","title":"\u00c9tapes"},{"location":"AzureML/#demander-un-calcul","text":"Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal slack pour demander un calcul dans Azure Machine Learning. Vous recevrez l'erreur suivante si vous proc\u00e9dez \u00e0 la cr\u00e9ation par vous-m\u00eame:","title":"Demander un calcul"},{"location":"AzureML/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"AzureSQL/","text":"English Base de donn\u00e9es Azure SQL Une base de donn\u00e9es Azure SQL peut \u00eatre cr\u00e9\u00e9e \u00e0 l'avance si vous en avez besoin pour votre projet. Rappel : Les bases de donn\u00e9es Azure SQL de l'Environnement d'Analyse Collaborative (EAC) sont seulement disponibles \u00e0 partir de l'environnement infonuagique de l'EAC. Vous ne pouvez y acc\u00e9der \u00e0 partir des centres de donn\u00e9es du gouvernement du Canada. Acc\u00e8s \u00e0 une base de donn\u00e9es Azure SQL Azure Data Factory On peut cr\u00e9er un service li\u00e9 dans Azure Data Factory. Configurez le service li\u00e9 pour se connecter via le runtime d'int\u00e9gration auto-h\u00e9berg\u00e9 et utilisez Identit\u00e9 manag\u00e9e comme M\u00e9thode d'authentification . Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com si vous avez besoin d'aide. Databricks On peut configurer un carnet Databricks pour ouvrir une connexion \u00e0 la base de donn\u00e9es. Puisque ceci exige une configuration additionnelle, veuillez faire une demande aupr\u00e8s de l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Machine virtuelle Vous pouvez vous connecter \u00e0 une base de donn\u00e9es Azure SQL \u00e0 partir de votre machine virtuelle en infonuagique, en utilisant une application telle que: 1. SQL Server Management Studio 2. Power BI Desktop 3. Azure Data Studio 4. Visual Studio ou Visual Studio Code Pr\u00e9requis Une machine virtuelle dans l'EAC. Voir la page Machines Virtuelle pour plus d'informations. SQL Server Management Studio ou un autre outil tel que Power BI Desktop . Ces outils sont offerts par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine . \u00c9tapes Connectez-vous \u00e0 votre machine virtuelle dans l'EAC. Lancez un outil tel que SQL Server Management Studio . Choisissez Azure Active Directory - Auth.universelle avec MFA comme type d'Authentication. Entrez le nom de votre serveur SQL puis entrez votre compte Cloud comme nom d'utilisateur. Cliquez sur le bouton Options . Sous l'onglet Propri\u00e9t\u00e9s de Connexion , selectionnez le nom de la base de donn\u00e9es en face du libell\u00e9 Se connecter \u00e0 la base de donn\u00e9es , puis cliquez sur le bouton de Connexion . Effectuer l'authentication avec les param\u00e8tres d'identification de votre compte Cloud. Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Base de donn\u00e9es Azure SQL"},{"location":"AzureSQL/#base-de-donnees-azure-sql","text":"Une base de donn\u00e9es Azure SQL peut \u00eatre cr\u00e9\u00e9e \u00e0 l'avance si vous en avez besoin pour votre projet. Rappel : Les bases de donn\u00e9es Azure SQL de l'Environnement d'Analyse Collaborative (EAC) sont seulement disponibles \u00e0 partir de l'environnement infonuagique de l'EAC. Vous ne pouvez y acc\u00e9der \u00e0 partir des centres de donn\u00e9es du gouvernement du Canada.","title":"Base de donn\u00e9es Azure SQL"},{"location":"AzureSQL/#acces-a-une-base-de-donnees-azure-sql","text":"","title":"Acc\u00e8s \u00e0 une base de donn\u00e9es Azure\u00a0SQL"},{"location":"AzureSQL/#azure-data-factory","text":"On peut cr\u00e9er un service li\u00e9 dans Azure Data Factory. Configurez le service li\u00e9 pour se connecter via le runtime d'int\u00e9gration auto-h\u00e9berg\u00e9 et utilisez Identit\u00e9 manag\u00e9e comme M\u00e9thode d'authentification . Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com si vous avez besoin d'aide.","title":"Azure Data Factory"},{"location":"AzureSQL/#databricks","text":"On peut configurer un carnet Databricks pour ouvrir une connexion \u00e0 la base de donn\u00e9es. Puisque ceci exige une configuration additionnelle, veuillez faire une demande aupr\u00e8s de l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com.","title":"Databricks"},{"location":"AzureSQL/#machine-virtuelle","text":"Vous pouvez vous connecter \u00e0 une base de donn\u00e9es Azure SQL \u00e0 partir de votre machine virtuelle en infonuagique, en utilisant une application telle que: 1. SQL Server Management Studio 2. Power BI Desktop 3. Azure Data Studio 4. Visual Studio ou Visual Studio Code","title":"Machine virtuelle"},{"location":"AzureSQL/#prerequis","text":"Une machine virtuelle dans l'EAC. Voir la page Machines Virtuelle pour plus d'informations. SQL Server Management Studio ou un autre outil tel que Power BI Desktop . Ces outils sont offerts par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine .","title":"Pr\u00e9requis"},{"location":"AzureSQL/#etapes","text":"Connectez-vous \u00e0 votre machine virtuelle dans l'EAC. Lancez un outil tel que SQL Server Management Studio . Choisissez Azure Active Directory - Auth.universelle avec MFA comme type d'Authentication. Entrez le nom de votre serveur SQL puis entrez votre compte Cloud comme nom d'utilisateur. Cliquez sur le bouton Options . Sous l'onglet Propri\u00e9t\u00e9s de Connexion , selectionnez le nom de la base de donn\u00e9es en face du libell\u00e9 Se connecter \u00e0 la base de donn\u00e9es , puis cliquez sur le bouton de Connexion . Effectuer l'authentication avec les param\u00e8tres d'identification de votre compte Cloud.","title":"\u00c9tapes"},{"location":"AzureSQL/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"AzureStorage/","text":"English Stockage Azure Les donn\u00e9es peuvent \u00eatre t\u00e9l\u00e9vers\u00e9es sur la plateforme par l'entremise du portail Azure ou de l'application Explorateur de stockage Azure. Une fois qu'elles auront \u00e9t\u00e9 t\u00e9l\u00e9vers\u00e9es dans un compte de stockage externe Blob Azure , elles seront automatiquement ing\u00e9r\u00e9es dans un compte de stockage interne Azure Data Lake Storage (ADLS) . Lorsque les donn\u00e9es seront dans Data Lake, les utilisateurs pourront choisir des outils de transformation et d'int\u00e9gration. Ils pourront utiliser des outils Web, comme Databricks et Data Factory, pour effectuer des transformations ou des outils de bureau sur une machine virtuelle pour transformer et analyser les donn\u00e9es. Les donn\u00e9es nettoy\u00e9es et transform\u00e9es pourront \u00eatre plac\u00e9es dans diff\u00e9rents dossiers (contenant des ensembles de donn\u00e9es trait\u00e9es ou de meilleure qualit\u00e9) ou t\u00e9l\u00e9vers\u00e9es dans une base de donn\u00e9es. Les utilisateurs seront de nouveau en mesure de se connecter \u00e0 ces donn\u00e9es \u00e0 l'aide des outils qu'ils souhaiteront utiliser, et ce, \u00e0 partir de leur machine virtuelle ou d'autres services offerts sur la plateforme, tels que Databricks et Data Factory. Rappel : Les comptes de stockage internes ne sont accessibles qu'\u00e0 partir d'une machine virtuelle dans l'Environnement d'analyse collaboratif (EAC); voir la FAQ . Explorateur de stockage -- Portail Azure Acc\u00e9dez au compte de stockage (aper\u00e7u) Storage Account (Preview) \u00e0 partir du portail Azure. S\u00e9lectionnez votre type d'abonnement, puis naviguez dans votre compte de stockage. Explorateur de stockage -- Poste de travail personnel ou machine virtuelle sur nuage T\u00e9l\u00e9chargez l'application Explorateur de stockage Azure et installez-la sur votre poste de travail ou votre machine virtuelle. Lancez l'Explorateur de stockage Azure \u00e0 partir du menu D\u00e9marrer. Ouvrez une session avec votre compte Azure. Entrez vos justificatifs d'identit\u00e9 du nuage . Explorateur de stockage -- VDI du r\u00e9seau B Cette section s'adresse aux employ\u00e9s de Statistique Canada qui doivent t\u00e9l\u00e9verser des donn\u00e9es du r\u00e9seau B. T\u00e9l\u00e9chargez l'application Explorateur de stockage Azure et installez-la sur votre VDI du r\u00e9seau B. Lancez l'Explorateur de stockage Azure \u00e0 partir du menu D\u00e9marrer. Sur un VDI du r\u00e9seau B, la seule fa\u00e7on d'acc\u00e9der \u00e0 votre compte de stockage est d'utiliser un jeton SAP temporaire. Pour en faire la demande, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Note : Pour obtenir des renseignements sur la configuration des param\u00e8tres du proxy du r\u00e9seau B, consultez la FAQ . Documentation Microsoft T\u00e9l\u00e9chargez l'Explorateur de stockage Azure D\u00e9marrage rapide : Charger, t\u00e9l\u00e9charger et lister les objets blob avec le portail Azure Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Stockage Azure"},{"location":"AzureStorage/#stockage-azure","text":"Les donn\u00e9es peuvent \u00eatre t\u00e9l\u00e9vers\u00e9es sur la plateforme par l'entremise du portail Azure ou de l'application Explorateur de stockage Azure. Une fois qu'elles auront \u00e9t\u00e9 t\u00e9l\u00e9vers\u00e9es dans un compte de stockage externe Blob Azure , elles seront automatiquement ing\u00e9r\u00e9es dans un compte de stockage interne Azure Data Lake Storage (ADLS) . Lorsque les donn\u00e9es seront dans Data Lake, les utilisateurs pourront choisir des outils de transformation et d'int\u00e9gration. Ils pourront utiliser des outils Web, comme Databricks et Data Factory, pour effectuer des transformations ou des outils de bureau sur une machine virtuelle pour transformer et analyser les donn\u00e9es. Les donn\u00e9es nettoy\u00e9es et transform\u00e9es pourront \u00eatre plac\u00e9es dans diff\u00e9rents dossiers (contenant des ensembles de donn\u00e9es trait\u00e9es ou de meilleure qualit\u00e9) ou t\u00e9l\u00e9vers\u00e9es dans une base de donn\u00e9es. Les utilisateurs seront de nouveau en mesure de se connecter \u00e0 ces donn\u00e9es \u00e0 l'aide des outils qu'ils souhaiteront utiliser, et ce, \u00e0 partir de leur machine virtuelle ou d'autres services offerts sur la plateforme, tels que Databricks et Data Factory. Rappel : Les comptes de stockage internes ne sont accessibles qu'\u00e0 partir d'une machine virtuelle dans l'Environnement d'analyse collaboratif (EAC); voir la FAQ .","title":"Stockage\u00a0Azure"},{"location":"AzureStorage/#explorateur-de-stockage-portail-azure","text":"Acc\u00e9dez au compte de stockage (aper\u00e7u) Storage Account (Preview) \u00e0 partir du portail Azure. S\u00e9lectionnez votre type d'abonnement, puis naviguez dans votre compte de stockage.","title":"Explorateur de stockage\u00a0-- Portail\u00a0Azure"},{"location":"AzureStorage/#explorateur-de-stockage-poste-de-travail-personnel-ou-machine-virtuelle-sur-nuage","text":"T\u00e9l\u00e9chargez l'application Explorateur de stockage Azure et installez-la sur votre poste de travail ou votre machine virtuelle. Lancez l'Explorateur de stockage Azure \u00e0 partir du menu D\u00e9marrer. Ouvrez une session avec votre compte Azure. Entrez vos justificatifs d'identit\u00e9 du nuage .","title":"Explorateur de stockage\u00a0-- Poste de travail personnel ou machine virtuelle sur nuage"},{"location":"AzureStorage/#explorateur-de-stockage-vdi-du-reseau-b","text":"Cette section s'adresse aux employ\u00e9s de Statistique Canada qui doivent t\u00e9l\u00e9verser des donn\u00e9es du r\u00e9seau B. T\u00e9l\u00e9chargez l'application Explorateur de stockage Azure et installez-la sur votre VDI du r\u00e9seau B. Lancez l'Explorateur de stockage Azure \u00e0 partir du menu D\u00e9marrer. Sur un VDI du r\u00e9seau B, la seule fa\u00e7on d'acc\u00e9der \u00e0 votre compte de stockage est d'utiliser un jeton SAP temporaire. Pour en faire la demande, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Note : Pour obtenir des renseignements sur la configuration des param\u00e8tres du proxy du r\u00e9seau B, consultez la FAQ .","title":"Explorateur de stockage\u00a0-- VDI du r\u00e9seau\u00a0B"},{"location":"AzureStorage/#documentation-microsoft","text":"T\u00e9l\u00e9chargez l'Explorateur de stockage Azure D\u00e9marrage rapide : Charger, t\u00e9l\u00e9charger et lister les objets blob avec le portail Azure","title":"Documentation Microsoft"},{"location":"AzureStorage/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"AzureSynapse/","text":"English Azure Synapse Getting Started Access Azure Synapse Make sure you are in your cloud VM in order to access Azure Synapse. See Virtual Machines for information on how to create one if needed. Inside your virtual machine, open a web browser and navigate to the Azure Portal (https://portal.azure.com). Sign in with your cloud account credentials. a . Click on the ** Azure Synapse Analytics ** icon under ** Azure services ** . If you do not see this icon , follow step 3 b instead . ! [ Access Synapse ]( images / AzureSynapseAccess_2 . png ) b. Start typing \"synapse\" into the search bar to find Azure Synapse Analytics . Find your Synapse workspace in the list and click on it. Then click Open Synapse Studio . Note: You can also acccess Synapse workspaces from the Collaborative Analytics Environment dashboard. Start and Stop Dedicated SQL Pool Click on the Integrate tab. Under Pipelines , click on either Start Dedicated SQL Pool or Pause Dedicated SQL Pool . Then click the trigger button to open a menu, and select Trigger now . On the next screen, click OK . Home The Home tab is where you start when you first open Azure Synapse Studio. From here, you can access shortcuts for common tasks such as creating SQL scripts or notebooks by clicking the New dropdown menu button. Recently opened resources are also displayed. Data The Data tab is where you can explore everything in your database and linked datasets. Under the Workspace tab, you can explore the dedicated SQL pool database and any Spark databases. Under the Linked tab, you can explore external objects (e.g. Data Lake accounts) and explore/create any integration datasets from external linked data (e.g. Data Lake, Blob Storage, web service, etc) to be used in pipelines. How to Bring in Data from Linked Services (Note: This example shows how to get data from the Data Lake, although there are many source types available.) Click the plus button the add a new resource, then click Integration Dataset . Select Azure Data Lake Storage Gen2 (you may need to search for this), then click Continue . Select the format type, then click Continue . Enter a name, then click the drop-down menu under Linked service and select your data lake. Under Connect via integration runtime , ensure that interactive authoring is enabled. If it is not, click the edit button to enable it, then click Apply . Set additional properties as appropriate, then click OK . How to Explore Data in the Data Lake Browse to find your dataset file (CSV, Parquet, JSON, Avro, etc) and right click on it. A menu will open with options to preview the data, or create resources such as SQL scripts and notebooks. How to Explore the Dedicated SQL Pool Under the Workspace tab, you can explore databases similarly to SQL Server Management Studio (SSMS). Right click on any table, highlight New SQL script , and click Select TOP 100 rows to create a new query. You can then view the results as either a table or a chart. Importing Data to the Dedicated SQL Pool To import data to the dedicated SQL pool, you can either: - create a pipeline with a Copy data activity (most efficient for large datasets); or - use the Bulk Load Wizard . Develop From here, you can create and save resources such as SQL scripts, notebooks, and Power BI reports. To add a new resource, click the plus button. A drop-down menu will open. To make your changes visible to others, you need to click the Publish button. SQL Scripts Be sure to connect to your dedicated SQL pool in order to run SQL scripts. Notebooks In order to run notebook cells, you first need to select your Apache Spark pool. To change languages for a single cell, you can use magic commands: %%pyspark, %%spark, %%csharp, %%sql. You can also change the default language using the Language dropdown menu. Dataflows To add a source to a dataflow, under Source Settings , click the plus button, then select Azure Data Lake Storage Gen2 (you may need to search for this). Click Continue , select the data format, then on the next page, select your Linked Service. Power BI Reports You can view and create Power BI reports directly in Azure Synapse. Please contact the CAE support team to validate that a linked service is setup. Integrate This is where you can create pipelines for ingesting, preparing and transforming all of your data, like in Azure Data Factory . Example: Copy Data from External Blob to Data Lake Click the plus button to add a new resource, then click on Pipeline . Under Move & transform , drag and drop Copy data into the window. Click on the Source tab, then click New to add the source dataset (where you want to copy the data from). Select Azure Blob Storage , then select the format type (CSV, Parquet, JSON, etc). Set any additional properties if relevant, then click OK . Click on the Sink , then click New to set the sink dataset (where you want the data to be copied to). Choose Azure Data Lake Storage Gen2 , then select the format type. Under Linked service , choose your data lake and ensure that interactive authoring is enabled (see How to Bring in Data from Linked Services under Data for more info). Debugging and Running Pipelines To run a pipeline in debug mode, click the Debug button at the top of the pipeline window. Results will appear in the Output tab. To run a pipeline without debugging, click the Add trigger button, then Trigger now . When you are ready to publish your pipelines, click the Validate all button, then click the Publish all button. Note that this will publish for all users to see everything that you currently have open (pipelines, SQL scripts, notebooks, etc). Monitor From the Monitor tab, you can monitor live pipeline runs (inputs/outputs of each activity and any errors) and view historical pipeline runs, trigger runs, SQL requests, etc. Manage This is where you can: - Add new SQL or Apache Spark pools - Add new linked services - Grant others access to the workspace - Set up git integration Microsoft Documentation Azure Synapse Analytics What is Azure Synapse Analytics? Analyse Data with Dedicated SQL Pools Integrate with Pipelines Visualize Data with Power BI Monitor Your Synapse Workspace Change Display Language See Language page to find out how to change the display language.","title":"AzureSynapse"},{"location":"AzureSynapse/#azure-synapse","text":"","title":"Azure Synapse"},{"location":"AzureSynapse/#getting-started","text":"","title":"Getting Started"},{"location":"AzureSynapse/#access-azure-synapse","text":"Make sure you are in your cloud VM in order to access Azure Synapse. See Virtual Machines for information on how to create one if needed. Inside your virtual machine, open a web browser and navigate to the Azure Portal (https://portal.azure.com). Sign in with your cloud account credentials. a . Click on the ** Azure Synapse Analytics ** icon under ** Azure services ** . If you do not see this icon , follow step 3 b instead . ! [ Access Synapse ]( images / AzureSynapseAccess_2 . png ) b. Start typing \"synapse\" into the search bar to find Azure Synapse Analytics . Find your Synapse workspace in the list and click on it. Then click Open Synapse Studio . Note: You can also acccess Synapse workspaces from the Collaborative Analytics Environment dashboard.","title":"Access Azure Synapse"},{"location":"AzureSynapse/#start-and-stop-dedicated-sql-pool","text":"Click on the Integrate tab. Under Pipelines , click on either Start Dedicated SQL Pool or Pause Dedicated SQL Pool . Then click the trigger button to open a menu, and select Trigger now . On the next screen, click OK .","title":"Start and Stop Dedicated SQL Pool"},{"location":"AzureSynapse/#home","text":"The Home tab is where you start when you first open Azure Synapse Studio. From here, you can access shortcuts for common tasks such as creating SQL scripts or notebooks by clicking the New dropdown menu button. Recently opened resources are also displayed.","title":"Home"},{"location":"AzureSynapse/#data","text":"The Data tab is where you can explore everything in your database and linked datasets. Under the Workspace tab, you can explore the dedicated SQL pool database and any Spark databases. Under the Linked tab, you can explore external objects (e.g. Data Lake accounts) and explore/create any integration datasets from external linked data (e.g. Data Lake, Blob Storage, web service, etc) to be used in pipelines.","title":"Data"},{"location":"AzureSynapse/#how-to-bring-in-data-from-linked-services","text":"(Note: This example shows how to get data from the Data Lake, although there are many source types available.) Click the plus button the add a new resource, then click Integration Dataset . Select Azure Data Lake Storage Gen2 (you may need to search for this), then click Continue . Select the format type, then click Continue . Enter a name, then click the drop-down menu under Linked service and select your data lake. Under Connect via integration runtime , ensure that interactive authoring is enabled. If it is not, click the edit button to enable it, then click Apply . Set additional properties as appropriate, then click OK .","title":"How to Bring in Data from Linked Services"},{"location":"AzureSynapse/#how-to-explore-data-in-the-data-lake","text":"Browse to find your dataset file (CSV, Parquet, JSON, Avro, etc) and right click on it. A menu will open with options to preview the data, or create resources such as SQL scripts and notebooks.","title":"How to Explore Data in the Data Lake"},{"location":"AzureSynapse/#how-to-explore-the-dedicated-sql-pool","text":"Under the Workspace tab, you can explore databases similarly to SQL Server Management Studio (SSMS). Right click on any table, highlight New SQL script , and click Select TOP 100 rows to create a new query. You can then view the results as either a table or a chart.","title":"How to Explore the Dedicated SQL Pool"},{"location":"AzureSynapse/#importing-data-to-the-dedicated-sql-pool","text":"To import data to the dedicated SQL pool, you can either: - create a pipeline with a Copy data activity (most efficient for large datasets); or - use the Bulk Load Wizard .","title":"Importing Data to the Dedicated SQL Pool"},{"location":"AzureSynapse/#develop","text":"From here, you can create and save resources such as SQL scripts, notebooks, and Power BI reports. To add a new resource, click the plus button. A drop-down menu will open. To make your changes visible to others, you need to click the Publish button.","title":"Develop"},{"location":"AzureSynapse/#sql-scripts","text":"Be sure to connect to your dedicated SQL pool in order to run SQL scripts.","title":"SQL Scripts"},{"location":"AzureSynapse/#notebooks","text":"In order to run notebook cells, you first need to select your Apache Spark pool. To change languages for a single cell, you can use magic commands: %%pyspark, %%spark, %%csharp, %%sql. You can also change the default language using the Language dropdown menu.","title":"Notebooks"},{"location":"AzureSynapse/#dataflows","text":"To add a source to a dataflow, under Source Settings , click the plus button, then select Azure Data Lake Storage Gen2 (you may need to search for this). Click Continue , select the data format, then on the next page, select your Linked Service.","title":"Dataflows"},{"location":"AzureSynapse/#power-bi-reports","text":"You can view and create Power BI reports directly in Azure Synapse. Please contact the CAE support team to validate that a linked service is setup.","title":"Power BI Reports"},{"location":"AzureSynapse/#integrate","text":"This is where you can create pipelines for ingesting, preparing and transforming all of your data, like in Azure Data Factory .","title":"Integrate"},{"location":"AzureSynapse/#example-copy-data-from-external-blob-to-data-lake","text":"Click the plus button to add a new resource, then click on Pipeline . Under Move & transform , drag and drop Copy data into the window. Click on the Source tab, then click New to add the source dataset (where you want to copy the data from). Select Azure Blob Storage , then select the format type (CSV, Parquet, JSON, etc). Set any additional properties if relevant, then click OK . Click on the Sink , then click New to set the sink dataset (where you want the data to be copied to). Choose Azure Data Lake Storage Gen2 , then select the format type. Under Linked service , choose your data lake and ensure that interactive authoring is enabled (see How to Bring in Data from Linked Services under Data for more info).","title":"Example: Copy Data from External Blob to Data Lake"},{"location":"AzureSynapse/#debugging-and-running-pipelines","text":"To run a pipeline in debug mode, click the Debug button at the top of the pipeline window. Results will appear in the Output tab. To run a pipeline without debugging, click the Add trigger button, then Trigger now . When you are ready to publish your pipelines, click the Validate all button, then click the Publish all button. Note that this will publish for all users to see everything that you currently have open (pipelines, SQL scripts, notebooks, etc).","title":"Debugging and Running Pipelines"},{"location":"AzureSynapse/#monitor","text":"From the Monitor tab, you can monitor live pipeline runs (inputs/outputs of each activity and any errors) and view historical pipeline runs, trigger runs, SQL requests, etc.","title":"Monitor"},{"location":"AzureSynapse/#manage","text":"This is where you can: - Add new SQL or Apache Spark pools - Add new linked services - Grant others access to the workspace - Set up git integration","title":"Manage"},{"location":"AzureSynapse/#microsoft-documentation","text":"Azure Synapse Analytics What is Azure Synapse Analytics? Analyse Data with Dedicated SQL Pools Integrate with Pipelines Visualize Data with Power BI Monitor Your Synapse Workspace","title":"Microsoft Documentation"},{"location":"AzureSynapse/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"BestPracticesFAQ/","text":"Fran\u00e7ais Best Practices FAQ What is the best file format to use for large data files? Recommend using newer format like Parquet because it does save larger datesets in a smaller file in comparison to a CSV file. If only accessing certain sections of the dataset, it is also faster using Parquet as it uses columnar storage format. Do I need a SQL database? In many cases a SQL database is not needed, data can be saved in files to the datalake. Do I need a SQL database when using Power BI? It is not needed to have an SQL datbase when using Power BI. You are able to read files from the Azure Storage. A database is only needed when you are using a more complex star-schema like system. To connect to the internal data lake with Power BI desktop, please refer to this link: https://statcan.github.io/cae-eac/en/FAQ/#how-do-i-connect-to-the-internal-data-lake-with-power-bi-desktop How should we structure our projects data lake container? There are 3 parts in which to structure your data lake container: Bronze/Raw Zone This zone stores the original format of any files or files/data that is immutable. The data contained in this zone is usually locked and are only accessible to certain members or is read-only. This zone is also organised in different folders per source system, with each ingestion process having a write access to only their associated folder. Silver/Cleansed Zone This zone is where parts of data removes unnecessary columns from the data, validates, standarizes and harmonises that data within this zone. This zone is mainly a folder per project. Any data that must be accessed within this zone is usually granted read-only access. Gold/Curated Zone This zone is mainly for analytics rather than data ingestion or processing. The data in the curated zone is stored in star schemas. The dimensional modelling is usually done using Spark or Data Factory instead of inside the database engine. But if the dimensional modelling is done outside of the lake then it is best to publish the model back to the lake. This zone is best suited to run for large-scale queries and analysis that do not have strict time-sensitive reporting needs. Laboratory Zone This zone is mainly for experimentation and exploration. It is used for prototype and innovation mixing both your own data sets with data sets from production. This zone is not a replacement for a development or test data lake which is required for more careful development. Each wil data lake project would have their own laboratory area via a folder. Permissions in this zone are typically read and write for each user/project. For more information about structuring your projects data lake container: https://medium.com/microsoftazure/building-your-data-lake-on-adls-gen2-3f196fc6b430 https://www.mssqltips.com/sqlservertip/6807/design-azure-data-lake-store-gen2/ I get an out of memory exception in Databricks? Option 1: The fastest and most expensive way to fix this is to increase the size of your cluster. To increase the size of the cluster, please contact the CAE support team to increase the size of the cluster Option 2: For a more programtic answer, if you are using pandas, it is also a suggestion to switch over and use pySpark or koalas. PySpark and koalas can run faster than pandas, it has better benefits from using data ingestion pipelines and also works efficiently as it runs parallel on different nodes in a cluster. https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/ Option 3: Consider to use a subset of your data when doing queries if possible. If you are working with only a certain section of the dataset but are quering through all of it, it is possible to use just the subset. Option 4: Consider changing the file format to something like Parquet or Avro which uses less space than a traditional CSV file. Conversion from CSV to Parquet: % python testConvert = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" ) Conversion from CSV to Avro: % python diamonds = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) diamonds . write . format ( \"avro\" ) . save ( \"/mnt/public-data/incoming/testingFile\" ) How can i easily convert SAS code to Python or R? It is not possible to easily convert SAS code to Python or R automatically, the only known way to convert is to manually do the conversion. How do I validate that I am developing my application in the most cost effective way in the cloud using Microsoft technologies (CAE)? There are plenty of ways to validate that your development is the most cost effective it can be: Take advantage of Spark in databricks. a. Spark is a great addition to databricks that runs faster and better especially for large data sets. Using Spark would cost less because it does take less time to do its task. Using spark will also 2. Make sure you cluster is running for the minimal amout of time. a. If the cluster is no longer needed or not being use, ensure that it is not running and only run when it is needed. 3. Ensure your databricks cluster is correctly sized. a. Make sure that you have to correct amount of workers in your cluster, too many clusters results in a higher cost. 4. Delete data files that you are not using. a. Ensure that any files that are no longer needed or not in use anymore are deleted from the container. Try not to do processing on a cloud VM. Ask for a review of your architecture. Code review. If you are using Pandas, it is a good idea to switch over to Koalas. Use a file format that is optimal for your work load (i.e. Parquet, Avro) How should data be structured if we plan to use Power BI? Data should be structured using the Star Schema. For more details about using Star Schema, click the link below for details about using Star Schema and the benefits with Power BI: https://docs.microsoft.com/en-us/power-bi/guidance/star-schema How to read in an Excel file from Databricks? Here is an example of how to read an Excel file using Python: % python import pandas as pd pd . read_excel ( \"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\" , engine = 'openpyxl' ) Which file types are best to use when? Parquet It is good to use for very large datasets. It is also good to use if only a section of the dataset is needed which reads in the data in a faster rate. Read: % python data = spark . read . parquet ( \"/tmp/testParquet\" ) display ( data ) Write: % python // Assumption that a dataframe has been created already data . write . parquet ( \"/tmp/tempFile\" ) Avro Just as Parquet, it is great for very large datasets. To compare, it is better used for editing/writing into a dataset and for querying all columns in the dataset. Read: data = spark . read . format ( \"avro\" ) . load ( \"/tmp/test_dataset\" ) display ( data ) Write: % scala val ex = Seq (( 132 , \"baseball\" ), ( 148 , \"softball\" ), ( 172 , \"slow pitch\" )). toDF ( \"players\" , \"sport\" ) ex . write . format ( \"avro\" ). save ( \"/tmp/testExample\" ) CSV It is fine to use with marginally smaller datasets as CSV files do not load well when the file size is very large. But with smaller data sets, it is simple and human-readable. For writing within a CSV file, it is also good to note that you are able to edit the file with Office. Read: % python data = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/tmp/test_dataCSV.csv' ) display ( data ) Excel Please see above on how to use Excel. The other formats above are perferable over excel. How to convert files (CSV, Text, JSON) to parquet using databricks? The rule of thumb in converting a file to parquet is to first read in the file and then write a new file into parquet CSV to Parquet: % python testConvert = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" ) JSON to Parquet: % python testConvert = spark . read . json ( 'tmp/test.json' ) testConvert . write . parquet ( 'tmp/testingJson' ) Text to Parquet: % python testConvert = spark . read . text ( \"/mnt/public-data/incoming/testing.txt\" ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" ) Can I read Word document in Databricks? It is best practice to read Word documents via Office instead. When should we use ADF vs. Databricks for data ingestion? Databricks is able to do real-time streaming through the Apache Spark API that can handle the streaming analytics workloads. Databricks does not need you to wrap the python code into functions or executable modules, all the code is able to work just as is. Databricks also supports Machine Learning which makes data ingestion easier as well. For any code that is already in an Azure Function or is easily translated into an executable, using data factory is usable. Data factory is also good to use if it is a heavy algorithm that is not usable within Databricks. What is the difference between SQL database temporal tables and Delta Lake? SQL temporal tables is specific to SQL 2018 and is not currently available in Azure Synapse. On the other hand, Delta lake is available in both Azure Synapse and in Databricks. Another difference is that SQL temporal tables are only available with only SQL queries while Delta lake time travel is available in Scala, Python, and SQL. When to use Power BI or R-Shiny? It is recommended to use Power BI over R-shiny because less coding is required when using Power BI. There are a lot of benefits to using Power BI including the additional amount of chart types that are at hand, visualisation of data into charts is easier to use in Power BI compared to R-Shiny, the creation of a dashboard is faster within PowerBI, and the ease of connectivity with other applications within Azure. When is a good time to use Azure Synapse vs. ADF and Databricks? Azure Synapse is good to use when doing queries and data analysis via the data lake, doing SQL analyses and data warehousing, and using additional services like Power BI. It is easy to query data from the data lake using Azure Snapse and you do not have to mount the data lake to the workspace. As for data analyses and data warehousing, synapse is perferred as it allows full realtional data models, provide all SQL features and also uses Delta Lake. Synapse also includes direct services with Power BI for ease of use. On the other hand, Databricks is preferred when doing machine learning development and real-time transformations. Databricks includes their own machine learning development that includes popular libraries like PyTorch, manage version of MLflow. Databricks is also preferred for real-time transformations as it uses Spark structured streaming and it gives you the ability to view changes from other users in real time. When should we use a SQL database data warehouse vs. Delta Lake? Best practice would be to use Delta lake over SQL server as it does not use additional SQL compute resouces and will reduce the overall cloud costs. How can i easily convert SAS files to another format? Statcan users can use SAS on the internal stats-can network to convert it to a supported file form. You are able to convert a SAS file to CSV or JSON with this method: First open databricks and install the sas7bdat-converter within your notebook. % pip install sas7bdat - converter Using python and your code editor of your choice, type in this code with the file directory that the file is in and the directory where you want the output file to be in. % python import sas7bdat_converter file_dicts = [{ 'sas7bdat_file' : '/dbfs/mnt/public-data/ToNetA/sas7bdat/tablea_1_10k.sas7bdat' , 'export_file' : '/dbfs/mnt/public-data/testFolder/testingConvert.csv' , }] sas7bdat_converter . batch_to_csv ( file_dicts ) You will then get the output file within the directory you have specified. For more information about the converter, please refer to this link: https://pypi.org/project/sas7bdat-converter/ Can\\How I convert Word document to a notebook? There is no easy way to convert a word document to a notebook. A manual solution to convert a Word document to a notebook is by copying any of the code that is within the word document into a notebook. How big of a dataframe/spark table can we store within the workspace? Spark tables are stored as parquet files and are stored in the internal storage account linked with the Databricks workspace, but it is best practice to delete the table if it is no longer in use. What is the best way to get data files into Azure ML? The best way would be to upload your files to the data lake. If you need to add a new cloud storage account, contact the CAE team to add the storage account to the Azure ML studio. Whats the difference to Machine Learning in Databricks or in Azure ML? The main difference between Azure ML and Databricks is the language that each application uses. Azure ML utilizes python-based libraries or R while Databricks utilizes the Apache Spark Platform and MLFlow. Azure ML also contains a tracking system which is able to track individual runs of the experiment and include the specific metrics of what wants to be seen. Databricks includes MLflow which also allows tracking but does not come with as many features as Azure ML. As a recommendation, it is best practice to use Databricks for data preperation and for large datasets but to use Azure ML for their tracking system, machine learning on normal datasets, deep learning on GPUs, and operationalization. How do you create a Table in Databricks? Option 1: Use Create Table function In Databricks, select Data and within the Database you have selected, click on Create Table. For more information about this option, please view this link: https://docs.databricks.com/data/tables.html#create-a-table Option 2: Create Table from Dataframe table Python: df . write . saveAsTable ( \"Table-Name\" ) SQL: CREATE TABLE IF NOT EXISTS Table - Name AS SELECT * FROM df Option 3: Create Table Programatically SQL: CREATE TABLE example (id INT, name STRING, age INT) USING CSV; When to use Spark Dataframe or Spark Table? There are really no difference between using a Spark Dataframe or Spark Table. Currently with Databricks, best practice right now would be to store tables as delta tables as it is saved in parquet format and gives the tracking capabilities. What should I do if the size of the broadcasted table far exceeds estimates and exceeds limit of spark.driver.maxResultSize = _____? Change the Spark configuration \"spark.driver.maxResultSize\" to \"0\" (means no limit) or something larger than your needs. What Should I do if I cannot broadcast the table that is larger than 8GB? This occurs only with BroadcastHashJoin. There are 2 options: Change the Spark configuration \"spark.sql.autoBroadcastJoinThreshold\" to \"-1\". This forces Databricks to perform a SortMergeJoin. Note About changing Spark Configuration Warning: Changing Spark configuraitons can cause out-of-memory-errors Normal approach: - spark.conf.set(\"configuration\", \"value\") If you do not have permissions to change some configurations, this seems to be a work around: - conf = spark.sparkContext._cibf,setAkk([(\"configuration\", \"value\"), (\"configuration\", \"value\")]) How to get Spark Configuration: - spark.conf.get(\"configuration\") Steps to avoid changing configurations: a. Partition DataFrame A into parts. b. Perform joins with each parittion from DataFrame A with DataFrame B (concurrently is the fastest way but may require writing Dataframes to file for reading in next step). c. Perform a union on all the joined DataFrames. Change Display Language See Language page to find out how to change the display language.","title":"BestPracticesFAQ"},{"location":"BestPracticesFAQ/#best-practices-faq","text":"","title":"Best Practices FAQ"},{"location":"BestPracticesFAQ/#what-is-the-best-file-format-to-use-for-large-data-files","text":"Recommend using newer format like Parquet because it does save larger datesets in a smaller file in comparison to a CSV file. If only accessing certain sections of the dataset, it is also faster using Parquet as it uses columnar storage format.","title":"What is the best file format to use for large data files?"},{"location":"BestPracticesFAQ/#do-i-need-a-sql-database","text":"In many cases a SQL database is not needed, data can be saved in files to the datalake.","title":"Do I need a SQL database?"},{"location":"BestPracticesFAQ/#do-i-need-a-sql-database-when-using-power-bi","text":"It is not needed to have an SQL datbase when using Power BI. You are able to read files from the Azure Storage. A database is only needed when you are using a more complex star-schema like system. To connect to the internal data lake with Power BI desktop, please refer to this link: https://statcan.github.io/cae-eac/en/FAQ/#how-do-i-connect-to-the-internal-data-lake-with-power-bi-desktop","title":"Do I need a SQL database when using Power BI?"},{"location":"BestPracticesFAQ/#how-should-we-structure-our-projects-data-lake-container","text":"There are 3 parts in which to structure your data lake container:","title":"How should we structure our projects data lake container?"},{"location":"BestPracticesFAQ/#bronzeraw-zone","text":"This zone stores the original format of any files or files/data that is immutable. The data contained in this zone is usually locked and are only accessible to certain members or is read-only. This zone is also organised in different folders per source system, with each ingestion process having a write access to only their associated folder.","title":"Bronze/Raw Zone"},{"location":"BestPracticesFAQ/#silvercleansed-zone","text":"This zone is where parts of data removes unnecessary columns from the data, validates, standarizes and harmonises that data within this zone. This zone is mainly a folder per project. Any data that must be accessed within this zone is usually granted read-only access.","title":"Silver/Cleansed Zone"},{"location":"BestPracticesFAQ/#goldcurated-zone","text":"This zone is mainly for analytics rather than data ingestion or processing. The data in the curated zone is stored in star schemas. The dimensional modelling is usually done using Spark or Data Factory instead of inside the database engine. But if the dimensional modelling is done outside of the lake then it is best to publish the model back to the lake. This zone is best suited to run for large-scale queries and analysis that do not have strict time-sensitive reporting needs.","title":"Gold/Curated Zone"},{"location":"BestPracticesFAQ/#laboratory-zone","text":"This zone is mainly for experimentation and exploration. It is used for prototype and innovation mixing both your own data sets with data sets from production. This zone is not a replacement for a development or test data lake which is required for more careful development. Each wil data lake project would have their own laboratory area via a folder. Permissions in this zone are typically read and write for each user/project. For more information about structuring your projects data lake container: https://medium.com/microsoftazure/building-your-data-lake-on-adls-gen2-3f196fc6b430 https://www.mssqltips.com/sqlservertip/6807/design-azure-data-lake-store-gen2/","title":"Laboratory Zone"},{"location":"BestPracticesFAQ/#i-get-an-out-of-memory-exception-in-databricks","text":"","title":"I get an out of memory exception in Databricks?"},{"location":"BestPracticesFAQ/#option-1","text":"The fastest and most expensive way to fix this is to increase the size of your cluster. To increase the size of the cluster, please contact the CAE support team to increase the size of the cluster","title":"Option 1:"},{"location":"BestPracticesFAQ/#option-2","text":"For a more programtic answer, if you are using pandas, it is also a suggestion to switch over and use pySpark or koalas. PySpark and koalas can run faster than pandas, it has better benefits from using data ingestion pipelines and also works efficiently as it runs parallel on different nodes in a cluster. https://www.analyticsvidhya.com/blog/2016/10/spark-dataframe-and-operations/","title":"Option 2:"},{"location":"BestPracticesFAQ/#option-3","text":"Consider to use a subset of your data when doing queries if possible. If you are working with only a certain section of the dataset but are quering through all of it, it is possible to use just the subset.","title":"Option 3:"},{"location":"BestPracticesFAQ/#option-4","text":"Consider changing the file format to something like Parquet or Avro which uses less space than a traditional CSV file. Conversion from CSV to Parquet: % python testConvert = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" ) Conversion from CSV to Avro: % python diamonds = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) diamonds . write . format ( \"avro\" ) . save ( \"/mnt/public-data/incoming/testingFile\" )","title":"Option 4:"},{"location":"BestPracticesFAQ/#how-can-i-easily-convert-sas-code-to-python-or-r","text":"It is not possible to easily convert SAS code to Python or R automatically, the only known way to convert is to manually do the conversion.","title":"How can i easily convert SAS code to Python or R?"},{"location":"BestPracticesFAQ/#how-do-i-validate-that-i-am-developing-my-application-in-the-most-cost-effective-way-in-the-cloud-using-microsoft-technologies-cae","text":"There are plenty of ways to validate that your development is the most cost effective it can be: Take advantage of Spark in databricks. a. Spark is a great addition to databricks that runs faster and better especially for large data sets. Using Spark would cost less because it does take less time to do its task. Using spark will also 2. Make sure you cluster is running for the minimal amout of time. a. If the cluster is no longer needed or not being use, ensure that it is not running and only run when it is needed. 3. Ensure your databricks cluster is correctly sized. a. Make sure that you have to correct amount of workers in your cluster, too many clusters results in a higher cost. 4. Delete data files that you are not using. a. Ensure that any files that are no longer needed or not in use anymore are deleted from the container. Try not to do processing on a cloud VM. Ask for a review of your architecture. Code review. If you are using Pandas, it is a good idea to switch over to Koalas. Use a file format that is optimal for your work load (i.e. Parquet, Avro)","title":"How do I validate that I am developing my application in the most cost effective way in the cloud using Microsoft technologies (CAE)?"},{"location":"BestPracticesFAQ/#how-should-data-be-structured-if-we-plan-to-use-power-bi","text":"Data should be structured using the Star Schema. For more details about using Star Schema, click the link below for details about using Star Schema and the benefits with Power BI: https://docs.microsoft.com/en-us/power-bi/guidance/star-schema","title":"How should data be structured if we plan to use Power BI?"},{"location":"BestPracticesFAQ/#how-to-read-in-an-excel-file-from-databricks","text":"Here is an example of how to read an Excel file using Python: % python import pandas as pd pd . read_excel ( \"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\" , engine = 'openpyxl' )","title":"How to read in an Excel file from Databricks?"},{"location":"BestPracticesFAQ/#which-file-types-are-best-to-use-when","text":"","title":"Which file types are best to use when?"},{"location":"BestPracticesFAQ/#parquet","text":"It is good to use for very large datasets. It is also good to use if only a section of the dataset is needed which reads in the data in a faster rate. Read: % python data = spark . read . parquet ( \"/tmp/testParquet\" ) display ( data ) Write: % python // Assumption that a dataframe has been created already data . write . parquet ( \"/tmp/tempFile\" )","title":"Parquet"},{"location":"BestPracticesFAQ/#avro","text":"Just as Parquet, it is great for very large datasets. To compare, it is better used for editing/writing into a dataset and for querying all columns in the dataset. Read: data = spark . read . format ( \"avro\" ) . load ( \"/tmp/test_dataset\" ) display ( data ) Write: % scala val ex = Seq (( 132 , \"baseball\" ), ( 148 , \"softball\" ), ( 172 , \"slow pitch\" )). toDF ( \"players\" , \"sport\" ) ex . write . format ( \"avro\" ). save ( \"/tmp/testExample\" )","title":"Avro"},{"location":"BestPracticesFAQ/#csv","text":"It is fine to use with marginally smaller datasets as CSV files do not load well when the file size is very large. But with smaller data sets, it is simple and human-readable. For writing within a CSV file, it is also good to note that you are able to edit the file with Office. Read: % python data = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/tmp/test_dataCSV.csv' ) display ( data )","title":"CSV"},{"location":"BestPracticesFAQ/#excel","text":"Please see above on how to use Excel. The other formats above are perferable over excel.","title":"Excel"},{"location":"BestPracticesFAQ/#how-to-convert-files-csv-text-json-to-parquet-using-databricks","text":"The rule of thumb in converting a file to parquet is to first read in the file and then write a new file into parquet CSV to Parquet: % python testConvert = spark . read . format ( 'csv' ) . options ( header = 'true' , inferSchema = 'true' ) . load ( '/mnt/public-data/incoming/titanic.csv' ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" ) JSON to Parquet: % python testConvert = spark . read . json ( 'tmp/test.json' ) testConvert . write . parquet ( 'tmp/testingJson' ) Text to Parquet: % python testConvert = spark . read . text ( \"/mnt/public-data/incoming/testing.txt\" ) testConvert . write . parquet ( \"/mnt/public-data/incoming/testingFile\" )","title":"How to convert files (CSV, Text, JSON) to parquet using databricks?"},{"location":"BestPracticesFAQ/#can-i-read-word-document-in-databricks","text":"It is best practice to read Word documents via Office instead.","title":"Can I read Word document in Databricks?"},{"location":"BestPracticesFAQ/#when-should-we-use-adf-vs-databricks-for-data-ingestion","text":"Databricks is able to do real-time streaming through the Apache Spark API that can handle the streaming analytics workloads. Databricks does not need you to wrap the python code into functions or executable modules, all the code is able to work just as is. Databricks also supports Machine Learning which makes data ingestion easier as well. For any code that is already in an Azure Function or is easily translated into an executable, using data factory is usable. Data factory is also good to use if it is a heavy algorithm that is not usable within Databricks.","title":"When should we use ADF vs. Databricks for data ingestion?"},{"location":"BestPracticesFAQ/#what-is-the-difference-between-sql-database-temporal-tables-and-delta-lake","text":"SQL temporal tables is specific to SQL 2018 and is not currently available in Azure Synapse. On the other hand, Delta lake is available in both Azure Synapse and in Databricks. Another difference is that SQL temporal tables are only available with only SQL queries while Delta lake time travel is available in Scala, Python, and SQL.","title":"What is the difference between SQL database temporal tables and Delta Lake?"},{"location":"BestPracticesFAQ/#when-to-use-power-bi-or-r-shiny","text":"It is recommended to use Power BI over R-shiny because less coding is required when using Power BI. There are a lot of benefits to using Power BI including the additional amount of chart types that are at hand, visualisation of data into charts is easier to use in Power BI compared to R-Shiny, the creation of a dashboard is faster within PowerBI, and the ease of connectivity with other applications within Azure.","title":"When to use Power BI or R-Shiny?"},{"location":"BestPracticesFAQ/#when-is-a-good-time-to-use-azure-synapse-vs-adf-and-databricks","text":"Azure Synapse is good to use when doing queries and data analysis via the data lake, doing SQL analyses and data warehousing, and using additional services like Power BI. It is easy to query data from the data lake using Azure Snapse and you do not have to mount the data lake to the workspace. As for data analyses and data warehousing, synapse is perferred as it allows full realtional data models, provide all SQL features and also uses Delta Lake. Synapse also includes direct services with Power BI for ease of use. On the other hand, Databricks is preferred when doing machine learning development and real-time transformations. Databricks includes their own machine learning development that includes popular libraries like PyTorch, manage version of MLflow. Databricks is also preferred for real-time transformations as it uses Spark structured streaming and it gives you the ability to view changes from other users in real time.","title":"When is a good time to use Azure Synapse vs. ADF and Databricks?"},{"location":"BestPracticesFAQ/#when-should-we-use-a-sql-database-data-warehouse-vs-delta-lake","text":"Best practice would be to use Delta lake over SQL server as it does not use additional SQL compute resouces and will reduce the overall cloud costs.","title":"When should we use a SQL database data warehouse vs. Delta Lake?"},{"location":"BestPracticesFAQ/#how-can-i-easily-convert-sas-files-to-another-format","text":"Statcan users can use SAS on the internal stats-can network to convert it to a supported file form. You are able to convert a SAS file to CSV or JSON with this method: First open databricks and install the sas7bdat-converter within your notebook. % pip install sas7bdat - converter Using python and your code editor of your choice, type in this code with the file directory that the file is in and the directory where you want the output file to be in. % python import sas7bdat_converter file_dicts = [{ 'sas7bdat_file' : '/dbfs/mnt/public-data/ToNetA/sas7bdat/tablea_1_10k.sas7bdat' , 'export_file' : '/dbfs/mnt/public-data/testFolder/testingConvert.csv' , }] sas7bdat_converter . batch_to_csv ( file_dicts ) You will then get the output file within the directory you have specified. For more information about the converter, please refer to this link: https://pypi.org/project/sas7bdat-converter/","title":"How can i easily convert SAS files to another format?"},{"location":"BestPracticesFAQ/#canhow-i-convert-word-document-to-a-notebook","text":"There is no easy way to convert a word document to a notebook. A manual solution to convert a Word document to a notebook is by copying any of the code that is within the word document into a notebook.","title":"Can\\How I convert Word document to a notebook?"},{"location":"BestPracticesFAQ/#how-big-of-a-dataframespark-table-can-we-store-within-the-workspace","text":"Spark tables are stored as parquet files and are stored in the internal storage account linked with the Databricks workspace, but it is best practice to delete the table if it is no longer in use.","title":"How big of a dataframe/spark table can we store within the workspace?"},{"location":"BestPracticesFAQ/#what-is-the-best-way-to-get-data-files-into-azure-ml","text":"The best way would be to upload your files to the data lake. If you need to add a new cloud storage account, contact the CAE team to add the storage account to the Azure ML studio.","title":"What is the best way to get data files into Azure ML?"},{"location":"BestPracticesFAQ/#whats-the-difference-to-machine-learning-in-databricks-or-in-azure-ml","text":"The main difference between Azure ML and Databricks is the language that each application uses. Azure ML utilizes python-based libraries or R while Databricks utilizes the Apache Spark Platform and MLFlow. Azure ML also contains a tracking system which is able to track individual runs of the experiment and include the specific metrics of what wants to be seen. Databricks includes MLflow which also allows tracking but does not come with as many features as Azure ML. As a recommendation, it is best practice to use Databricks for data preperation and for large datasets but to use Azure ML for their tracking system, machine learning on normal datasets, deep learning on GPUs, and operationalization.","title":"Whats the difference to Machine Learning in Databricks or in Azure ML?"},{"location":"BestPracticesFAQ/#how-do-you-create-a-table-in-databricks","text":"","title":"How do you create a Table in Databricks?"},{"location":"BestPracticesFAQ/#option-1-use-create-table-function","text":"In Databricks, select Data and within the Database you have selected, click on Create Table. For more information about this option, please view this link: https://docs.databricks.com/data/tables.html#create-a-table","title":"Option 1: Use Create Table function"},{"location":"BestPracticesFAQ/#option-2-create-table-from-dataframe-table","text":"Python: df . write . saveAsTable ( \"Table-Name\" ) SQL: CREATE TABLE IF NOT EXISTS Table - Name AS SELECT * FROM df","title":"Option 2: Create Table from Dataframe table"},{"location":"BestPracticesFAQ/#option-3-create-table-programatically","text":"SQL: CREATE TABLE example (id INT, name STRING, age INT) USING CSV;","title":"Option 3: Create Table Programatically"},{"location":"BestPracticesFAQ/#when-to-use-spark-dataframe-or-spark-table","text":"There are really no difference between using a Spark Dataframe or Spark Table. Currently with Databricks, best practice right now would be to store tables as delta tables as it is saved in parquet format and gives the tracking capabilities.","title":"When to use Spark Dataframe or Spark Table?"},{"location":"BestPracticesFAQ/#what-should-i-do-if-the-size-of-the-broadcasted-table-far-exceeds-estimates-and-exceeds-limit-of-sparkdrivermaxresultsize-_____","text":"Change the Spark configuration \"spark.driver.maxResultSize\" to \"0\" (means no limit) or something larger than your needs.","title":"What should I do if the size of the broadcasted table far exceeds estimates and exceeds limit of spark.driver.maxResultSize = _____?"},{"location":"BestPracticesFAQ/#what-should-i-do-if-i-cannot-broadcast-the-table-that-is-larger-than-8gb","text":"This occurs only with BroadcastHashJoin. There are 2 options: Change the Spark configuration \"spark.sql.autoBroadcastJoinThreshold\" to \"-1\". This forces Databricks to perform a SortMergeJoin.","title":"What Should I do if I cannot broadcast the table that is larger than 8GB?"},{"location":"BestPracticesFAQ/#note-about-changing-spark-configuration","text":"Warning: Changing Spark configuraitons can cause out-of-memory-errors Normal approach: - spark.conf.set(\"configuration\", \"value\") If you do not have permissions to change some configurations, this seems to be a work around: - conf = spark.sparkContext._cibf,setAkk([(\"configuration\", \"value\"), (\"configuration\", \"value\")]) How to get Spark Configuration: - spark.conf.get(\"configuration\") Steps to avoid changing configurations: a. Partition DataFrame A into parts. b. Perform joins with each parittion from DataFrame A with DataFrame B (concurrently is the fastest way but may require writing Dataframes to file for reading in next step). c. Perform a union on all the joined DataFrames.","title":"Note About changing Spark Configuration"},{"location":"BestPracticesFAQ/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"Dashboards/","text":"English Tableaux de bord Les tableaux de bord affichent vos ressources infonuagiques dans le portail Azure de fa\u00e7on pr\u00e9cise et organis\u00e9e. Ils servent d'espace de travail o\u00f9 vous pouvez rapidement lancer des t\u00e2ches pour les op\u00e9rations quotidiennes et surveiller les ressources. Par exemple, vous pouvez cr\u00e9er des tableaux de bord personnalis\u00e9s en fonction des projets, des t\u00e2ches ou des r\u00f4les des utilisateurs. Le portail Azure fournit un tableau de bord par d\u00e9faut comme point de d\u00e9part. Vous pouvez modifier ce dernier, cr\u00e9er et personnaliser des tableaux de bord suppl\u00e9mentaires, ainsi qu'en publier et en partager avec d'autres utilisateurs. Acc\u00e9der au tableau de bord de l'Environnement d'analyse collaborative Dans le menu du portail Azure, s\u00e9lectionnez Tableau de bord . Votre affichage par d\u00e9faut pourrait d\u00e9j\u00e0 \u00eatre r\u00e9gl\u00e9 au tableau de bord. S\u00e9lectionnez la fl\u00e8che \u00e0 c\u00f4t\u00e9 du nom du tableau de bord. S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste affich\u00e9e. Si ce tableau de bord n'est pas dans la liste : a. S\u00e9lectionnez Parcourir tous les tableaux de bord . b. Dans le champ Type , s\u00e9lectionnez Tableaux de bord partag\u00e9s . c. Assurez-vous que \u00ab vdl \u00bb se trouve parmi les abonnements s\u00e9lectionn\u00e9s. Vous pouvez aussi saisir du texte pour filtrer les tableaux de bord par leur nom. d. S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste des tableaux de bord partag\u00e9s. Documentation Microsoft https://docs.microsoft.com/fr-ca/azure/azure-portal/azure-portal-dashboards Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Tableaux de bord"},{"location":"Dashboards/#tableaux-de-bord","text":"Les tableaux de bord affichent vos ressources infonuagiques dans le portail Azure de fa\u00e7on pr\u00e9cise et organis\u00e9e. Ils servent d'espace de travail o\u00f9 vous pouvez rapidement lancer des t\u00e2ches pour les op\u00e9rations quotidiennes et surveiller les ressources. Par exemple, vous pouvez cr\u00e9er des tableaux de bord personnalis\u00e9s en fonction des projets, des t\u00e2ches ou des r\u00f4les des utilisateurs. Le portail Azure fournit un tableau de bord par d\u00e9faut comme point de d\u00e9part. Vous pouvez modifier ce dernier, cr\u00e9er et personnaliser des tableaux de bord suppl\u00e9mentaires, ainsi qu'en publier et en partager avec d'autres utilisateurs.","title":"Tableaux de bord"},{"location":"Dashboards/#acceder-au-tableau-de-bord-de-lenvironnement-danalyse-collaborative","text":"Dans le menu du portail Azure, s\u00e9lectionnez Tableau de bord . Votre affichage par d\u00e9faut pourrait d\u00e9j\u00e0 \u00eatre r\u00e9gl\u00e9 au tableau de bord. S\u00e9lectionnez la fl\u00e8che \u00e0 c\u00f4t\u00e9 du nom du tableau de bord. S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste affich\u00e9e. Si ce tableau de bord n'est pas dans la liste : a. S\u00e9lectionnez Parcourir tous les tableaux de bord . b. Dans le champ Type , s\u00e9lectionnez Tableaux de bord partag\u00e9s . c. Assurez-vous que \u00ab vdl \u00bb se trouve parmi les abonnements s\u00e9lectionn\u00e9s. Vous pouvez aussi saisir du texte pour filtrer les tableaux de bord par leur nom. d. S\u00e9lectionnez le tableau de bord Environnement d'analyse collaborative dans la liste des tableaux de bord partag\u00e9s.","title":"Acc\u00e9der au tableau de bord de l'Environnement d'analyse collaborative"},{"location":"Dashboards/#documentation-microsoft","text":"https://docs.microsoft.com/fr-ca/azure/azure-portal/azure-portal-dashboards","title":"Documentation Microsoft"},{"location":"Dashboards/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"DataBricks/","text":"English Azure Databricks Acc\u00e8s \u00e0 Databricks Tableau de bord Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements. Cliquez sur le menu Tableau de bord dans le portail Azure. Adresse URL de Databricks Rendez-vous au site https://canadacentral.azuredatabricks.net/, ouvrez une session en utilisant vos justificatifs d'identit\u00e9 du compte infonuagique et s\u00e9lectionnez l'espace de travail Databricks qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous. Portail Azure Dans la bo\u00eete de recherche du portail Azure, recherchez Databricks . Vous devriez alors voir une liste des espaces de travail Databricks auxquels vous pouvez acc\u00e9der. Commencer Une fois dans Databricks, vous pouvez cr\u00e9er un carnet ou ouvrir un carnet existant. Pour plus d'information, veuillez consulter le processus \u00e0 suivre pour acc\u00e9der \u00e0 Databricks pour la premi\u00e8re fois . Cr\u00e9ation d'un cluster Si aucun cluster n'a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous ou si vous avez besoin d'apporter des changements \u00e0 votre cluster, veuillez envoyer un message sur Slack , puisque vous n'avez pas la permission de cr\u00e9er un cluster. Note : Vous devez avoir un cluster en mode actif avant de pouvoir ex\u00e9cuter le code dans votre carnet. Pour obtenir des renseignements sur la fa\u00e7on de d\u00e9marrer un cluster, consultez la section ci-dessous ou la FAQ . Cr\u00e9ation d'un carnet Une fa\u00e7on de cr\u00e9er un carnet consiste \u00e0 cliquer sur l'option Nouveau carnet depuis la page principale de Databricks. Vous pouvez ensuite nommer votre carnet et choisir le langage par d\u00e9faut. Dans le champ \u00ab Grappe \u00bb, s\u00e9lectionnez parmis la liste propos\u00e9e le cluster auquel vous souhaitez attacher votre carnet. Pour d\u00e9marrer un cluster ou le modifier \u00e0 partir d'un carnet, ouvrez le carnet et, dans le coin sup\u00e9rieur droit, cliquez sur le menu d\u00e9roulant pour cluster. Vous pourrez alors d\u00e9marrer le cluster ou le d\u00e9tacher et en attacher un autre. Partage de carnets dans Databricks Pour partager un carnet ou inviter d'autres collaborateurs, depuis le menu Espace de travail, faites un clic droit sur le fichier ou le dossier du carnet souhait\u00e9 et s\u00e9lectionnez l'option Autorisations . Vous pouvez \u00e9galement le faire \u00e0 partir d'un carnet, en cliquant sur le bouton Autorisations . Une fois que le carnet aura \u00e9t\u00e9 partag\u00e9, plusieurs auteurs pourront le consulter et le modifier simultan\u00e9ment. Note : Pour ajouter un utilisateur \u00e0 l'espace de travail Databricks, veuillez envoyer un message Slack . Ingestion de donn\u00e9es dans Databricks Les donn\u00e9es peuvent \u00eatre mont\u00e9es ou t\u00e9l\u00e9vers\u00e9es dans le Syst\u00e8me de fichiers Databricks (DBFS), qui est un espace de stockage propre \u00e0 l'espace de travail Databricks. Vous pouvez lire des donn\u00e9es d'une source de donn\u00e9es ou m\u00eame t\u00e9l\u00e9verser un fichier de donn\u00e9es (p. ex. CSV) directement dans le DBFS. Note : Le conteneur interne de lac de donn\u00e9es pour votre environnement a d\u00e9j\u00e0 \u00e9t\u00e9 mont\u00e9 pour vous, et vous pouvez travailler directement avec le conteneur. Si vous ne connaissez pas le nom de votre conteneur de lac de donn\u00e9es, veuillez envoyer un message Slack . Ajout de donn\u00e9es dans Databricks Lecture de fichiers mont\u00e9s Exemple : %python testData = spark . read . format ( ' csv ' ). options ( header = ' true ' , inferSchema = ' true ' ). load ( ' / mnt / mad - du / incoming / age - single - years -2018 - census - csv . csv ' ) display ( testData ) Modification du langage par d\u00e9faut dans un carnet Utilisation de plusieurs langages dans un carnet Vous pouvez changer les param\u00e8tres de langage par d\u00e9faut en entrant la commande sp\u00e9ciale % au d\u00e9but d'une cellule. Les commandes sp\u00e9ciales prises en charge sont les suivantes : %python, %r, %scala et %sql. Note: Lorsque vous utilisez une commande sp\u00e9ciale Langage, celle-ci est distribu\u00e9e \u00e0 la valeur REPL dans le contexte d'ex\u00e9cution du carnet. Les variables d\u00e9finies dans un langage (et par cons\u00e9quent dans la REPL pour ce langage) ne sont pas offertes dans la valeur REPL d'un autre langage. Les valeurs REPL permettent de partager l'\u00e9tat uniquement par l'interm\u00e9diaire de ressources externes, telles que des fichiers dans le DBFS ou des objets stock\u00e9s. Les carnets prennent \u00e9galement en charge quelques commandes sp\u00e9ciales auxiliaires: Vous permet d'ex\u00e9cuter du code Shell dans votre carnet. Pour faire \u00e9chouer la cellule si la commande Shell a un \u00e9tat de sortie diff\u00e9rent de z\u00e9ro, ajoutez l'-e option. Cette commande s'ex\u00e9cute uniquement sur le pilote Apache Spark, et non sur les processus de travail. Pour ex\u00e9cuter une commande Shell sur tous les n\u0153uds, utilisez un script d'initialisation (script init). Vous permet d'utiliser des commandes de type syst\u00e8me de fichiers (dbutils). Vous permet d'inclure diff\u00e9rents types de documentation, notamment du texte, des images ainsi que des formules et des \u00e9quations math\u00e9matiques. D\u00e9marrage de clusters dans Databricks Cliquez sur la liste d\u00e9roulante de clusters. S\u00e9lectionnez un cluster \u00e0 partir de cette liste. Cliquez sur le bouton D\u00e9but pour d\u00e9marrer le cluster. Configuration de Databricks Connect sur une machine virtuelle Databricks connect permet l'acc\u00e8s \u00e0 un environnement Databricks sans avoir besoin de se connecter via le portail Azure ou l'IU Databricks. Il permet d'utiliser d'autres EDI pour travailler du code Databricks. Voici les \u00e9tapes pour installer et tester Databricks Connect sur votre machine virtuelle: Il y a un conflit entre Databricks Connect et l'installation Pyspark qui se trouve sur les images Data Science Virtual Machine. Par d\u00e9faut, cette installation de Pyspark se trouve dans C:\\dsvm\\tools\\spark-2.4.4-bin-hadoop2.7 . Veuillez supprimer ou d\u00e9placer ce dossier afin d'installer Databricks Connect. Avant d'installer Databricks Connect, cr\u00e9ez un environment conda. Pour ce faire, ouvrez une invite de commandes et execut\u00e9z les commandes suivantes: conda create -- name dbconnect python = 3 . 7 conda activate dbconnect type pip install - U databricks - connect == X . Y . * REMARQUE: Remplacez X et Y avec le num\u00e9ro de version de votre cluster Databricks. Vous pouvez trouvez cette valeur en ouvrant l'espace de travail Databricks du portail Azure. Cliquez sur Clusters dans le menu \u00e0 gauche, et notez la version Runtime pour votre cluster. Dans une invite de commandes, entrez databricks-connect configure , et entez les valeurs suivantes quand demand\u00e9es: H\u00f4te Databricks: https//:canadacentral.azuredatabricks.net Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks ID du cluster : la valeur indiqu\u00e9e sous Instance de calcul --> Options avanc\u00e9es--> \u00c9tiquettes dans votre espace de travail Databricks ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= Port : conserver la valeur existante Changez la valeur de la variable d'environnement SPARK_HOME \u00e0 c:\\miniconda\\envs\\(conda env name))\\lib\\site-packages\\pyspark , et red\u00e9marrez votre machine virtuelle. (Veuillez demander de l'aide via un message Slack si vous ne savez pas comment changer des variables d'environnement.) Testez la connectivit\u00e9 avec Azure Databricks en ex\u00e9cutant databricks-connect test dans une invite de commandes. Si votre cluster Databricks est arr\u00eat\u00e9 quand vous commencez ce test, vous recevrez des messages d'avertissement jusqu'\u00e0 ce qu'il ait d\u00e9marr\u00e9, ce qui peut prendre du temps. Installation de librairies Cluster Databricks Veuillez contacter le canal [slack] (https://cae-eac.slack.com) pour que l'\u00e9quipe d'assistance puisse installer les librairies pour vous. Carnet Veuillez utiliser les commandes suivantes pour installer une librairie dans une session de carnet. Python: dbutils . library . installPyPI ( \"pypipackage\" , version = \"version\" , repo = \"repo\" , extras = \"extras\" ) dbutils . library . restartPython () # Supprime l'\u00e9tat Python, mais certaines biblioth\u00e8ques peuvent ne pas fonctionner sans appeler cette fonction R Code: install.packages ( \"library\" ) Documentation Microsoft Acc\u00e9der \u00e0 Databricks pour la premi\u00e8re fois En savoir plus sur Databricks (en anglais seulement) Databricks Connect (en anglais seulement) Installer des biblioth\u00e8ques dans la session active d'un carnet Gestion des biblioth\u00e8ques pour les administrateurs Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Databricks"},{"location":"DataBricks/#azure-databricks","text":"","title":"Azure\u00a0Databricks"},{"location":"DataBricks/#acces-a-databricks","text":"","title":"Acc\u00e8s \u00e0 Databricks"},{"location":"DataBricks/#tableau-de-bord","text":"Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements. Cliquez sur le menu Tableau de bord dans le portail Azure.","title":"Tableau de bord"},{"location":"DataBricks/#adresse-url-de-databricks","text":"Rendez-vous au site https://canadacentral.azuredatabricks.net/, ouvrez une session en utilisant vos justificatifs d'identit\u00e9 du compte infonuagique et s\u00e9lectionnez l'espace de travail Databricks qui a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous.","title":"Adresse\u00a0URL de Databricks"},{"location":"DataBricks/#portail-azure","text":"Dans la bo\u00eete de recherche du portail Azure, recherchez Databricks . Vous devriez alors voir une liste des espaces de travail Databricks auxquels vous pouvez acc\u00e9der.","title":"Portail\u00a0Azure"},{"location":"DataBricks/#commencer","text":"Une fois dans Databricks, vous pouvez cr\u00e9er un carnet ou ouvrir un carnet existant. Pour plus d'information, veuillez consulter le processus \u00e0 suivre pour acc\u00e9der \u00e0 Databricks pour la premi\u00e8re fois .","title":"Commencer"},{"location":"DataBricks/#creation-dun-cluster","text":"Si aucun cluster n'a \u00e9t\u00e9 cr\u00e9\u00e9 pour vous ou si vous avez besoin d'apporter des changements \u00e0 votre cluster, veuillez envoyer un message sur Slack , puisque vous n'avez pas la permission de cr\u00e9er un cluster. Note : Vous devez avoir un cluster en mode actif avant de pouvoir ex\u00e9cuter le code dans votre carnet. Pour obtenir des renseignements sur la fa\u00e7on de d\u00e9marrer un cluster, consultez la section ci-dessous ou la FAQ .","title":"Cr\u00e9ation d'un cluster"},{"location":"DataBricks/#creation-dun-carnet","text":"Une fa\u00e7on de cr\u00e9er un carnet consiste \u00e0 cliquer sur l'option Nouveau carnet depuis la page principale de Databricks. Vous pouvez ensuite nommer votre carnet et choisir le langage par d\u00e9faut. Dans le champ \u00ab Grappe \u00bb, s\u00e9lectionnez parmis la liste propos\u00e9e le cluster auquel vous souhaitez attacher votre carnet. Pour d\u00e9marrer un cluster ou le modifier \u00e0 partir d'un carnet, ouvrez le carnet et, dans le coin sup\u00e9rieur droit, cliquez sur le menu d\u00e9roulant pour cluster. Vous pourrez alors d\u00e9marrer le cluster ou le d\u00e9tacher et en attacher un autre.","title":"Cr\u00e9ation d'un carnet"},{"location":"DataBricks/#partage-de-carnets-dans-databricks","text":"Pour partager un carnet ou inviter d'autres collaborateurs, depuis le menu Espace de travail, faites un clic droit sur le fichier ou le dossier du carnet souhait\u00e9 et s\u00e9lectionnez l'option Autorisations . Vous pouvez \u00e9galement le faire \u00e0 partir d'un carnet, en cliquant sur le bouton Autorisations . Une fois que le carnet aura \u00e9t\u00e9 partag\u00e9, plusieurs auteurs pourront le consulter et le modifier simultan\u00e9ment. Note : Pour ajouter un utilisateur \u00e0 l'espace de travail Databricks, veuillez envoyer un message Slack .","title":"Partage de carnets dans Databricks"},{"location":"DataBricks/#ingestion-de-donnees-dans-databricks","text":"Les donn\u00e9es peuvent \u00eatre mont\u00e9es ou t\u00e9l\u00e9vers\u00e9es dans le Syst\u00e8me de fichiers Databricks (DBFS), qui est un espace de stockage propre \u00e0 l'espace de travail Databricks. Vous pouvez lire des donn\u00e9es d'une source de donn\u00e9es ou m\u00eame t\u00e9l\u00e9verser un fichier de donn\u00e9es (p. ex. CSV) directement dans le DBFS. Note : Le conteneur interne de lac de donn\u00e9es pour votre environnement a d\u00e9j\u00e0 \u00e9t\u00e9 mont\u00e9 pour vous, et vous pouvez travailler directement avec le conteneur. Si vous ne connaissez pas le nom de votre conteneur de lac de donn\u00e9es, veuillez envoyer un message Slack .","title":"Ingestion de donn\u00e9es dans Databricks"},{"location":"DataBricks/#ajout-de-donnees-dans-databricks","text":"","title":"Ajout de donn\u00e9es dans Databricks"},{"location":"DataBricks/#lecture-de-fichiers-montes","text":"Exemple : %python testData = spark . read . format ( ' csv ' ). options ( header = ' true ' , inferSchema = ' true ' ). load ( ' / mnt / mad - du / incoming / age - single - years -2018 - census - csv . csv ' ) display ( testData )","title":"Lecture de fichiers mont\u00e9s"},{"location":"DataBricks/#modification-du-langage-par-defaut-dans-un-carnet","text":"","title":"Modification du langage par d\u00e9faut dans un carnet"},{"location":"DataBricks/#utilisation-de-plusieurs-langages-dans-un-carnet","text":"Vous pouvez changer les param\u00e8tres de langage par d\u00e9faut en entrant la commande sp\u00e9ciale % au d\u00e9but d'une cellule. Les commandes sp\u00e9ciales prises en charge sont les suivantes : %python, %r, %scala et %sql. Note: Lorsque vous utilisez une commande sp\u00e9ciale Langage, celle-ci est distribu\u00e9e \u00e0 la valeur REPL dans le contexte d'ex\u00e9cution du carnet. Les variables d\u00e9finies dans un langage (et par cons\u00e9quent dans la REPL pour ce langage) ne sont pas offertes dans la valeur REPL d'un autre langage. Les valeurs REPL permettent de partager l'\u00e9tat uniquement par l'interm\u00e9diaire de ressources externes, telles que des fichiers dans le DBFS ou des objets stock\u00e9s. Les carnets prennent \u00e9galement en charge quelques commandes sp\u00e9ciales auxiliaires: Vous permet d'ex\u00e9cuter du code Shell dans votre carnet. Pour faire \u00e9chouer la cellule si la commande Shell a un \u00e9tat de sortie diff\u00e9rent de z\u00e9ro, ajoutez l'-e option. Cette commande s'ex\u00e9cute uniquement sur le pilote Apache Spark, et non sur les processus de travail. Pour ex\u00e9cuter une commande Shell sur tous les n\u0153uds, utilisez un script d'initialisation (script init). Vous permet d'utiliser des commandes de type syst\u00e8me de fichiers (dbutils). Vous permet d'inclure diff\u00e9rents types de documentation, notamment du texte, des images ainsi que des formules et des \u00e9quations math\u00e9matiques.","title":"Utilisation de plusieurs langages dans un carnet"},{"location":"DataBricks/#demarrage-de-clusters-dans-databricks","text":"Cliquez sur la liste d\u00e9roulante de clusters. S\u00e9lectionnez un cluster \u00e0 partir de cette liste. Cliquez sur le bouton D\u00e9but pour d\u00e9marrer le cluster.","title":"D\u00e9marrage de clusters dans Databricks"},{"location":"DataBricks/#configuration-de-databricks-connect-sur-une-machine-virtuelle","text":"Databricks connect permet l'acc\u00e8s \u00e0 un environnement Databricks sans avoir besoin de se connecter via le portail Azure ou l'IU Databricks. Il permet d'utiliser d'autres EDI pour travailler du code Databricks. Voici les \u00e9tapes pour installer et tester Databricks Connect sur votre machine virtuelle: Il y a un conflit entre Databricks Connect et l'installation Pyspark qui se trouve sur les images Data Science Virtual Machine. Par d\u00e9faut, cette installation de Pyspark se trouve dans C:\\dsvm\\tools\\spark-2.4.4-bin-hadoop2.7 . Veuillez supprimer ou d\u00e9placer ce dossier afin d'installer Databricks Connect. Avant d'installer Databricks Connect, cr\u00e9ez un environment conda. Pour ce faire, ouvrez une invite de commandes et execut\u00e9z les commandes suivantes: conda create -- name dbconnect python = 3 . 7 conda activate dbconnect type pip install - U databricks - connect == X . Y . * REMARQUE: Remplacez X et Y avec le num\u00e9ro de version de votre cluster Databricks. Vous pouvez trouvez cette valeur en ouvrant l'espace de travail Databricks du portail Azure. Cliquez sur Clusters dans le menu \u00e0 gauche, et notez la version Runtime pour votre cluster. Dans une invite de commandes, entrez databricks-connect configure , et entez les valeurs suivantes quand demand\u00e9es: H\u00f4te Databricks: https//:canadacentral.azuredatabricks.net Jeton : le jeton d\u2019acc\u00e8s personnel g\u00e9n\u00e9r\u00e9 dans les param\u00e8tres utilisateur de votre espace de travail Databricks ID du cluster : la valeur indiqu\u00e9e sous Instance de calcul --> Options avanc\u00e9es--> \u00c9tiquettes dans votre espace de travail Databricks ID de l\u2019organisation : la partie de l\u2019URL de Databricks qui se trouve apr\u00e8s .net/?o= Port : conserver la valeur existante Changez la valeur de la variable d'environnement SPARK_HOME \u00e0 c:\\miniconda\\envs\\(conda env name))\\lib\\site-packages\\pyspark , et red\u00e9marrez votre machine virtuelle. (Veuillez demander de l'aide via un message Slack si vous ne savez pas comment changer des variables d'environnement.) Testez la connectivit\u00e9 avec Azure Databricks en ex\u00e9cutant databricks-connect test dans une invite de commandes. Si votre cluster Databricks est arr\u00eat\u00e9 quand vous commencez ce test, vous recevrez des messages d'avertissement jusqu'\u00e0 ce qu'il ait d\u00e9marr\u00e9, ce qui peut prendre du temps.","title":"Configuration de Databricks Connect sur une machine virtuelle"},{"location":"DataBricks/#installation-de-librairies","text":"","title":"Installation de librairies"},{"location":"DataBricks/#cluster-databricks","text":"Veuillez contacter le canal [slack] (https://cae-eac.slack.com) pour que l'\u00e9quipe d'assistance puisse installer les librairies pour vous.","title":"Cluster Databricks"},{"location":"DataBricks/#carnet","text":"Veuillez utiliser les commandes suivantes pour installer une librairie dans une session de carnet. Python: dbutils . library . installPyPI ( \"pypipackage\" , version = \"version\" , repo = \"repo\" , extras = \"extras\" ) dbutils . library . restartPython () # Supprime l'\u00e9tat Python, mais certaines biblioth\u00e8ques peuvent ne pas fonctionner sans appeler cette fonction R Code: install.packages ( \"library\" )","title":"Carnet"},{"location":"DataBricks/#documentation-microsoft","text":"Acc\u00e9der \u00e0 Databricks pour la premi\u00e8re fois En savoir plus sur Databricks (en anglais seulement) Databricks Connect (en anglais seulement) Installer des biblioth\u00e8ques dans la session active d'un carnet Gestion des biblioth\u00e8ques pour les administrateurs","title":"Documentation Microsoft"},{"location":"DataBricks/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"DataFactory/","text":"English Azure Data Factory (ADF) Acc\u00e8s \u00e0 Data Factory Tableau de bord Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements. Cliquez sur le menu Tableau de bord dans le portail Azure. ADRESSE URL D'ADF Rendez-vous \u00e0 https://adf.azure.com et s\u00e9lectionnez l'instance Data Factory qui a \u00e9t\u00e9 cr\u00e9\u00e9e pour vous. Portail Azure Dans la bo\u00eete de recherche du portail Azure, recherchez Data factories . Vous devriez alors voir la liste des Data Factories auxquelles vous avez obtenu la permission d'acc\u00e9der. Auteur Cliquez sur Author & Monitor . Dans Data Factory, vous avez la capacit\u00e9 de cr\u00e9er et de d\u00e9ployer des ressources. Voir le document Cr\u00e9ation visuelle dans Azure Data Factory pour obtenir de plus amples renseignements. Vous pouvez \u00e9galement utiliser certains des divers assistants fournis sur la page d' aper\u00e7u (Overview) de Data Factory . NOTE : La configuration de SSIS Integration n'est PAS recommand\u00e9e. Si vous avez des questions, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack . les tutoriels de la documentation Azure pour obtenir plus de d\u00e9tails. Acc\u00e8s \u00e0 Data Lake \u00e0 partir d'ADF Une connexion au compte de stockage Data Lake a \u00e9t\u00e9 pr\u00e9configur\u00e9e pour votre environnement. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Services li\u00e9s . Le service li\u00e9 au type Stockage Azure Data Lake Gen2 est votre compte de stockage Data Lake . Note : On vous a accord\u00e9 l'acc\u00e8s \u00e0 des contenants particuliers cr\u00e9\u00e9s dans le compte de stockage Data Lake pour votre environnement. Acc\u00e8s \u00e0 la Base de donn\u00e9es SQL Azure Certains projets ont une instance de Base de donn\u00e9es SQL Azure. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Services li\u00e9s . Les services li\u00e9s au type Base de donn\u00e9es SQL Azure sont vos bases de donn\u00e9es . Enregistrement ou publication de vos ressources dans Data Factory Azure Data Factory peut \u00eatre configur\u00e9 pour enregistrer votre travail dans les emplacements suivants: D\u00e9p\u00f4t Git Publier directement dans Data Factory Git (lorsqu'accessible) Lorsque Git est activ\u00e9, vous pouvez voir votre configuration et enregistrer votre travail dans une branche particuli\u00e8re. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Configuration de Git . V\u00e9rifiez la configuration de Git qui a \u00e9t\u00e9 mise en place pour vous. Lorsque vous cr\u00e9ez un flux de travail, vous pouvez l'enregistrer dans votre branche. Cliquez sur + Nouvelle branche dans le menu d\u00e9roulant des branches pour cr\u00e9er une branche de fonctionnalit\u00e9s. Lorsque vous serez pr\u00eat \u00e0 fusionner les changements de votre branche de fonctionnalit\u00e9s dans votre branche de collaboration (master), cliquez sur le menu d\u00e9roulant des branches et s\u00e9lectionnez Cr\u00e9er la demande de tirage (pull request) . Cette action vous dirigera vers Azure DevOps Git, o\u00f9 vous pourrez cr\u00e9er des demandes de tirage, proc\u00e9der \u00e0 des revues du code et fusionner les modifications dans votre branche de collaboration (master) d\u00e8s que la demande aura \u00e9t\u00e9 approuv\u00e9e. Apr\u00e8s avoir fusionn\u00e9 les modifications dans la branche de collaboration (master), cliquez sur Publier pour publier les changements de votre code de la branche dans Azure Data Factory. Si vous obtenez un message d'erreur au moment de la publication, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack . Service Data Factory Lorsque Data Factory n'est pas int\u00e9gr\u00e9 au contr\u00f4le source, vos flux de travail sont stock\u00e9s directement dans le service Data Factory. Vous ne pouvez pas enregistrer les changements partiels, vous pouvez seulement utiliser l'option Tout publier , ce qui \u00e9crase l'\u00e9tat actuel de Data Factory avec vos changements qui deviennent alors visibles \u00e0 tous. Ingestion et transformation des donn\u00e9es avec ADF Assistant de copie de donn\u00e9es Mappage de flux de donn\u00e9es -- Processus ETC ax\u00e9 sur l'interface utilisateur graphique Runtimes d'int\u00e9gration AutoResolveIntegrationRuntime Ne pas utiliser. Veuillez utiliser les runtimes d'int\u00e9gration canadaCentralIR-4nodesDataFlow ou selfHostedCovidIaaSVnet au lieu. Le runtime d'int\u00e9gration de r\u00e9solution automatique (\"auto resolve\") est cr\u00e9\u00e9 par d\u00e9faut avec le Data Factory, et va s\u00e9lectionner le centre de donn\u00e9es Azure le plus pr\u00e8s des donn\u00e9es, ce qui pourrait contrevenir aux politiques de r\u00e9sidence des donn\u00e9es. canadaCentralIR-4nodesDataFlow Ceci est partag\u00e9 par tous les utilisateurs et fonctionne tout le temps. Peut acc\u00e9der: Lac de donn\u00e9es interne Compte de stockage externe Sources de donn\u00e9es externes (Internet) Ne peut pas acc\u00e9der: Base de donn\u00e9es Azure SQL selfHostedCovidIaaSVnet Situ\u00e9 \u00e0 l'int\u00e9rieur du r\u00e9seau virtuel interne. Peut acc\u00e9der: Lac de donn\u00e9es interne Base de donn\u00e9es Azure SQL Ne peut pas acc\u00e9der: Compte de stockage externe Sources de donn\u00e9es externes (Internet) Exemple : Comment se connecter aux donn\u00e9es de John Hopkins Il y a un exemple de flux de travail qui montre la fa\u00e7on d'ing\u00e9rer des donn\u00e9es \u00e0 partir de GitHub \u00e0 l'aide d'un pipeline de Data Factory. Les donn\u00e9es peuvent \u00eatre filtr\u00e9es depuis Data Factory. Il est aussi possible d'extraire des donn\u00e9es de GitHub au moyen d'un code dans un notebook de Databricks. Documentation Microsoft Pr\u00e9sentation d'Azure Data Factory -- Azure Data Factory Cr\u00e9er une fabrique de donn\u00e9es Azure \u00e0 l'aide de l'interface utilisateur d'Azure Data Factory -- Azure Data Factory Copier des donn\u00e9es avec l'outil d'Azure Copier des donn\u00e9es -- Azure Data Factory Cr\u00e9er un flux de donn\u00e9es de mappage -- Azure Data Factory Fonctions d'expression dans le flux de donn\u00e9es de mappage --Azure Data Factory Mode de d\u00e9bogage du mappage de flux de donn\u00e9es -- Azure Data Factory Supervision visuelle du flux de donn\u00e9es de mappage -- Azure Data Factory Vid\u00e9o YouTube (en anglais seulement) Ingest, prepare & transform using Azure Databricks & Data Factory Azure Friday Azure Friday Visually build pipelines for Azure Data Factory V2 How to prepare data using wrangling data flows in Azure Data Factory Azure Friday How to develop and debug with Azure Data Factory Azure Friday Building Data Flows in Azure Data Factory Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Data Factory"},{"location":"DataFactory/#azure-data-factory-adf","text":"","title":"Azure\u00a0Data\u00a0Factory (ADF)"},{"location":"DataFactory/#acces-a-data-factory","text":"","title":"Acc\u00e8s \u00e0 Data\u00a0Factory"},{"location":"DataFactory/#tableau-de-bord","text":"Consultez la section Tableau de bord de cette documentation pour obtenir de plus amples renseignements. Cliquez sur le menu Tableau de bord dans le portail Azure.","title":"Tableau de bord"},{"location":"DataFactory/#adresse-url-dadf","text":"Rendez-vous \u00e0 https://adf.azure.com et s\u00e9lectionnez l'instance Data Factory qui a \u00e9t\u00e9 cr\u00e9\u00e9e pour vous.","title":"ADRESSE\u00a0URL D'ADF"},{"location":"DataFactory/#portail-azure","text":"Dans la bo\u00eete de recherche du portail Azure, recherchez Data factories . Vous devriez alors voir la liste des Data Factories auxquelles vous avez obtenu la permission d'acc\u00e9der.","title":"Portail\u00a0Azure"},{"location":"DataFactory/#auteur","text":"Cliquez sur Author & Monitor . Dans Data Factory, vous avez la capacit\u00e9 de cr\u00e9er et de d\u00e9ployer des ressources. Voir le document Cr\u00e9ation visuelle dans Azure Data Factory pour obtenir de plus amples renseignements. Vous pouvez \u00e9galement utiliser certains des divers assistants fournis sur la page d' aper\u00e7u (Overview) de Data Factory . NOTE : La configuration de SSIS Integration n'est PAS recommand\u00e9e. Si vous avez des questions, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack . les tutoriels de la documentation Azure pour obtenir plus de d\u00e9tails.","title":"Auteur"},{"location":"DataFactory/#acces-a-data-lake-a-partir-dadf","text":"Une connexion au compte de stockage Data Lake a \u00e9t\u00e9 pr\u00e9configur\u00e9e pour votre environnement. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Services li\u00e9s . Le service li\u00e9 au type Stockage Azure Data Lake Gen2 est votre compte de stockage Data Lake . Note : On vous a accord\u00e9 l'acc\u00e8s \u00e0 des contenants particuliers cr\u00e9\u00e9s dans le compte de stockage Data Lake pour votre environnement.","title":"Acc\u00e8s \u00e0 Data\u00a0Lake \u00e0 partir d'ADF"},{"location":"DataFactory/#acces-a-la-base-de-donnees-sql-azure","text":"Certains projets ont une instance de Base de donn\u00e9es SQL Azure. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Services li\u00e9s . Les services li\u00e9s au type Base de donn\u00e9es SQL Azure sont vos bases de donn\u00e9es .","title":"Acc\u00e8s \u00e0 la Base de donn\u00e9es SQL\u00a0Azure"},{"location":"DataFactory/#enregistrement-ou-publication-de-vos-ressources-dans-data-factory","text":"Azure Data Factory peut \u00eatre configur\u00e9 pour enregistrer votre travail dans les emplacements suivants: D\u00e9p\u00f4t Git Publier directement dans Data Factory","title":"Enregistrement ou publication de vos ressources dans Data\u00a0Factory"},{"location":"DataFactory/#git-lorsquaccessible","text":"Lorsque Git est activ\u00e9, vous pouvez voir votre configuration et enregistrer votre travail dans une branche particuli\u00e8re. Cliquez sur l' ic\u00f4ne de la mallette . Cliquez sur Configuration de Git . V\u00e9rifiez la configuration de Git qui a \u00e9t\u00e9 mise en place pour vous. Lorsque vous cr\u00e9ez un flux de travail, vous pouvez l'enregistrer dans votre branche. Cliquez sur + Nouvelle branche dans le menu d\u00e9roulant des branches pour cr\u00e9er une branche de fonctionnalit\u00e9s. Lorsque vous serez pr\u00eat \u00e0 fusionner les changements de votre branche de fonctionnalit\u00e9s dans votre branche de collaboration (master), cliquez sur le menu d\u00e9roulant des branches et s\u00e9lectionnez Cr\u00e9er la demande de tirage (pull request) . Cette action vous dirigera vers Azure DevOps Git, o\u00f9 vous pourrez cr\u00e9er des demandes de tirage, proc\u00e9der \u00e0 des revues du code et fusionner les modifications dans votre branche de collaboration (master) d\u00e8s que la demande aura \u00e9t\u00e9 approuv\u00e9e. Apr\u00e8s avoir fusionn\u00e9 les modifications dans la branche de collaboration (master), cliquez sur Publier pour publier les changements de votre code de la branche dans Azure Data Factory. Si vous obtenez un message d'erreur au moment de la publication, communiquez avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal Slack .","title":"Git (lorsqu'accessible)"},{"location":"DataFactory/#service-data-factory","text":"Lorsque Data Factory n'est pas int\u00e9gr\u00e9 au contr\u00f4le source, vos flux de travail sont stock\u00e9s directement dans le service Data Factory. Vous ne pouvez pas enregistrer les changements partiels, vous pouvez seulement utiliser l'option Tout publier , ce qui \u00e9crase l'\u00e9tat actuel de Data Factory avec vos changements qui deviennent alors visibles \u00e0 tous.","title":"Service Data\u00a0Factory"},{"location":"DataFactory/#ingestion-et-transformation-des-donnees-avec-adf","text":"Assistant de copie de donn\u00e9es Mappage de flux de donn\u00e9es -- Processus ETC ax\u00e9 sur l'interface utilisateur graphique","title":"Ingestion et transformation des donn\u00e9es avec ADF"},{"location":"DataFactory/#runtimes-dintegration","text":"","title":"Runtimes d'int\u00e9gration"},{"location":"DataFactory/#autoresolveintegrationruntime","text":"Ne pas utiliser. Veuillez utiliser les runtimes d'int\u00e9gration canadaCentralIR-4nodesDataFlow ou selfHostedCovidIaaSVnet au lieu. Le runtime d'int\u00e9gration de r\u00e9solution automatique (\"auto resolve\") est cr\u00e9\u00e9 par d\u00e9faut avec le Data Factory, et va s\u00e9lectionner le centre de donn\u00e9es Azure le plus pr\u00e8s des donn\u00e9es, ce qui pourrait contrevenir aux politiques de r\u00e9sidence des donn\u00e9es.","title":"AutoResolveIntegrationRuntime"},{"location":"DataFactory/#canadacentralir-4nodesdataflow","text":"Ceci est partag\u00e9 par tous les utilisateurs et fonctionne tout le temps.","title":"canadaCentralIR-4nodesDataFlow"},{"location":"DataFactory/#peut-acceder","text":"Lac de donn\u00e9es interne Compte de stockage externe Sources de donn\u00e9es externes (Internet)","title":"Peut acc\u00e9der:"},{"location":"DataFactory/#ne-peut-pas-acceder","text":"Base de donn\u00e9es Azure SQL","title":"Ne peut pas acc\u00e9der:"},{"location":"DataFactory/#selfhostedcovidiaasvnet","text":"Situ\u00e9 \u00e0 l'int\u00e9rieur du r\u00e9seau virtuel interne.","title":"selfHostedCovidIaaSVnet"},{"location":"DataFactory/#peut-acceder_1","text":"Lac de donn\u00e9es interne Base de donn\u00e9es Azure SQL","title":"Peut acc\u00e9der:"},{"location":"DataFactory/#ne-peut-pas-acceder_1","text":"Compte de stockage externe Sources de donn\u00e9es externes (Internet)","title":"Ne peut pas acc\u00e9der:"},{"location":"DataFactory/#exemple-comment-se-connecter-aux-donnees-de-john-hopkins","text":"Il y a un exemple de flux de travail qui montre la fa\u00e7on d'ing\u00e9rer des donn\u00e9es \u00e0 partir de GitHub \u00e0 l'aide d'un pipeline de Data Factory. Les donn\u00e9es peuvent \u00eatre filtr\u00e9es depuis Data Factory. Il est aussi possible d'extraire des donn\u00e9es de GitHub au moyen d'un code dans un notebook de Databricks.","title":"Exemple\u00a0: Comment se connecter aux donn\u00e9es de John\u00a0Hopkins"},{"location":"DataFactory/#documentation-microsoft","text":"Pr\u00e9sentation d'Azure Data Factory -- Azure Data Factory Cr\u00e9er une fabrique de donn\u00e9es Azure \u00e0 l'aide de l'interface utilisateur d'Azure Data Factory -- Azure Data Factory Copier des donn\u00e9es avec l'outil d'Azure Copier des donn\u00e9es -- Azure Data Factory Cr\u00e9er un flux de donn\u00e9es de mappage -- Azure Data Factory Fonctions d'expression dans le flux de donn\u00e9es de mappage --Azure Data Factory Mode de d\u00e9bogage du mappage de flux de donn\u00e9es -- Azure Data Factory Supervision visuelle du flux de donn\u00e9es de mappage -- Azure Data Factory Vid\u00e9o YouTube (en anglais seulement) Ingest, prepare & transform using Azure Databricks & Data Factory Azure Friday Azure Friday Visually build pipelines for Azure Data Factory V2 How to prepare data using wrangling data flows in Azure Data Factory Azure Friday How to develop and debug with Azure Data Factory Azure Friday Building Data Flows in Azure Data Factory","title":"Documentation Microsoft"},{"location":"DataFactory/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"FAQ/","text":"English FAQ Ingestion de donn\u00e9es Comment puis-je ing\u00e9rer des donn\u00e9es (y compris des fichiers volumineux) dans la plateforme? Compte de stockage externe Les fichiers peuvent \u00eatre t\u00e9l\u00e9vers\u00e9s dans dans le conteneur inbox ou to-vers-int d'un compte de stockage externe, comme indiqu\u00e9 dans l'[ Explorateur de stockage Azure ] (AzureStorage.md). Ces fichiers seront alors automatiquement transf\u00e9r\u00e9s dans un compte de stockage interne (Data Lake) et rendus accessibles \u00e0 partir des services autoris\u00e9s. Remarque: Les comptes de stockage externe ont la convention de d\u00e9nomination stats project-acronym external . Service de transfert \u00e9lectronique de fichiers (TEF) Les employ\u00e9s de Statistique Canada peuvent utiliser le TEF pour transf\u00e9rer des fichiers de / vers les r\u00e9seaux sur site (R\u00e9s. A ou B) vers / depuis l'environnement infonuagique Azure. Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com pour plus d'information sur ce processus. Outils de plateforme Des outils de plateforme comme Databricks ou Data Factory peuvent \u00eatre utilis\u00e9s pour ing\u00e9rer des donn\u00e9es provenant de sources dedonn\u00e9es publiques. Explorateur de stockage Comment puis-je configurer les param\u00e8tres du proxy de l'Explorateur de stockage Azure sur un VDI du r\u00e9seau B? Pour les employ\u00e9s de Statistique Canada seulement 1. La configuration des param\u00e8tres du proxy est n\u00e9cessaire, si vous recevez le message d'erreur suivant : Dans l'Explorateur de stockage Azure, allez \u00e0 Modifier Param\u00e8tres du proxy . Entrez les param\u00e8tres du proxy n\u00e9cessaires et cliquez sur OK . Comment puis-je demander un nouveau jeton SAP (requis pour l'Explorateur de stockage Azure sur un VDI du r\u00e9seau B)? Pour les employ\u00e9s de Statistique Canada seulement Pour demander un jeton SAP temporaire, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Pourquoi est-ce que j'obtiens un message d'erreur lorsque j'acc\u00e8de au compte de stockage interne Data Lake? Le compte de stockage interne Data Lake n'est accessible qu'\u00e0 partir d'une machine virtuelle dans l'Environnement d'analyse collaboratif (EAC). Il n'est pas accessible \u00e0 partir de votre ordinateur personnel, ni de votre ordinateur portable de travail, ni du VDI du r\u00e9seau B, ni d'une autre machine virtuelle sur nuage. Contr\u00f4le de code source Comment puis-je relier mon compte Visual Studio \u00e0 mon compte infonuagique de StatCan? Connectez-vous \u00e0 votre compte Visual Studio sur le site https://visualstudio.microsoft.com/fr/subscriptions/ en utilisant l'adresse \u00e9lectronique de votre organisation. Pour les employ\u00e9s de StatCan, il s'agit de votre adresse \u00e9lectronique qui se termine par \u00ab canada.ca \u00bb. Ajoutez votre compte infonuagique comme compte secondaire. Vous pourrez ainsi utiliser vos licences pour Visual Studio et Azure DevOps dans l'EAC. Pour les employ\u00e9s de Statistique Canada : Si vous n'avez pas d'abonnement Visual Studio, veuillez communiquer avec votre superviseur. S'il d\u00e9cide que vous avez besoin d'un abonnement, il pourra alors soumettre une demande de soutien en votre nom aupr\u00e8s de la Gestion des biens logiciels de StatCan pour vous obtenir une licence. Machines virtuelles Que dois-je faire si j'ai oubli\u00e9 le mot de passe de ma machine virtuelle? Si vous oubliez le mot de passe de votre machine virtuelle, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com pour r\u00e9initialiser votre mot de passe. Vous pouvez \u00e9galement supprimer votre machine virtuelle, puis en cr\u00e9er une autre. Ce faisant, vous perdrez malheureusement les donn\u00e9es et les logiciels sur votre ancienne machine. Que dois-je faire si je dois ex\u00e9cuter un travail de longue dur\u00e9e sur ma machine virtuelle? Les machines sont arr\u00eat\u00e9es tous les jours \u00e0 19 h (HNE), afin de r\u00e9duire les frais d'exploitation. Pour ex\u00e9cuter un travail de longue dur\u00e9e, il est recommand\u00e9 d'utiliser Databricks ou Data Factory. AVERTISSEMENT : Il n'est pas recommand\u00e9 de d\u00e9sactiver l'arr\u00eat automatique, car cela pourrait entra\u00eener des frais importants. Pour d\u00e9sactiver l'arr\u00eat automatique : Acc\u00e9dez \u00e0 votre machine virtuelle dans le portail Azure. D\u00e9sactivez l'arr\u00eat automatique. Comment puis-je apporter des changements \u00e0 ma machine virtuelle? Si la machine virtuelle que vous utilisez actuellement ne r\u00e9pond pas \u00e0 vos besoins, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Databricks Pourquoi suis-je incapable d'ex\u00e9cuter le code \u00e0 partir de mon notebook dans Databricks? Vous devez d'abord d\u00e9marrer un cluster dans Databricks qui a d\u00e9j\u00e0 \u00e9t\u00e9 cr\u00e9\u00e9 pour vous : 1. Cliquez sur Clusters. Naviguez vers votre cluster et cliquez sur le bouton D\u00e9marrer (ic\u00f4ne de la fl\u00e8che). Quels types de clusters sont disponibles dans Databricks? Voir le lien suivant pour les diff\u00e9rents types de clusters disponibles: https://docs.microsoft.com/en-us/azure/databricks/release-notes/runtime/releases#:~:text=Supported%20Databricks%20runtime%20releases%20and%20support%20schedule%20,Sep%2002%2C%202021%20%2022%20more%20rows%20 Que se passe-t-il lorsque les clusters sont mis \u00e0 niveau? LTS (support \u00e0 long terme) a un support pendant 1-2 ans. Ils devront \u00eatre p\u00e9riodiquement mis \u00e0 jour vers une version plus r\u00e9cente. Lors de la mise \u00e0 niveau, tout le code doit \u00eatre r\u00e9ex\u00e9cut\u00e9 pour s'assurer qu'il n'y a pas de probl\u00e8mes lors de la mise \u00e0 jour d'un cluster. Comment lire un fichier excel avec databricks/python? Voici un exemple de lecture dans un fichier excel : % python import pandas as pd pd . read_excel ( \"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\" , engine = 'openyxl' ) Tableau de bord Comment changer mon abonnement pour voir mes ressources? Dans le portail Azure, cliquez sur l'ic\u00f4ne R\u00e9pertoire + abonnement . S\u00e9lectionnez l'abonnement vdl . Autre Comment puis-je me connecter au compte de stockage interne Data Lake avec Power BI Desktop? Pr\u00e9requis : Une machine virtuelle dans l'Environnement d'analyse collaborative (EAC). Power BI Desktop. (Offert par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine.) \u00c9tapes : Connectez-vous \u00e0 votre machine virtuelle dans l'EAC. Lancez Power BI Desktop. Suivez les \u00e9tapes dans Analysez des donn\u00e9es dans Azure Data Lake Storage Gen2 avec Power BI - Cr\u00e9er un rapport dans Power BI Desktop (document anglais) . S.v.p. envoyez un message slack \u00e0 https://cae-eac.slack.com si vous ne connaissez pas l'URL du Azure Data Lake Storage Gen2. Comment les employ\u00e9s de Statistique Canada peuvent-ils transf\u00e9rer des fichiers de leur centre de donn\u00e9es? Pour les employ\u00e9s de Statistique Canada, ils peuvent se r\u00e9f\u00e9rer \u00e0 cette documentation interne : https://confluence.statcan.ca/display/DAaaS/CAE+-+Data+Ingestion Comment puis-je ajouter une question \u00e0 la FAQ? Veuillez faire parvenir votre suggestion de question par l'interm\u00e9diaire du canal https://cae-eac.slack.com. Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#ingestion-de-donnees","text":"","title":"Ingestion de donn\u00e9es"},{"location":"FAQ/#comment-puis-je-ingerer-des-donnees-y-compris-des-fichiers-volumineux-dans-la-plateforme","text":"","title":"Comment puis-je ing\u00e9rer des donn\u00e9es (y compris des fichiers volumineux) dans la plateforme?"},{"location":"FAQ/#compte-de-stockage-externe","text":"Les fichiers peuvent \u00eatre t\u00e9l\u00e9vers\u00e9s dans dans le conteneur inbox ou to-vers-int d'un compte de stockage externe, comme indiqu\u00e9 dans l'[ Explorateur de stockage Azure ] (AzureStorage.md). Ces fichiers seront alors automatiquement transf\u00e9r\u00e9s dans un compte de stockage interne (Data Lake) et rendus accessibles \u00e0 partir des services autoris\u00e9s. Remarque: Les comptes de stockage externe ont la convention de d\u00e9nomination stats project-acronym external .","title":"Compte de stockage externe"},{"location":"FAQ/#service-de-transfert-electronique-de-fichiers-tef","text":"Les employ\u00e9s de Statistique Canada peuvent utiliser le TEF pour transf\u00e9rer des fichiers de / vers les r\u00e9seaux sur site (R\u00e9s. A ou B) vers / depuis l'environnement infonuagique Azure. Veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com pour plus d'information sur ce processus.","title":"Service de transfert \u00e9lectronique de fichiers (TEF)"},{"location":"FAQ/#outils-de-plateforme","text":"Des outils de plateforme comme Databricks ou Data Factory peuvent \u00eatre utilis\u00e9s pour ing\u00e9rer des donn\u00e9es provenant de sources dedonn\u00e9es publiques.","title":"Outils de plateforme"},{"location":"FAQ/#explorateur-de-stockage","text":"","title":"Explorateur de stockage"},{"location":"FAQ/#comment-puis-je-configurer-les-parametres-du-proxy-de-lexplorateur-de-stockage-azure-sur-un-vdi-du-reseau-b","text":"Pour les employ\u00e9s de Statistique Canada seulement 1. La configuration des param\u00e8tres du proxy est n\u00e9cessaire, si vous recevez le message d'erreur suivant : Dans l'Explorateur de stockage Azure, allez \u00e0 Modifier Param\u00e8tres du proxy . Entrez les param\u00e8tres du proxy n\u00e9cessaires et cliquez sur OK .","title":"Comment puis-je configurer les param\u00e8tres du proxy de l'Explorateur de stockage\u00a0Azure sur un VDI du r\u00e9seau\u00a0B?"},{"location":"FAQ/#comment-puis-je-demander-un-nouveau-jeton-sap-requis-pour-lexplorateur-de-stockage-azure-sur-un-vdi-du-reseau-b","text":"Pour les employ\u00e9s de Statistique Canada seulement Pour demander un jeton SAP temporaire, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com.","title":"Comment puis-je demander un nouveau jeton\u00a0SAP (requis pour l'Explorateur de stockage\u00a0Azure sur un VDI du r\u00e9seau\u00a0B)?"},{"location":"FAQ/#pourquoi-est-ce-que-jobtiens-un-message-derreur-lorsque-jaccede-au-compte-de-stockage-interne-data-lake","text":"Le compte de stockage interne Data Lake n'est accessible qu'\u00e0 partir d'une machine virtuelle dans l'Environnement d'analyse collaboratif (EAC). Il n'est pas accessible \u00e0 partir de votre ordinateur personnel, ni de votre ordinateur portable de travail, ni du VDI du r\u00e9seau B, ni d'une autre machine virtuelle sur nuage.","title":"Pourquoi est-ce que j'obtiens un message d'erreur lorsque j'acc\u00e8de au compte de stockage interne Data\u00a0Lake?"},{"location":"FAQ/#controle-de-code-source","text":"","title":"Contr\u00f4le de code source"},{"location":"FAQ/#comment-puis-je-relier-mon-compte-visual-studio-a-mon-compte-infonuagique-de-statcan","text":"Connectez-vous \u00e0 votre compte Visual Studio sur le site https://visualstudio.microsoft.com/fr/subscriptions/ en utilisant l'adresse \u00e9lectronique de votre organisation. Pour les employ\u00e9s de StatCan, il s'agit de votre adresse \u00e9lectronique qui se termine par \u00ab canada.ca \u00bb. Ajoutez votre compte infonuagique comme compte secondaire. Vous pourrez ainsi utiliser vos licences pour Visual Studio et Azure DevOps dans l'EAC. Pour les employ\u00e9s de Statistique Canada : Si vous n'avez pas d'abonnement Visual Studio, veuillez communiquer avec votre superviseur. S'il d\u00e9cide que vous avez besoin d'un abonnement, il pourra alors soumettre une demande de soutien en votre nom aupr\u00e8s de la Gestion des biens logiciels de StatCan pour vous obtenir une licence.","title":"Comment puis-je relier mon compte Visual\u00a0Studio \u00e0 mon compte infonuagique de StatCan?"},{"location":"FAQ/#machines-virtuelles","text":"","title":"Machines virtuelles"},{"location":"FAQ/#que-dois-je-faire-si-jai-oublie-le-mot-de-passe-de-ma-machine-virtuelle","text":"Si vous oubliez le mot de passe de votre machine virtuelle, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com pour r\u00e9initialiser votre mot de passe. Vous pouvez \u00e9galement supprimer votre machine virtuelle, puis en cr\u00e9er une autre. Ce faisant, vous perdrez malheureusement les donn\u00e9es et les logiciels sur votre ancienne machine.","title":"Que dois-je faire si j'ai oubli\u00e9 le mot de passe de ma machine virtuelle?"},{"location":"FAQ/#que-dois-je-faire-si-je-dois-executer-un-travail-de-longue-duree-sur-ma-machine-virtuelle","text":"Les machines sont arr\u00eat\u00e9es tous les jours \u00e0 19 h (HNE), afin de r\u00e9duire les frais d'exploitation. Pour ex\u00e9cuter un travail de longue dur\u00e9e, il est recommand\u00e9 d'utiliser Databricks ou Data Factory. AVERTISSEMENT : Il n'est pas recommand\u00e9 de d\u00e9sactiver l'arr\u00eat automatique, car cela pourrait entra\u00eener des frais importants. Pour d\u00e9sactiver l'arr\u00eat automatique : Acc\u00e9dez \u00e0 votre machine virtuelle dans le portail Azure. D\u00e9sactivez l'arr\u00eat automatique.","title":"Que dois-je faire si je dois ex\u00e9cuter un travail de longue dur\u00e9e sur ma machine virtuelle?"},{"location":"FAQ/#comment-puis-je-apporter-des-changements-a-ma-machine-virtuelle","text":"Si la machine virtuelle que vous utilisez actuellement ne r\u00e9pond pas \u00e0 vos besoins, veuillez communiquer avec l'\u00e9quipe de soutien par l'interm\u00e9diaire du canal https://cae-eac.slack.com.","title":"Comment puis-je apporter des changements \u00e0 ma machine virtuelle?"},{"location":"FAQ/#databricks","text":"","title":"Databricks"},{"location":"FAQ/#pourquoi-suis-je-incapable-dexecuter-le-code-a-partir-de-mon-notebook-dans-databricks","text":"Vous devez d'abord d\u00e9marrer un cluster dans Databricks qui a d\u00e9j\u00e0 \u00e9t\u00e9 cr\u00e9\u00e9 pour vous : 1. Cliquez sur Clusters. Naviguez vers votre cluster et cliquez sur le bouton D\u00e9marrer (ic\u00f4ne de la fl\u00e8che).","title":"Pourquoi suis-je incapable d'ex\u00e9cuter le code \u00e0 partir de mon notebook dans Databricks?"},{"location":"FAQ/#quels-types-de-clusters-sont-disponibles-dans-databricks","text":"Voir le lien suivant pour les diff\u00e9rents types de clusters disponibles: https://docs.microsoft.com/en-us/azure/databricks/release-notes/runtime/releases#:~:text=Supported%20Databricks%20runtime%20releases%20and%20support%20schedule%20,Sep%2002%2C%202021%20%2022%20more%20rows%20","title":"Quels types de clusters sont disponibles dans Databricks?"},{"location":"FAQ/#que-se-passe-t-il-lorsque-les-clusters-sont-mis-a-niveau","text":"LTS (support \u00e0 long terme) a un support pendant 1-2 ans. Ils devront \u00eatre p\u00e9riodiquement mis \u00e0 jour vers une version plus r\u00e9cente. Lors de la mise \u00e0 niveau, tout le code doit \u00eatre r\u00e9ex\u00e9cut\u00e9 pour s'assurer qu'il n'y a pas de probl\u00e8mes lors de la mise \u00e0 jour d'un cluster.","title":"Que se passe-t-il lorsque les clusters sont mis \u00e0 niveau?"},{"location":"FAQ/#comment-lire-un-fichier-excel-avec-databrickspython","text":"Voici un exemple de lecture dans un fichier excel : % python import pandas as pd pd . read_excel ( \"/dbfs/mnt/ccei-ccie-ext/Daily charts.xlsx\" , engine = 'openyxl' )","title":"Comment lire un fichier excel avec databricks/python?"},{"location":"FAQ/#tableau-de-bord","text":"","title":"Tableau de bord"},{"location":"FAQ/#comment-changer-mon-abonnement-pour-voir-mes-ressources","text":"Dans le portail Azure, cliquez sur l'ic\u00f4ne R\u00e9pertoire + abonnement . S\u00e9lectionnez l'abonnement vdl .","title":"Comment changer mon abonnement pour voir mes ressources?"},{"location":"FAQ/#autre","text":"","title":"Autre"},{"location":"FAQ/#comment-puis-je-me-connecter-au-compte-de-stockage-interne-data-lake-avec-power-bi-desktop","text":"Pr\u00e9requis : Une machine virtuelle dans l'Environnement d'analyse collaborative (EAC). Power BI Desktop. (Offert par d\u00e9faut dans les images de machine virtuelle Data Science Virtual Machine.) \u00c9tapes : Connectez-vous \u00e0 votre machine virtuelle dans l'EAC. Lancez Power BI Desktop. Suivez les \u00e9tapes dans Analysez des donn\u00e9es dans Azure Data Lake Storage Gen2 avec Power BI - Cr\u00e9er un rapport dans Power BI Desktop (document anglais) . S.v.p. envoyez un message slack \u00e0 https://cae-eac.slack.com si vous ne connaissez pas l'URL du Azure Data Lake Storage Gen2.","title":"Comment puis-je me connecter au compte de stockage interne Data Lake avec Power BI Desktop?"},{"location":"FAQ/#comment-les-employes-de-statistique-canada-peuvent-ils-transferer-des-fichiers-de-leur-centre-de-donnees","text":"Pour les employ\u00e9s de Statistique Canada, ils peuvent se r\u00e9f\u00e9rer \u00e0 cette documentation interne : https://confluence.statcan.ca/display/DAaaS/CAE+-+Data+Ingestion","title":"Comment les employ\u00e9s de Statistique Canada peuvent-ils transf\u00e9rer des fichiers de leur centre de donn\u00e9es?"},{"location":"FAQ/#comment-puis-je-ajouter-une-question-a-la-faq","text":"Veuillez faire parvenir votre suggestion de question par l'interm\u00e9diaire du canal https://cae-eac.slack.com.","title":"Comment puis-je ajouter une question \u00e0 la FAQ?"},{"location":"FAQ/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"Langue/","text":"English Langue Le document d\u00e9crit la fa\u00e7on de changer la langue dans les diff\u00e9rents services offerts. Portail Azure Pour modifier les param\u00e8tres de langue du portail Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale. Cliquez sur l'onglet Langue et r\u00e9gion . Utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9. Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional. Tableau de bord Pour acc\u00e9der au tableau de bord en fran\u00e7ais de l\u2019environnement d\u2019Analyse collaborative (EAC), voici les \u00e9tapes \u00e0 suivre: \u00c0 partir de la liste des tableaux de bords, cliquez sur la fl\u00e8che correspondant au nom du tableau de bord. S\u00e9lectionnez le tableau de bord Environnement d\u2019Analyse Collaborative dans la liste affich\u00e9e. Note: Si ce tableau de bord n'est pas dans la liste, cliquez sur Parcourir tous les tableaux de bord pour acc\u00e9der \u00e0 la liste compl\u00e8te des tableaux de bord. Data Factory Pour configurer la langue, voici les \u00e9tapes \u00e0 suivre: Dans Azure Data Factory, s\u00e9lectionnez Param\u00e8tres . S\u00e9lectionnez Fran\u00e7ais . Cliquez sur Appliquer . Databricks Cet outil est disponible uniquement en anglais pour le moment. Machines Virtuelles Serveur Windows Pour configurer la langue d'affichage dans une machine virtuelle Windows, voici les \u00e9tapes \u00e0 suivre: Selectionnez Param\u00e8tres . S\u00e9lectionnez Heure et langue . S\u00e9lectionnez Langue . Utilisez le menu d\u00e9roulant sous l'en-t\u00eate Langue d\u2019affichage de Windows pour choisir la langue d\u00e9sir\u00e9e. La zone de langue d'affichage de Windows doit maintenant comprendre la langue choisie. Pour \u00eatre en mesure d'appliquer la nouvelle langue, d\u00e9connectez-vous de la session Windows actuelle, puis reconnectez-vous. Serveur Ubuntu Si vous utilisez l'application X2GO pour acc\u00e9der \u00e0 l'interface graphique de votre machine Ubuntu, notez que par d\u00e9faut la session est disponible en anglais uniquement. Il sera donc necessaire d'installer des modules supplementaires de langue manuellement. Azure Apprentissage automatique Pour modifier les param\u00e8tres de langue dans l\u2019espace de travail d'apprentissage automatique Microsoft Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale. Sous Langue et formats , utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9. Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional. Azure Apprentissage automatique - Jupyter Lab Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML: pip install jupyterlab == 3 Red\u00e9marrez l'instance de calcul Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML: pip install git+https://github.com/StatCan/jupyterlab-language-pack-fr_FR Dans JupyterLab, s\u00e9lectionnez Param\u00e8tres - Langue - Fran\u00e7ais Slack Pour modifier les param\u00e8tres de langue dans l\u2019application Slack, voici les \u00e9tapes \u00e0 suivre: 1. Cliquez sur l\u2019 ic\u00f4ne de profil dans l'en-t\u00eate de la page principale. Cliquez sur Pr\u00e9f\u00e9rences . S\u00e9lectionnez l\u2019onglet Langue et r\u00e9gion . Sous Langue , utilisez le menu d\u00e9roulant pour choisir la langue pr\u00e9f\u00e9r\u00e9e. Fermez la fen\u00eatre Pr\u00e9f\u00e9rences . Explorateur de stockage Microsoft Azure Par d\u00e9faut, cette application d\u00e9termine la langue d'utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur. Pour modifier les param\u00e8tres de langue dans l\u2019Explorateur de stockage Microsoft Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur Modifier . Cliquez sur Param\u00e8tres . Dans la page des param\u00e8tres, s\u00e9lectionnez Application . Sous Param\u00e8tres r\u00e9gionaux , utilisez le menu d\u00e9roulant pour choisir votre langue pr\u00e9f\u00e9r\u00e9e. Pour appliquer la nouvelle langue, fermez puis relancer l\u2019application. Power BI Pour obtenir plus de renseignements, vous pouvez consulter l\u2019article \u00ab Langues et pays/r\u00e9gions pris en charge pour Power BI \u00bb. Service Power BI Par d\u00e9faut, le service Power BI d\u00e9termine la langue d\u2019utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur. Les \u00e9tapes \u00e0 suivre pour afficher et modifier ces pr\u00e9f\u00e9rences peuvent varier selon votre syst\u00e8me d\u2019exploitation et votre fureteur. Pour changer la langue du menu dans le service Power BI, voici les \u00e9tapes \u00e0 suivre: Dans le service Power BI, cliquez sur l\u2019 ic\u00f4ne Param\u00e8tres , puis s\u00e9lectionnez Param\u00e8tres . Sous l\u2019onglet G\u00e9n\u00e9ral , s\u00e9lectionnez Langue . S\u00e9lectionnez votre langue pr\u00e9f\u00e9r\u00e9e, puis cliquez sur Appliquer . Pour obtenir plus de renseignements, consultez l\u2019article \u00ab Langues disponibles pour le service Power BI \u00bb. Power BI Desktop Par d\u00e9faut, \u2022 la Langue de l'application est fond\u00e9e sur la Langue de Windows \u2022 la Langue du mod\u00e8le est fond\u00e9e sur la Langue de l'application \u2022 les \u00e9tapes de la requ\u00eate sont fond\u00e9es sur la Langue de l'application Il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States) . La langue du mod\u00e8le s'applique seulement au moment de la cr\u00e9ation du rapport et ne peut pas \u00eatre chang\u00e9e dans les rapports existants. Ainsi, il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States) , sauf si vous avez besoin d\u2019utiliser une autre langue pour le mod\u00e8le de rapport. Les comparaisons de cha\u00eene de caract\u00e8res et les champs de date internes sont affect\u00e9s par cette configuration. Pour changer la langue du menu et la langue du mod\u00e8le dans Power BI Desktop, voici les \u00e9tapes \u00e0 suivre: Ouvrez le menu Options . Sous GLOBAL , cliquez sur Param\u00e8tres r\u00e9gionaux , et fixez la langue de l\u2019application et la langue du mod\u00e8le \u00e0 la langue souhait\u00e9e. NOTE : La langue d'importation des donn\u00e9es est fix\u00e9e s\u00e9par\u00e9ment dans les Param\u00e8tres r\u00e9gionaux de la section FICHIER ACTIF . Vous devez la changer seulement si vous importez des fichiers de donn\u00e9es comportant des nombres ou des dates suivant des param\u00e8tres r\u00e9gionaux pr\u00e9cis (p. ex. le format de date JJ/MM/AAAA de l\u2019anglais du Canada et le format de date MM/JJ/AAAA de l\u2019anglais des \u00c9tats-Unis). Databricks Pour modifier les param\u00e8tres de langue dans Databricks: S\u00e9lectionnez le menu d\u00e9roulant de l'utilisateur en haut \u00e0 droite et s\u00e9lectionnez Param\u00e8tres utilisateur . Sur la page, s\u00e9lectionnez Param\u00e8tres de langue . Cliquez sur la liste d\u00e9roulante et s\u00e9lectionnez la langue de votre choix. Datafactory Pour modifier les param\u00e8tres de langue dans Data Factory: S\u00e9lectionnez l' Ic\u00f4ne Param\u00e8tres en haut \u00e0 droite. Acc\u00e9dez \u00e0 la section Langue et s\u00e9lectionnez la langue de votre choix. JupyterLab Pour modifier les param\u00e8tres de langue dans JupyterLab: Dans JupyterLab, ouvrez une console ou un terminal. Installez l'exemple de langue de votre choix \u00e0 l'aide de pip. Exemple: pip install jupyterlab - language - pack - fr - FR Sous settings , mettez en surbrillance Language et s\u00e9lectionnez la langue que vous avez install\u00e9e. Cliquez sur OK pour rafra\u00eechir la page, vous verrez le changement de langue. Pour plus d'informations sur le changement de langue: https://jupyterlab.readthedocs.io/en/stable/user/language.html#changing-the-display-language VSCode Pour changer la langue d'affichage dans VSCode: Ouvrez VSCode et ouvrez la palette de commandes (Ctrl+Maj+P). Dans la palette de commandes, tapez \"affichage\" et s\u00e9lectionnez installer des langues suppl\u00e9mentaires Remarque : si vous avez d\u00e9j\u00e0 install\u00e9 la langue souhait\u00e9e, vous pouvez la s\u00e9lectionner dans la liste d\u00e9roulante. Sur le c\u00f4t\u00e9 gauche de VSCode, les langues qui peuvent \u00eatre install\u00e9es appara\u00eetront, s\u00e9lectionnez la langue de votre choix. Une fen\u00eatre contextuelle peut appara\u00eetre en bas \u00e0 droite de l'\u00e9cran dans laquelle vous pouvez changer la langue et red\u00e9marrera VSCode. Visual Studio Si vous avez d\u00e9j\u00e0 install\u00e9 des packages de langue dans Visual Studio: Dans la barre sup\u00e9rieure, s\u00e9lectionnez Outils puis Options . Dans le menu, sous l'onglet Environnement , s\u00e9lectionnez Param\u00e8tres internationaux Dans le menu d\u00e9roulant sous Langue , s\u00e9lectionnez la langue de votre choix. Si vous n'avez pas install\u00e9 d'autres packages de langue dans Visual Studio : Sur votre ordinateur, ouvrez le programme d'installation de Visual Studio. Dans le programme d'installation, s\u00e9lectionnez le bouton Modifier. Dans la nouvelle fen\u00eatre, s\u00e9lectionnez Packs linguistiques . S\u00e9lectionnez toutes les langues que vous souhaitez ajouter, puis s\u00e9lectionnez modifier. \u00c0 partir de l\u00e0, vous pouvez suivre les \u00e9tapes d'utilisation des packages de langue install\u00e9s dans Visual Studio. Pour configurer RStudio dans une autre langue : Ouvrez RStudio et ouvrez la console. Dans la console, tapez \"Sys.getenv(LANGUAGE = \"fr\") Note : \"fr\" est pour la langue fran\u00e7aise, pour une liste d'autres langues qui peuvent \u00eatre utilis\u00e9es : https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes Pour le tester, vous pouvez taper \"2+x\" et cela devrait donner une erreur dans la langue saisie. Fureteurs Web Chrome Safari Edge Firefox Opera (en anglais seulement)","title":"Langue"},{"location":"Langue/#langue","text":"Le document d\u00e9crit la fa\u00e7on de changer la langue dans les diff\u00e9rents services offerts.","title":"Langue"},{"location":"Langue/#portail-azure","text":"Pour modifier les param\u00e8tres de langue du portail Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale. Cliquez sur l'onglet Langue et r\u00e9gion . Utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9. Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional.","title":"Portail Azure"},{"location":"Langue/#tableau-de-bord","text":"Pour acc\u00e9der au tableau de bord en fran\u00e7ais de l\u2019environnement d\u2019Analyse collaborative (EAC), voici les \u00e9tapes \u00e0 suivre: \u00c0 partir de la liste des tableaux de bords, cliquez sur la fl\u00e8che correspondant au nom du tableau de bord. S\u00e9lectionnez le tableau de bord Environnement d\u2019Analyse Collaborative dans la liste affich\u00e9e. Note: Si ce tableau de bord n'est pas dans la liste, cliquez sur Parcourir tous les tableaux de bord pour acc\u00e9der \u00e0 la liste compl\u00e8te des tableaux de bord.","title":"Tableau de bord"},{"location":"Langue/#data-factory","text":"Pour configurer la langue, voici les \u00e9tapes \u00e0 suivre: Dans Azure Data Factory, s\u00e9lectionnez Param\u00e8tres . S\u00e9lectionnez Fran\u00e7ais . Cliquez sur Appliquer .","title":"Data Factory"},{"location":"Langue/#databricks","text":"Cet outil est disponible uniquement en anglais pour le moment.","title":"Databricks"},{"location":"Langue/#machines-virtuelles","text":"","title":"Machines Virtuelles"},{"location":"Langue/#serveur-windows","text":"Pour configurer la langue d'affichage dans une machine virtuelle Windows, voici les \u00e9tapes \u00e0 suivre: Selectionnez Param\u00e8tres . S\u00e9lectionnez Heure et langue . S\u00e9lectionnez Langue . Utilisez le menu d\u00e9roulant sous l'en-t\u00eate Langue d\u2019affichage de Windows pour choisir la langue d\u00e9sir\u00e9e. La zone de langue d'affichage de Windows doit maintenant comprendre la langue choisie. Pour \u00eatre en mesure d'appliquer la nouvelle langue, d\u00e9connectez-vous de la session Windows actuelle, puis reconnectez-vous.","title":"Serveur Windows"},{"location":"Langue/#serveur-ubuntu","text":"Si vous utilisez l'application X2GO pour acc\u00e9der \u00e0 l'interface graphique de votre machine Ubuntu, notez que par d\u00e9faut la session est disponible en anglais uniquement. Il sera donc necessaire d'installer des modules supplementaires de langue manuellement.","title":"Serveur Ubuntu"},{"location":"Langue/#azure-apprentissage-automatique","text":"Pour modifier les param\u00e8tres de langue dans l\u2019espace de travail d'apprentissage automatique Microsoft Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur le menu Param\u00e8tres dans l'en-t\u00eate de la page principale. Sous Langue et formats , utilisez les menus d\u00e9roulants pour choisir la langue pr\u00e9f\u00e9r\u00e9e et le format r\u00e9gional appropri\u00e9. Cliquez sur le bouton Appliquer pour mettre \u00e0 jour vos param\u00e8tres de langue et de format r\u00e9gional.","title":"Azure Apprentissage automatique"},{"location":"Langue/#azure-apprentissage-automatique-jupyter-lab","text":"Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML: pip install jupyterlab == 3 Red\u00e9marrez l'instance de calcul Ex\u00e9cutez dans le terminal d'instance de calcul Azure ML: pip install git+https://github.com/StatCan/jupyterlab-language-pack-fr_FR Dans JupyterLab, s\u00e9lectionnez Param\u00e8tres - Langue - Fran\u00e7ais","title":"Azure Apprentissage automatique - Jupyter Lab"},{"location":"Langue/#slack","text":"Pour modifier les param\u00e8tres de langue dans l\u2019application Slack, voici les \u00e9tapes \u00e0 suivre: 1. Cliquez sur l\u2019 ic\u00f4ne de profil dans l'en-t\u00eate de la page principale. Cliquez sur Pr\u00e9f\u00e9rences . S\u00e9lectionnez l\u2019onglet Langue et r\u00e9gion . Sous Langue , utilisez le menu d\u00e9roulant pour choisir la langue pr\u00e9f\u00e9r\u00e9e. Fermez la fen\u00eatre Pr\u00e9f\u00e9rences .","title":"Slack"},{"location":"Langue/#explorateur-de-stockage-microsoft-azure","text":"Par d\u00e9faut, cette application d\u00e9termine la langue d'utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur. Pour modifier les param\u00e8tres de langue dans l\u2019Explorateur de stockage Microsoft Azure, voici les \u00e9tapes \u00e0 suivre: Cliquez sur Modifier . Cliquez sur Param\u00e8tres . Dans la page des param\u00e8tres, s\u00e9lectionnez Application . Sous Param\u00e8tres r\u00e9gionaux , utilisez le menu d\u00e9roulant pour choisir votre langue pr\u00e9f\u00e9r\u00e9e. Pour appliquer la nouvelle langue, fermez puis relancer l\u2019application.","title":"Explorateur de stockage Microsoft Azure"},{"location":"Langue/#power-bi","text":"Pour obtenir plus de renseignements, vous pouvez consulter l\u2019article \u00ab Langues et pays/r\u00e9gions pris en charge pour Power BI \u00bb.","title":"Power BI"},{"location":"Langue/#service-power-bi","text":"Par d\u00e9faut, le service Power BI d\u00e9termine la langue d\u2019utilisation en fonction des pr\u00e9f\u00e9rences linguistiques d\u00e9finies sur votre ordinateur. Les \u00e9tapes \u00e0 suivre pour afficher et modifier ces pr\u00e9f\u00e9rences peuvent varier selon votre syst\u00e8me d\u2019exploitation et votre fureteur. Pour changer la langue du menu dans le service Power BI, voici les \u00e9tapes \u00e0 suivre: Dans le service Power BI, cliquez sur l\u2019 ic\u00f4ne Param\u00e8tres , puis s\u00e9lectionnez Param\u00e8tres . Sous l\u2019onglet G\u00e9n\u00e9ral , s\u00e9lectionnez Langue . S\u00e9lectionnez votre langue pr\u00e9f\u00e9r\u00e9e, puis cliquez sur Appliquer . Pour obtenir plus de renseignements, consultez l\u2019article \u00ab Langues disponibles pour le service Power BI \u00bb.","title":"Service Power BI"},{"location":"Langue/#power-bi-desktop","text":"Par d\u00e9faut, \u2022 la Langue de l'application est fond\u00e9e sur la Langue de Windows \u2022 la Langue du mod\u00e8le est fond\u00e9e sur la Langue de l'application \u2022 les \u00e9tapes de la requ\u00eate sont fond\u00e9es sur la Langue de l'application Il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States) . La langue du mod\u00e8le s'applique seulement au moment de la cr\u00e9ation du rapport et ne peut pas \u00eatre chang\u00e9e dans les rapports existants. Ainsi, il est recommand\u00e9 de fixer la langue du mod\u00e8le \u00e0 English (United States) , sauf si vous avez besoin d\u2019utiliser une autre langue pour le mod\u00e8le de rapport. Les comparaisons de cha\u00eene de caract\u00e8res et les champs de date internes sont affect\u00e9s par cette configuration. Pour changer la langue du menu et la langue du mod\u00e8le dans Power BI Desktop, voici les \u00e9tapes \u00e0 suivre: Ouvrez le menu Options . Sous GLOBAL , cliquez sur Param\u00e8tres r\u00e9gionaux , et fixez la langue de l\u2019application et la langue du mod\u00e8le \u00e0 la langue souhait\u00e9e. NOTE : La langue d'importation des donn\u00e9es est fix\u00e9e s\u00e9par\u00e9ment dans les Param\u00e8tres r\u00e9gionaux de la section FICHIER ACTIF . Vous devez la changer seulement si vous importez des fichiers de donn\u00e9es comportant des nombres ou des dates suivant des param\u00e8tres r\u00e9gionaux pr\u00e9cis (p. ex. le format de date JJ/MM/AAAA de l\u2019anglais du Canada et le format de date MM/JJ/AAAA de l\u2019anglais des \u00c9tats-Unis).","title":"Power BI Desktop"},{"location":"Langue/#databricks_1","text":"Pour modifier les param\u00e8tres de langue dans Databricks: S\u00e9lectionnez le menu d\u00e9roulant de l'utilisateur en haut \u00e0 droite et s\u00e9lectionnez Param\u00e8tres utilisateur . Sur la page, s\u00e9lectionnez Param\u00e8tres de langue . Cliquez sur la liste d\u00e9roulante et s\u00e9lectionnez la langue de votre choix.","title":"Databricks"},{"location":"Langue/#datafactory","text":"Pour modifier les param\u00e8tres de langue dans Data Factory: S\u00e9lectionnez l' Ic\u00f4ne Param\u00e8tres en haut \u00e0 droite. Acc\u00e9dez \u00e0 la section Langue et s\u00e9lectionnez la langue de votre choix.","title":"Datafactory"},{"location":"Langue/#jupyterlab","text":"Pour modifier les param\u00e8tres de langue dans JupyterLab: Dans JupyterLab, ouvrez une console ou un terminal. Installez l'exemple de langue de votre choix \u00e0 l'aide de pip. Exemple: pip install jupyterlab - language - pack - fr - FR Sous settings , mettez en surbrillance Language et s\u00e9lectionnez la langue que vous avez install\u00e9e. Cliquez sur OK pour rafra\u00eechir la page, vous verrez le changement de langue. Pour plus d'informations sur le changement de langue: https://jupyterlab.readthedocs.io/en/stable/user/language.html#changing-the-display-language","title":"JupyterLab"},{"location":"Langue/#vscode","text":"Pour changer la langue d'affichage dans VSCode: Ouvrez VSCode et ouvrez la palette de commandes (Ctrl+Maj+P). Dans la palette de commandes, tapez \"affichage\" et s\u00e9lectionnez installer des langues suppl\u00e9mentaires Remarque : si vous avez d\u00e9j\u00e0 install\u00e9 la langue souhait\u00e9e, vous pouvez la s\u00e9lectionner dans la liste d\u00e9roulante. Sur le c\u00f4t\u00e9 gauche de VSCode, les langues qui peuvent \u00eatre install\u00e9es appara\u00eetront, s\u00e9lectionnez la langue de votre choix. Une fen\u00eatre contextuelle peut appara\u00eetre en bas \u00e0 droite de l'\u00e9cran dans laquelle vous pouvez changer la langue et red\u00e9marrera VSCode.","title":"VSCode"},{"location":"Langue/#visual-studio","text":"Si vous avez d\u00e9j\u00e0 install\u00e9 des packages de langue dans Visual Studio: Dans la barre sup\u00e9rieure, s\u00e9lectionnez Outils puis Options . Dans le menu, sous l'onglet Environnement , s\u00e9lectionnez Param\u00e8tres internationaux Dans le menu d\u00e9roulant sous Langue , s\u00e9lectionnez la langue de votre choix. Si vous n'avez pas install\u00e9 d'autres packages de langue dans Visual Studio : Sur votre ordinateur, ouvrez le programme d'installation de Visual Studio. Dans le programme d'installation, s\u00e9lectionnez le bouton Modifier. Dans la nouvelle fen\u00eatre, s\u00e9lectionnez Packs linguistiques . S\u00e9lectionnez toutes les langues que vous souhaitez ajouter, puis s\u00e9lectionnez modifier. \u00c0 partir de l\u00e0, vous pouvez suivre les \u00e9tapes d'utilisation des packages de langue install\u00e9s dans Visual Studio. Pour configurer RStudio dans une autre langue : Ouvrez RStudio et ouvrez la console. Dans la console, tapez \"Sys.getenv(LANGUAGE = \"fr\") Note : \"fr\" est pour la langue fran\u00e7aise, pour une liste d'autres langues qui peuvent \u00eatre utilis\u00e9es : https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes Pour le tester, vous pouvez taper \"2+x\" et cela devrait donner une erreur dans la langue saisie.","title":"Visual Studio"},{"location":"Langue/#fureteurs-web","text":"Chrome Safari Edge Firefox Opera (en anglais seulement)","title":"Fureteurs Web"},{"location":"Login/","text":"English Comment acc\u00e9der \u00e0 l'environnement Pr\u00e9requis Un compte de l'infonuagique StatCan ou un compte d'utilisateur invit\u00e9. L'acc\u00e8s avec un compte du r\u00e9seau de StatCan est pr\u00e9sentement seulement disponible pour le service Power BI, mais pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC). Notes Il est recommand\u00e9 d'utiliser Chrome, Chromium or Edge (non Internet Explorer) pour acc\u00e8der au portail Azure, les services Azure ou le service Power BI. Lors de la connexion aux services infonuagiques Azure, vous pourrez soit acc\u00e9der avec votre: Compte infonuagique de StatCan (c.-\u00e0-d. prenom.nomfamille@cloud.statcan.ca) ou Informations d\u2019identification d'autres d\u00e9partements ou chercheurs (c.-\u00e0-d. prenom.nom@dept-d\u00e9pt.gc.ca or nom@gov.prov.ca) ou Compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) pour les employ\u00e9s de StatCan utilisant le service Power BI seulement. Suivre les instructions pour votre type de compte afin de compl\u00e9ter votre connexion. Compte infonuagique de StatCan (prenom.nomfamille@cloud.statcan.ca) S'applique \u00e0 tous les services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.) En utilisant Chrome, Chromium ou Edge, ouvrir soit: Le tableau de bord Azure de l' Environnement d'Analyse Collaborative Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer ou de choisir un compte: La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Entrez votre compte infonuagique (prenom.nomfamille@cloud.statcan.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte cloud.statcan.ca. On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique. Une fois entr\u00e9, cliquez sur Connexion . Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. Informations d\u2019identification d'autres d\u00e9partements ou chercheurs S'applique \u00e0 la majorit\u00e9 des services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.) En utilisant Chrome, Chromium ou Edge, ouvrir soit: Le tableau de bord Azure de l' Environnement d'Analyse Collaborative Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI Azure Databricks Azure Data Factory En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer ou de choisir un compte : La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Connectez-vous avec vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca). On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique. Une fois entr\u00e9, cliquez sur Connexion . Si votre adresse \u00e9lectronique officielle ne prend pas en charge ce type de connexion, vous recevrez automatiquement par courrier \u00e9lectronique un code \u00e0 saisir en lieu et place d'un mot de passe, puis vous cliquerez sur Connexion . - Le courriel que vous recevez ressemblera \u00e0 ce qui suit. Si vous ne le recevez pas, v\u00e9rifiez qu'il n'a pas \u00e9t\u00e9 envoy\u00e9 dans votre dossier Spam ou Junk. Accepter les autorisations de r\u00e9vision (consentement pour la premi\u00e8re fois uniquement). Vous recevrez alors le message suivant. Attendez jusqu\u2019\u00e0 la fin. Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte de l\u2019infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. Compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca) S'applique seulement au service Power BI pour les employ\u00e9s de Statistique Canada. Pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC). Veuillez noter que l\u2019\u00e9tape 5 (mot de passe d\u2019Internet) ci-dessous peut arriver \u00e0 n\u2019importe quel moment. \u00c0 partir du r\u00e9seau B ou du OZ, et en utilisant Chrome, Chromium ou Edge, ouvrir soit: -Le lien URL de l\u2019application Power BI (si fourni), ou -https://powerbi.microsoft.com/fr-fr/landing/signin/ Vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer soit de choisir un compte: La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Entrez votre compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte statcan.gc.ca. Vous allez ensuite recevoir le message de Microsoft \u201cVous allez \u00eatre redirig\u00e9 vers la page de connexion de votre organisation\u201c. Vous serez peut-\u00eatre amen\u00e9 \u00e0 entrer votre nom d\u2019utilisateur et votre mot de passe d\u2019 Internet comme montr\u00e9 ci-dessous. Une fois entr\u00e9s, cliquez sur Ouvrir une session . On vous demandera ensuite de vous connecter \u00e0 votre compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) et d\u2019entrer votre mot de passe du r\u00e9seau A. Une fois entr\u00e9s, cliquez sur Ouvrir une session . Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte du r\u00e9seau de StatCan. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9. Documentation Microsoft https://docs.microsoft.com/fr-ca/azure/azure-portal/ Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Se connecter"},{"location":"Login/#comment-acceder-a-lenvironnement","text":"","title":"Comment acc\u00e9der \u00e0 l'environnement"},{"location":"Login/#prerequis","text":"Un compte de l'infonuagique StatCan ou un compte d'utilisateur invit\u00e9. L'acc\u00e8s avec un compte du r\u00e9seau de StatCan est pr\u00e9sentement seulement disponible pour le service Power BI, mais pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC).","title":"Pr\u00e9requis"},{"location":"Login/#notes","text":"Il est recommand\u00e9 d'utiliser Chrome, Chromium or Edge (non Internet Explorer) pour acc\u00e8der au portail Azure, les services Azure ou le service Power BI. Lors de la connexion aux services infonuagiques Azure, vous pourrez soit acc\u00e9der avec votre: Compte infonuagique de StatCan (c.-\u00e0-d. prenom.nomfamille@cloud.statcan.ca) ou Informations d\u2019identification d'autres d\u00e9partements ou chercheurs (c.-\u00e0-d. prenom.nom@dept-d\u00e9pt.gc.ca or nom@gov.prov.ca) ou Compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) pour les employ\u00e9s de StatCan utilisant le service Power BI seulement. Suivre les instructions pour votre type de compte afin de compl\u00e9ter votre connexion.","title":"Notes"},{"location":"Login/#compte-infonuagique-de-statcan-prenomnomfamillecloudstatcanca","text":"S'applique \u00e0 tous les services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.) En utilisant Chrome, Chromium ou Edge, ouvrir soit: Le tableau de bord Azure de l' Environnement d'Analyse Collaborative Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer ou de choisir un compte: La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Entrez votre compte infonuagique (prenom.nomfamille@cloud.statcan.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte cloud.statcan.ca. On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique. Une fois entr\u00e9, cliquez sur Connexion . Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9.","title":"Compte infonuagique de StatCan (prenom.nomfamille@cloud.statcan.ca)"},{"location":"Login/#informations-didentification-dautres-departements-ou-chercheurs","text":"S'applique \u00e0 la majorit\u00e9 des services infonuagiques Azure (Power BI, Databricks, Data Factory, machines virtuelles, etc.) En utilisant Chrome, Chromium ou Edge, ouvrir soit: Le tableau de bord Azure de l' Environnement d'Analyse Collaborative Le lien URL de l\u2019application Power BI (si fourni), ou la page de connexion au service Power BI Azure Databricks Azure Data Factory En ouvrant le lien URL d'une application Power BI ou la page de connexion au service Power BI, vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer ou de choisir un compte : La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Connectez-vous avec vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur vos informations d\u2019identification de messagerie officielle/O365 ou vos informations d\u2019identification GCCollaboration (p. ex., prenom.nom.departement@dept-d\u00e9pt.gc.ca, prenom.nom.departement@gccollaboration.ca or non@gov.prov.ca). On vous demandera ensuite d\u2019entrer le mot de passe de votre compte infonuagique. Une fois entr\u00e9, cliquez sur Connexion . Si votre adresse \u00e9lectronique officielle ne prend pas en charge ce type de connexion, vous recevrez automatiquement par courrier \u00e9lectronique un code \u00e0 saisir en lieu et place d'un mot de passe, puis vous cliquerez sur Connexion . - Le courriel que vous recevez ressemblera \u00e0 ce qui suit. Si vous ne le recevez pas, v\u00e9rifiez qu'il n'a pas \u00e9t\u00e9 envoy\u00e9 dans votre dossier Spam ou Junk. Accepter les autorisations de r\u00e9vision (consentement pour la premi\u00e8re fois uniquement). Vous recevrez alors le message suivant. Attendez jusqu\u2019\u00e0 la fin. Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte de l\u2019infonuagique. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9.","title":"Informations d\u2019identification d'autres d\u00e9partements ou chercheurs"},{"location":"Login/#compte-du-reseau-de-statcan-prenomnomfamillestatcangcca","text":"S'applique seulement au service Power BI pour les employ\u00e9s de Statistique Canada. Pourrait \u00eatre une option future pour les autres services de l'Environnement d'Analyse Collaborative (EAC). Veuillez noter que l\u2019\u00e9tape 5 (mot de passe d\u2019Internet) ci-dessous peut arriver \u00e0 n\u2019importe quel moment. \u00c0 partir du r\u00e9seau B ou du OZ, et en utilisant Chrome, Chromium ou Edge, ouvrir soit: -Le lien URL de l\u2019application Power BI (si fourni), ou -https://powerbi.microsoft.com/fr-fr/landing/signin/ Vous serez dirig\u00e9 vers la page d\u2019ouverture de session de Microsoft Power BI, comme montr\u00e9 ci-dessous, disant \u201cVous disposez d\u00e9j\u00e0 d\u2019un compte?\u201c. Cliquez sur CONNEXION . On vous demandera ensuite soit d\u2019entrer soit de choisir un compte: La 1\u00e8re fois que vous vous connectez, la fen\u00eatre Se connecter de Microsoft s\u2019affichera comme montr\u00e9 ci-dessous. Entrez votre compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca), et cliquez sur Suivant . Lors des connexions subs\u00e9quentes, la fen\u00eatre Choisir un compte de Microsoft s\u2019affichera, comme montr\u00e9 ci-dessous. Cliquez sur votre compte statcan.gc.ca. Vous allez ensuite recevoir le message de Microsoft \u201cVous allez \u00eatre redirig\u00e9 vers la page de connexion de votre organisation\u201c. Vous serez peut-\u00eatre amen\u00e9 \u00e0 entrer votre nom d\u2019utilisateur et votre mot de passe d\u2019 Internet comme montr\u00e9 ci-dessous. Une fois entr\u00e9s, cliquez sur Ouvrir une session . On vous demandera ensuite de vous connecter \u00e0 votre compte du r\u00e9seau de StatCan (c.-\u00e0-d. prenom.nomfamille@statcan.gc.ca) et d\u2019entrer votre mot de passe du r\u00e9seau A. Une fois entr\u00e9s, cliquez sur Ouvrir une session . Enfin, vous recevrez peut-\u00eatre une demande de Statistique Canada disant Plus d\u2019informations requises \u2013 Votre organisation a besoin de plus d\u2019information pour pr\u00e9server la s\u00e9curit\u00e9 de votre compte, comme montr\u00e9 ci-dessous, surtout si c\u2019est la premi\u00e8re fois que vous ouvrez une session sur le portail Web avec votre compte du r\u00e9seau de StatCan. Cliquez sur Suivant et assurez-vous de suivre les instructions pour s\u00e9curiser votre compte par l\u2019authentification de votre courriel et la configuration de vos questions de s\u00e9curit\u00e9.","title":"Compte du r\u00e9seau de StatCan (prenom.nomfamille@statcan.gc.ca)"},{"location":"Login/#documentation-microsoft","text":"https://docs.microsoft.com/fr-ca/azure/azure-portal/","title":"Documentation Microsoft"},{"location":"Login/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"R-Shiny/","text":"English R-Shiny \u00e0 partir de RStudio Ce document d\u00e9crit comment acc\u00e9der R-Shiny \u00e0 partir de l'application Rstudio. Commencer Afin d'utiliser R-Shiny, s.v.p. envoyer un message Slack \u00e0 l'\u00e9quipe de l'EAC pour activer RStudio dans votre cluster Databricks. Avertissement : Les clusters R-Shiny s'\u00e9teignent tous les jours \u00e0 19h . Pour r\u00e9duire vos co\u00fbts, veuillez arr\u00eater vos clusters R-Shiny lorsque vous ne les utilisez pas. Acc\u00e8s \u00e0 R-Shiny \u00c0 partir du portail Azure, lancer l'espace de travail Databricks qui vous a \u00e9t\u00e9 cr\u00e9\u00e9. \u00c0 partir de l'espace de travail Databricks, cliquez sur Cluster . \u00c0 partir de la liste de clusters disponibles, selectionnez le cluster sur lequel RStudio a \u00e9t\u00e9 install\u00e9. Note: Le cluster doit \u00eatre active pour acc\u00e9der \u00e0 l'application RStudio. Consulter la section Databricks pour plus de d\u00e9tails \u00e0 propos du d\u00e9marrage d'un cluster. Selectionnez l'onglet Apps . Cliquez sur Set up RStudio . Un mot de passe \u00e0 usage unique est g\u00e9n\u00e9r\u00e9 pour vous, cliquez sur show pour l'afficher et le copier. Cliquez sur Open RStudio . Une nouvelle fen\u00eatre s'ouvre, entrez le nom d'utilisateur et le mot de passe fournis (\u00c9tape 6) dans le formulaire de connexion afin de d\u00e9marrer RStudio. \u00c0 partir de l'interface RStudio, entrez la commande library(shiny) dans la console afin d'importer la librarie Shiny. Exemple d'une application R-Shiny Vous pouvez utiliser l'exemple Hello Shiny pour explorer la structure d'une application Shiny. Lancer l'application \u00e0 partir de votre session RStudio en entrant les commandes suivantes: library(shiny) runExample(\"01_hello\") Votre application devrait correspondre \u00e0 l'image ci-dessous. Acc\u00e8s aux fichiers \u00e0 partir du lac de donn\u00e9es Par d\u00e9faut, le r\u00e9pertoire de travail dans RStudio se trouve sur le noeud du pilote du cluster Databricks. Pour conserver votre travail, vous devrez utiliser DBFS. Pour avoir acc\u00e8s au DBFS dans l'explorateur de fichiers, cliquez sur le bouton ... \u00e0 droite et entrez /dbfs/mnt/ . Le lac de donn\u00e9es sera disponible et vous pourrez y acc\u00e9der et stocker vos fichiers. Lorsque votre cluster s'\u00e9teint \u00e0 la fin de votre session, votre travail reste disponible \u00e0 votre retour. NOTE: Voici des exemples de code pour acc\u00e9der \u00e0 vos fichiers \u00e0 partir du lac de donn\u00e9es. library(SparkR) sparkR.session() testData = as.data.frame(read.df(\"/mnt/le chemin du fichier\", source = \"l'extension du fichier\", header=\"true\", inferSchema = \"true\")) str(testData) setwd(\"/dbfs/mnt/le chemin du fichier\") testData = read.csv(\"le nom du fichier\") str(testData) Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"R-Shiny"},{"location":"R-Shiny/#r-shiny-a-partir-de-rstudio","text":"Ce document d\u00e9crit comment acc\u00e9der R-Shiny \u00e0 partir de l'application Rstudio.","title":"R-Shiny \u00e0 partir de RStudio"},{"location":"R-Shiny/#commencer","text":"Afin d'utiliser R-Shiny, s.v.p. envoyer un message Slack \u00e0 l'\u00e9quipe de l'EAC pour activer RStudio dans votre cluster Databricks. Avertissement : Les clusters R-Shiny s'\u00e9teignent tous les jours \u00e0 19h . Pour r\u00e9duire vos co\u00fbts, veuillez arr\u00eater vos clusters R-Shiny lorsque vous ne les utilisez pas.","title":"Commencer"},{"location":"R-Shiny/#acces-a-r-shiny","text":"\u00c0 partir du portail Azure, lancer l'espace de travail Databricks qui vous a \u00e9t\u00e9 cr\u00e9\u00e9. \u00c0 partir de l'espace de travail Databricks, cliquez sur Cluster . \u00c0 partir de la liste de clusters disponibles, selectionnez le cluster sur lequel RStudio a \u00e9t\u00e9 install\u00e9. Note: Le cluster doit \u00eatre active pour acc\u00e9der \u00e0 l'application RStudio. Consulter la section Databricks pour plus de d\u00e9tails \u00e0 propos du d\u00e9marrage d'un cluster. Selectionnez l'onglet Apps . Cliquez sur Set up RStudio . Un mot de passe \u00e0 usage unique est g\u00e9n\u00e9r\u00e9 pour vous, cliquez sur show pour l'afficher et le copier. Cliquez sur Open RStudio . Une nouvelle fen\u00eatre s'ouvre, entrez le nom d'utilisateur et le mot de passe fournis (\u00c9tape 6) dans le formulaire de connexion afin de d\u00e9marrer RStudio. \u00c0 partir de l'interface RStudio, entrez la commande library(shiny) dans la console afin d'importer la librarie Shiny.","title":"Acc\u00e8s \u00e0 R-Shiny"},{"location":"R-Shiny/#exemple-dune-application-r-shiny","text":"Vous pouvez utiliser l'exemple Hello Shiny pour explorer la structure d'une application Shiny. Lancer l'application \u00e0 partir de votre session RStudio en entrant les commandes suivantes: library(shiny) runExample(\"01_hello\") Votre application devrait correspondre \u00e0 l'image ci-dessous.","title":"Exemple d'une application R-Shiny"},{"location":"R-Shiny/#acces-aux-fichiers-a-partir-du-lac-de-donnees","text":"Par d\u00e9faut, le r\u00e9pertoire de travail dans RStudio se trouve sur le noeud du pilote du cluster Databricks. Pour conserver votre travail, vous devrez utiliser DBFS. Pour avoir acc\u00e8s au DBFS dans l'explorateur de fichiers, cliquez sur le bouton ... \u00e0 droite et entrez /dbfs/mnt/ . Le lac de donn\u00e9es sera disponible et vous pourrez y acc\u00e9der et stocker vos fichiers. Lorsque votre cluster s'\u00e9teint \u00e0 la fin de votre session, votre travail reste disponible \u00e0 votre retour. NOTE: Voici des exemples de code pour acc\u00e9der \u00e0 vos fichiers \u00e0 partir du lac de donn\u00e9es. library(SparkR) sparkR.session() testData = as.data.frame(read.df(\"/mnt/le chemin du fichier\", source = \"l'extension du fichier\", header=\"true\", inferSchema = \"true\")) str(testData) setwd(\"/dbfs/mnt/le chemin du fichier\") testData = read.csv(\"le nom du fichier\") str(testData)","title":"Acc\u00e8s aux fichiers \u00e0 partir du lac de donn\u00e9es"},{"location":"R-Shiny/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"},{"location":"VirtualMachines/","text":"English Machines virtuelles Trouvez votre laboratoire DevTest Dans le portail Azure, cliquez sur le laboratoire DevTest dans le tableau de bord personnalis\u00e9 de votre projet. S\u00e9lectionnez le DevTest Lab qui a \u00e9t\u00e9 attribu\u00e9. Cr\u00e9ez votre machine virtuelle Note : Dans certains cas, une machine virtuelle aura \u00e9t\u00e9 cr\u00e9\u00e9e au pr\u00e9alable pour vous et vous n'aurez pas l'autorisation d'en cr\u00e9er une. Si vous devez apporter des changements \u00e0 votre machine virtuelle, consultez la FAQ . \u00c0 partir de la page Vue d'ensemble du laboratoire DevTest, cliquez sur le bouton + Ajouter . Choisissez une base appropri\u00e9e pour votre machine virtuelle (p. ex. Data Science Virtual Machine - Windows Server 2019). Pour en savoir plus sur le logiciel inclus dans l'image de machine virtuelle pour la science des donn\u00e9es (Data Science Virtual Machine), veuillez cliquer ici . Entrez un nom pour votre machine virtuelle ainsi qu'un nom d'utilisateur et un mot de passe que vous utiliserez pour vous connecter \u00e0 la machine virtuelle. D\u00e9cochez les cases Utiliser un secret enregistr\u00e9 et Enregistrer comme mot de passe par d\u00e9faut . Vous pouvez cliquer sur le lien Changer la taille pour modifier la taille de votre machine virtuelle si vous le souhaitez. Laissez les autres champs par d\u00e9faut et cliquez sur le bouton Cr\u00e9er . Trouvez votre machine virtuelle Faites d\u00e9filer la page Vue d'ensemble du laboratoire DevTest jusqu'\u00e0 ce que vous voyiez votre machine virtuelle sous Mes machines virtuelles . Cliquez sur votre machine virtuelle pour en afficher la Vue d'ensemble . D\u00e9marrez votre machine virtuelle \u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton D\u00e9marrer . Le demarrage de la machine virtuelle prendra quelques minutes. Surveillez l'avancement du d\u00e9marrage en cliquant sur l'ic\u00f4ne Notifications dans le coin sup\u00e9rieur droit de la fen\u00eatre. Connectez-vous \u00e0 votre machine virtuelle \u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur Connexion du navigateur (si vous ne voyez pas ce bouton, vous devrez peut-\u00eatre cliquer sur le bouton Connecter , puis choisir Bastion dans le menu d\u00e9roulant). Veuillez \u00e0 cocher la case Ouvrir dans une nouvelle fen\u00eatre , puis entrez le nom d'utilisateur et le mot de passe que vous avez utilis\u00e9 au moment de cr\u00e9er votre machine virtuelle, et cliquez sur le bouton Connecter . Votre machine virtuelle devrait s'ouvrir dans un nouvel onglet du navigateur. Note : Par d\u00e9faut, la machine virtuelle Ubuntu s'ouvre en mode Serveur Terminal. Vous pouvez acceder \u00e0 l\u2019interface graphique de votre machine Ubuntu \u00e0 l'aide de l'application X2Go , \u00e0 partir de votre machine Windows. Note : Apr\u00e8s avoir tent\u00e9 de vous connecter pour la premi\u00e8re fois, une erreur peut appara\u00eetre indiquant qu'un bloqueur de fen\u00eatres contextuelles emp\u00eache l'ouverture d'une nouvelle fen\u00eatre. Pour le d\u00e9sactiver, une ic\u00f4ne appara\u00eetra dans la barre de recherche du navigateur, s\u00e9lectionnez le bouton et cliquez sur toujours autoriser . Arr\u00eatez votre machine virtuelle Les machines virtuelles entra\u00eenent des co\u00fbts uniquement quand elles sont en marche. Pour \u00e9viter les d\u00e9penses inutiles, vous devez arr\u00eater votre machine virtuelle lorsque vous ne l'utilisez pas. 1. \u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton Arr\u00eater . Changer la langue d'affichage Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Machines Virtuelle"},{"location":"VirtualMachines/#machines-virtuelles","text":"","title":"Machines virtuelles"},{"location":"VirtualMachines/#trouvez-votre-laboratoire-devtest","text":"Dans le portail Azure, cliquez sur le laboratoire DevTest dans le tableau de bord personnalis\u00e9 de votre projet. S\u00e9lectionnez le DevTest Lab qui a \u00e9t\u00e9 attribu\u00e9.","title":"Trouvez votre laboratoire\u00a0DevTest"},{"location":"VirtualMachines/#creez-votre-machine-virtuelle","text":"Note : Dans certains cas, une machine virtuelle aura \u00e9t\u00e9 cr\u00e9\u00e9e au pr\u00e9alable pour vous et vous n'aurez pas l'autorisation d'en cr\u00e9er une. Si vous devez apporter des changements \u00e0 votre machine virtuelle, consultez la FAQ . \u00c0 partir de la page Vue d'ensemble du laboratoire DevTest, cliquez sur le bouton + Ajouter . Choisissez une base appropri\u00e9e pour votre machine virtuelle (p. ex. Data Science Virtual Machine - Windows Server 2019). Pour en savoir plus sur le logiciel inclus dans l'image de machine virtuelle pour la science des donn\u00e9es (Data Science Virtual Machine), veuillez cliquer ici . Entrez un nom pour votre machine virtuelle ainsi qu'un nom d'utilisateur et un mot de passe que vous utiliserez pour vous connecter \u00e0 la machine virtuelle. D\u00e9cochez les cases Utiliser un secret enregistr\u00e9 et Enregistrer comme mot de passe par d\u00e9faut . Vous pouvez cliquer sur le lien Changer la taille pour modifier la taille de votre machine virtuelle si vous le souhaitez. Laissez les autres champs par d\u00e9faut et cliquez sur le bouton Cr\u00e9er .","title":"Cr\u00e9ez votre machine virtuelle"},{"location":"VirtualMachines/#trouvez-votre-machine-virtuelle","text":"Faites d\u00e9filer la page Vue d'ensemble du laboratoire DevTest jusqu'\u00e0 ce que vous voyiez votre machine virtuelle sous Mes machines virtuelles . Cliquez sur votre machine virtuelle pour en afficher la Vue d'ensemble .","title":"Trouvez votre machine virtuelle"},{"location":"VirtualMachines/#demarrez-votre-machine-virtuelle","text":"\u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton D\u00e9marrer . Le demarrage de la machine virtuelle prendra quelques minutes. Surveillez l'avancement du d\u00e9marrage en cliquant sur l'ic\u00f4ne Notifications dans le coin sup\u00e9rieur droit de la fen\u00eatre.","title":"D\u00e9marrez votre machine virtuelle"},{"location":"VirtualMachines/#connectez-vous-a-votre-machine-virtuelle","text":"\u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur Connexion du navigateur (si vous ne voyez pas ce bouton, vous devrez peut-\u00eatre cliquer sur le bouton Connecter , puis choisir Bastion dans le menu d\u00e9roulant). Veuillez \u00e0 cocher la case Ouvrir dans une nouvelle fen\u00eatre , puis entrez le nom d'utilisateur et le mot de passe que vous avez utilis\u00e9 au moment de cr\u00e9er votre machine virtuelle, et cliquez sur le bouton Connecter . Votre machine virtuelle devrait s'ouvrir dans un nouvel onglet du navigateur. Note : Par d\u00e9faut, la machine virtuelle Ubuntu s'ouvre en mode Serveur Terminal. Vous pouvez acceder \u00e0 l\u2019interface graphique de votre machine Ubuntu \u00e0 l'aide de l'application X2Go , \u00e0 partir de votre machine Windows. Note : Apr\u00e8s avoir tent\u00e9 de vous connecter pour la premi\u00e8re fois, une erreur peut appara\u00eetre indiquant qu'un bloqueur de fen\u00eatres contextuelles emp\u00eache l'ouverture d'une nouvelle fen\u00eatre. Pour le d\u00e9sactiver, une ic\u00f4ne appara\u00eetra dans la barre de recherche du navigateur, s\u00e9lectionnez le bouton et cliquez sur toujours autoriser .","title":"Connectez-vous \u00e0 votre machine virtuelle"},{"location":"VirtualMachines/#arretez-votre-machine-virtuelle","text":"Les machines virtuelles entra\u00eenent des co\u00fbts uniquement quand elles sont en marche. Pour \u00e9viter les d\u00e9penses inutiles, vous devez arr\u00eater votre machine virtuelle lorsque vous ne l'utilisez pas. 1. \u00c0 partir de la page Vue d'ensemble de votre machine virtuelle, cliquez sur le bouton Arr\u00eater .","title":"Arr\u00eatez votre machine virtuelle"},{"location":"VirtualMachines/#changer-la-langue-daffichage","text":"Voir la page Langue pour savoir comment changer la langue d'affichage.","title":"Changer la langue d'affichage"}]}