{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Collaborative Analytics Environment (CAE) The Collaborative Analytics Environment (CAE) provides cloud services for data ingestion, transformation and preparation, as well as data exploration and computation. It includes tools for collaborative analytics, machine learning environments, and data visualization capabilities. Notebook environments and virtual machines provide analytical capabilties using a variety of statistical software such as R, Python, SAS, etc. The CAE leverages Microsoft Azure Platform as a Service (PaaS) and Software as a Service (SaaS) offerings. Environment Overview We are currently testing different use cases against the platform. Each use case can be onboarded into the main or a new private environment can be created. Main (Shared) Environment Shared with users from several use cases. When granted access to this environment, users can view / share data across use cases. Private Environment A private environment configured upon request so only named users can access workspace files. Data Ingestion Data enters the platform via an external storage account. Once inside the platform, the data is stored an internal storage account (Data Lake). Publicly available data sources may be ingested directly via one of the platform tools. External Storage Account Users will be able to access the external storage account from the Internet, and use it to upload / download data in and out the environment. In some private environments, restrictions or additonal vetting processes may be implemented for data upload / download. Internal Storage Account (Data Lake) Files that are uploaded into the external storage account are automatically moved to an internal Data Lake. This Data Lake is located in a secure virtual network, and is only accessible from platform services and virtual machines. Change Display Language See Language page to find out how to change the display language.","title":"Getting Started"},{"location":"#collaborative-analytics-environment-cae","text":"The Collaborative Analytics Environment (CAE) provides cloud services for data ingestion, transformation and preparation, as well as data exploration and computation. It includes tools for collaborative analytics, machine learning environments, and data visualization capabilities. Notebook environments and virtual machines provide analytical capabilties using a variety of statistical software such as R, Python, SAS, etc. The CAE leverages Microsoft Azure Platform as a Service (PaaS) and Software as a Service (SaaS) offerings.","title":"Collaborative Analytics Environment (CAE)"},{"location":"#environment-overview","text":"We are currently testing different use cases against the platform. Each use case can be onboarded into the main or a new private environment can be created.","title":"Environment Overview"},{"location":"#main-shared-environment","text":"Shared with users from several use cases. When granted access to this environment, users can view / share data across use cases.","title":"Main (Shared) Environment"},{"location":"#private-environment","text":"A private environment configured upon request so only named users can access workspace files.","title":"Private Environment"},{"location":"#data-ingestion","text":"Data enters the platform via an external storage account. Once inside the platform, the data is stored an internal storage account (Data Lake). Publicly available data sources may be ingested directly via one of the platform tools.","title":"Data Ingestion"},{"location":"#external-storage-account","text":"Users will be able to access the external storage account from the Internet, and use it to upload / download data in and out the environment. In some private environments, restrictions or additonal vetting processes may be implemented for data upload / download.","title":"External Storage Account"},{"location":"#internal-storage-account-data-lake","text":"Files that are uploaded into the external storage account are automatically moved to an internal Data Lake. This Data Lake is located in a secure virtual network, and is only accessible from platform services and virtual machines.","title":"Internal Storage Account (Data Lake)"},{"location":"#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"AzureML/","text":"Azure Machine Learning Accessing Azure Machine Learning Dashboard See the Dashboard section of this documentation from more information. 1. Click on the Dashboard menu from the Azure Portal. Your default view might already be set to dashboard. Under Machine Learning , select the Machine Learning workspace that was created for you. If the workspace you want to open isn't listed, click on See more to access the complete list. Azure Portal In the Azure Portal Search box, search for Machine Learning . You should see the list of the Machine Learning workspaces you were given permission to access. Select the Machine Learning workspace you want to access. Machine Learning URL Navigate to https://ml.azure.com/, sign in with your cloud account credentials, and select vdl subscription and the Machine Learning workspace that was created for you. Getting Started On the machine learning Overview page, click Launch studio . Use the drop-down to select vdl subscription and the Machine Learning workspace you want to access, then click Get started . Once inside your Machine Learning workspace, you can train, deploy and manage machine learning models, use AutoML, and run pipelines. See Getting started quickly for more information. Using Azure ML Notebook standalone Requirements \u2022 A compute instance in Azure ML. You should see it under Compute --> Compute instances . Note : If a compute instance has not been created for you, please contact the support team via Slack . Steps Under Notebooks , create a new notebook in your user directory. You can then enter the code to execute. Select the Compute instance assigned to you. Click the run all cells button to execute your code. Using Databricks Connect as Remote Compute Disclaimer: Please note that the Databricks connect configuration shown below is under revision and will likely change in the near future. Requirements \u2022 A compute instance in Azure ML. You should see it under Compute --> Compute instances . Note : If a compute instance has not been created for you, please contact the support team via Slack . Steps Under Notebooks , open Terminal . Select your Compute instance from the drop-down next to Compute . Execute the code from Databricks Connect Setup in the terminal, while following the prompts to continue as needed. This code installs Python 3.7 and sets up a new kernel for Azure ML notebooks. When prompted, enter the following values to configure Databricks connect: Host: the URL from the Overview page for your Databricks workspace. Token: the personal access token generated in your Databricks Workspace User Settings. Cluster ID: the value found under Cluster --> Advanced Options --> Tags in your Databricks workspace. Org ID: the part of the Databricks URL found after .net/?o= Port: keep the existing value Execute the following code in terminal to test the connectivity to Azure Databricks. databricks-connect test Create a new notebook with Azure ML and select the Python 3 kernel . It should now display Python 3.7.9 Databricks connect should be setup now! Try the Databricks connect example code in a notebook, replacing public-data/incoming/1test.txt with the path to a file in your data lake container. Change Display Language See Language page to find out how to change the display language.","title":"Azure Machine Learning"},{"location":"AzureML/#azure-machine-learning","text":"","title":"Azure Machine Learning"},{"location":"AzureML/#accessing-azure-machine-learning","text":"","title":"Accessing Azure Machine Learning"},{"location":"AzureML/#dashboard","text":"See the Dashboard section of this documentation from more information. 1. Click on the Dashboard menu from the Azure Portal. Your default view might already be set to dashboard. Under Machine Learning , select the Machine Learning workspace that was created for you. If the workspace you want to open isn't listed, click on See more to access the complete list.","title":"Dashboard"},{"location":"AzureML/#azure-portal","text":"In the Azure Portal Search box, search for Machine Learning . You should see the list of the Machine Learning workspaces you were given permission to access. Select the Machine Learning workspace you want to access.","title":"Azure Portal"},{"location":"AzureML/#machine-learning-url","text":"Navigate to https://ml.azure.com/, sign in with your cloud account credentials, and select vdl subscription and the Machine Learning workspace that was created for you.","title":"Machine Learning URL"},{"location":"AzureML/#getting-started","text":"On the machine learning Overview page, click Launch studio . Use the drop-down to select vdl subscription and the Machine Learning workspace you want to access, then click Get started . Once inside your Machine Learning workspace, you can train, deploy and manage machine learning models, use AutoML, and run pipelines. See Getting started quickly for more information.","title":"Getting Started"},{"location":"AzureML/#using-azure-ml-notebook-standalone","text":"","title":"Using Azure ML Notebook standalone"},{"location":"AzureML/#requirements","text":"\u2022 A compute instance in Azure ML. You should see it under Compute --> Compute instances . Note : If a compute instance has not been created for you, please contact the support team via Slack .","title":"Requirements"},{"location":"AzureML/#steps","text":"Under Notebooks , create a new notebook in your user directory. You can then enter the code to execute. Select the Compute instance assigned to you. Click the run all cells button to execute your code.","title":"Steps"},{"location":"AzureML/#using-databricks-connect-as-remote-compute","text":"Disclaimer: Please note that the Databricks connect configuration shown below is under revision and will likely change in the near future.","title":"Using Databricks Connect as Remote Compute"},{"location":"AzureML/#requirements_1","text":"\u2022 A compute instance in Azure ML. You should see it under Compute --> Compute instances . Note : If a compute instance has not been created for you, please contact the support team via Slack .","title":"Requirements"},{"location":"AzureML/#steps_1","text":"Under Notebooks , open Terminal . Select your Compute instance from the drop-down next to Compute . Execute the code from Databricks Connect Setup in the terminal, while following the prompts to continue as needed. This code installs Python 3.7 and sets up a new kernel for Azure ML notebooks. When prompted, enter the following values to configure Databricks connect: Host: the URL from the Overview page for your Databricks workspace. Token: the personal access token generated in your Databricks Workspace User Settings. Cluster ID: the value found under Cluster --> Advanced Options --> Tags in your Databricks workspace. Org ID: the part of the Databricks URL found after .net/?o= Port: keep the existing value Execute the following code in terminal to test the connectivity to Azure Databricks. databricks-connect test Create a new notebook with Azure ML and select the Python 3 kernel . It should now display Python 3.7.9 Databricks connect should be setup now! Try the Databricks connect example code in a notebook, replacing public-data/incoming/1test.txt with the path to a file in your data lake container.","title":"Steps"},{"location":"AzureML/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"AzureMLRemoteCompute/","text":"<!--## Using Attach Databricks as Remote Compute <!--### Requirements <!--\u2022 An attached compute in Azure ML. You should see it under Compute > Attached compute . <!--\u2022 A compute instance in Azure ML. You should see it under Compute > Compute instances . <!-- Note : If a compute instance or/and attached compute have not been created for you, please contact the support team via Slack . <!--### Steps <!--1. Under Notebooks , create a new folder in your user directory. <!-- <!--2. Create a sample .py file in the newly created folder, and select Text as the File type . <!-- <!--This file should contain your Python code to execute with Databricks. <!-- <!--3. In your user root directory, create a new notebook . <!-- <!--4. Copy and paste the Attach-Databricks-Notebook code in the new notebook. Update the code with the missing values. It should run as validated with Azure ML SDK version 1.18.0. <!-- <!--5. You can see the results with the following steps: <!-- a . Click on the ** PipelineRun link ** . ! [ PipelinRun Link ]( images / AttachDatabricks . png ) b . Click on the ** Databricks run page link ** under ** Outputs + logs ** . ! [ AttachDatabricks Result ]( images / AttachDatabricksResult0 . PNG ) c . You should be redirected to the Databricks run page . ! [ AttachDatabricksResult ]( images / AttachDatabricksResult . PNG ) d . Under ** Driver Logs ** , see the result in the ** Standart output ** tab . ! [ AttachDatabricksResult2 ]( images / AttachDatabricksResult2 . PNG ) <!-- References : <!--\u2022 Using Databricks Connect <!--\u2022 Using attach Databricks as remote compute","title":"AzureMLRemoteCompute"},{"location":"AzureSQL/","text":"Azure SQL Database An Azure SQL Database can be setup in advance if your project requires one. Reminder : The CAE Azure SQL Databases are only accessible from inside the CAE cloud environment. They are not accessible from any of the Government of Canada Data Centres. Accessing Azure SQL Database Azure Data Factory A linked service can be setup inside Azure Data Factory. Configure the linked service to connect via the self-hosted integration runtime and use Managed Identity as the Authentication type . Please contact the support team through the https://cae-eac.slack.com channel if you need assistance. Databricks Databricks notebooks can be configured to connect to the database. Because additional setup is required, please contact the the support team through the https://cae-eac.slack.com channel to request this configuration as well as example notebooks. Virtual Machine You can access an Azure SQL database from your cloud virtual machine, using various applications including: 1. SQL Server Management Studio 2. Power BI Desktop 3. Azure Data Studio 4. Visual Studio or Visual Studio Code Prerequisites A virtual machine in the Collaborative Analytics Environment (CAE). See the VM page for more information. SQL Server Management Studio or another tool such as Power BI Desktop . These tools are available by default in the Windows Data Science Virtual Machine images. Steps Login to your CAE virtual machine . Launch a tool such as SQL Server Management Studio . Choose Azure Active Directory - Universal with MFA as the Authentication type. Enter your Azure SQL server name and your cloud account username as User name. 5. Click on Options . In the Connection Properties tab, enter your database name next to the Connect to database label and click on Connect . Sign in with your cloud account credentials. Change Display Language See Language page to find out how to change the display language.","title":"Azure SQL Database"},{"location":"AzureSQL/#azure-sql-database","text":"An Azure SQL Database can be setup in advance if your project requires one. Reminder : The CAE Azure SQL Databases are only accessible from inside the CAE cloud environment. They are not accessible from any of the Government of Canada Data Centres.","title":"Azure SQL Database"},{"location":"AzureSQL/#accessing-azure-sql-database","text":"","title":"Accessing Azure SQL Database"},{"location":"AzureSQL/#azure-data-factory","text":"A linked service can be setup inside Azure Data Factory. Configure the linked service to connect via the self-hosted integration runtime and use Managed Identity as the Authentication type . Please contact the support team through the https://cae-eac.slack.com channel if you need assistance.","title":"Azure Data Factory"},{"location":"AzureSQL/#databricks","text":"Databricks notebooks can be configured to connect to the database. Because additional setup is required, please contact the the support team through the https://cae-eac.slack.com channel to request this configuration as well as example notebooks.","title":"Databricks"},{"location":"AzureSQL/#virtual-machine","text":"You can access an Azure SQL database from your cloud virtual machine, using various applications including: 1. SQL Server Management Studio 2. Power BI Desktop 3. Azure Data Studio 4. Visual Studio or Visual Studio Code","title":"Virtual Machine"},{"location":"AzureSQL/#prerequisites","text":"A virtual machine in the Collaborative Analytics Environment (CAE). See the VM page for more information. SQL Server Management Studio or another tool such as Power BI Desktop . These tools are available by default in the Windows Data Science Virtual Machine images.","title":"Prerequisites"},{"location":"AzureSQL/#steps","text":"Login to your CAE virtual machine . Launch a tool such as SQL Server Management Studio . Choose Azure Active Directory - Universal with MFA as the Authentication type. Enter your Azure SQL server name and your cloud account username as User name. 5. Click on Options . In the Connection Properties tab, enter your database name next to the Connect to database label and click on Connect . Sign in with your cloud account credentials.","title":"Steps"},{"location":"AzureSQL/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"AzureStorage/","text":"Azure Storage Data can be uploaded to the platform via the Azure Portal or the Azure Storage Explorer application. Once data uploaded to an external Blob storage account, it is automatically ingested into an internal Azure Data Lake Storage (ADLS) account. Once data is in the data lake, users have their choice of tools for transformation and integration. They can use Web based tools such as Databricks and Data Factory to do their transformations or they can use desktop tools on a virtual machine (VM) to tansform & analyse the data. Cleansed and transformed data can be placed into different folders (containing higher quality / processed datasets) or loaded into a database. Users can once again connect to this data with the tools they would like to use, either from their VMs or other platform services such as Databricks and Data Factory. Reminder: Internal Storage Accounts can only be accessed from a VM in the Collaborative Analytics Environment (CAE) - See the FAQ Storage Explorer - Azure Portal Navigate to the Storage Account (Preview) from the Azure Portal. Select your subscription, then navigate the storage account. Storage Explorer - Personal Workstation or Cloud Virtual Machine Download the Azure Storage Explorer application, and install it on your workstation or VM. Launch Azure Storage Explorer from the Start menu. Login with your Azure Account. Enter your Cloud credentials Storage Explorer - Network B VDI This section is for Statistics Canada employees who need to upload data from Network B. 1. Download the Azure Storage Explorer application, and install it on your Network B VDI. 2. Launch Azure Storage Explorer from the Start menu. 3. On a Network B VDI, you can only access your storage account with a temporary SAS token. Please contact the support team through the Slack channel to obtain one. Note: See the FAQ for information on configuring Network B proxy settings. Microsoft Documentation Azure Storage Explorer Download Quickstart: Upload, download, and list blobs with the Azure portal Change Display Language See Language page to find out how to change the display language.","title":"Azure Storage"},{"location":"AzureStorage/#azure-storage","text":"Data can be uploaded to the platform via the Azure Portal or the Azure Storage Explorer application. Once data uploaded to an external Blob storage account, it is automatically ingested into an internal Azure Data Lake Storage (ADLS) account. Once data is in the data lake, users have their choice of tools for transformation and integration. They can use Web based tools such as Databricks and Data Factory to do their transformations or they can use desktop tools on a virtual machine (VM) to tansform & analyse the data. Cleansed and transformed data can be placed into different folders (containing higher quality / processed datasets) or loaded into a database. Users can once again connect to this data with the tools they would like to use, either from their VMs or other platform services such as Databricks and Data Factory. Reminder: Internal Storage Accounts can only be accessed from a VM in the Collaborative Analytics Environment (CAE) - See the FAQ","title":"Azure Storage"},{"location":"AzureStorage/#storage-explorer-azure-portal","text":"Navigate to the Storage Account (Preview) from the Azure Portal. Select your subscription, then navigate the storage account.","title":"Storage Explorer - Azure Portal"},{"location":"AzureStorage/#storage-explorer-personal-workstation-or-cloud-virtual-machine","text":"Download the Azure Storage Explorer application, and install it on your workstation or VM. Launch Azure Storage Explorer from the Start menu. Login with your Azure Account. Enter your Cloud credentials","title":"Storage Explorer - Personal Workstation or Cloud Virtual Machine"},{"location":"AzureStorage/#storage-explorer-network-b-vdi","text":"This section is for Statistics Canada employees who need to upload data from Network B. 1. Download the Azure Storage Explorer application, and install it on your Network B VDI. 2. Launch Azure Storage Explorer from the Start menu. 3. On a Network B VDI, you can only access your storage account with a temporary SAS token. Please contact the support team through the Slack channel to obtain one. Note: See the FAQ for information on configuring Network B proxy settings.","title":"Storage Explorer - Network B VDI"},{"location":"AzureStorage/#microsoft-documentation","text":"Azure Storage Explorer Download Quickstart: Upload, download, and list blobs with the Azure portal","title":"Microsoft Documentation"},{"location":"AzureStorage/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"Dashboards/","text":"Dashboards Dashboards are a focused and organized view of your cloud resources in the Azure portal. They serve as a workspace where you can quickly launch tasks for day-to-day operations and monitor resources. Build custom dashboards based on projects, tasks, or user roles, for example. The Azure portal provides a default dashboard as a starting point. You can edit the default dashboard. Create and customize additional dashboards, and publish and share dashboards to make them available to other users. Access Your Environment's Dashboard From the Azure portal menu, select Dashboard . Your default view might already be set to dashboard. Select the arrow next to the dashboard name. Select your dashboard from the displayed list of dashboards. If the dashboard you want to open isn't listed: a. Select Browse all dashboards . b. In the Type field, select Shared dashboards . c. Ensure the list of selected subsciptions includes the vdl subscription. You can also enter text to filter dashboards by name. d. Select a dashboard from the list of shared dashboards. Note: Please send a Slack message if you don't know the name of the dashboard that was created for your environment. Microsoft Documentation https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards Change Display Language See Language page to find out how to change the display language.","title":"Dashboards"},{"location":"Dashboards/#dashboards","text":"Dashboards are a focused and organized view of your cloud resources in the Azure portal. They serve as a workspace where you can quickly launch tasks for day-to-day operations and monitor resources. Build custom dashboards based on projects, tasks, or user roles, for example. The Azure portal provides a default dashboard as a starting point. You can edit the default dashboard. Create and customize additional dashboards, and publish and share dashboards to make them available to other users.","title":"Dashboards"},{"location":"Dashboards/#access-your-environments-dashboard","text":"From the Azure portal menu, select Dashboard . Your default view might already be set to dashboard. Select the arrow next to the dashboard name. Select your dashboard from the displayed list of dashboards. If the dashboard you want to open isn't listed: a. Select Browse all dashboards . b. In the Type field, select Shared dashboards . c. Ensure the list of selected subsciptions includes the vdl subscription. You can also enter text to filter dashboards by name. d. Select a dashboard from the list of shared dashboards. Note: Please send a Slack message if you don't know the name of the dashboard that was created for your environment.","title":"Access Your Environment's Dashboard"},{"location":"Dashboards/#microsoft-documentation","text":"https://docs.microsoft.com/en-us/azure/azure-portal/azure-portal-dashboards","title":"Microsoft Documentation"},{"location":"Dashboards/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"DataBricks/","text":"Azure Databricks Accessing Databricks Dashboard See the Dashboard section of this documentation from more information. 1. Click on the Dashboard menu from the Azure Portal. Databricks URL Navigate to https://canadacentral.azuredatabricks.net/, sign in with your cloud account credentials, and select the Databricks workspace that was created for you. Azure Portal In the Azure Portal Search box, search for Databricks . You should then see a list of the Databricks workspaces you were given permission to access. Getting Started Once inside Databricks you can create a new notebook or open an existing notebook. See First Access to Databricks for more information. Creating a Cluster Since you do not have permission to create a cluster, please send a slack message if a cluster has not been created for you or if you require changes to your cluster. Note: You must have a cluster running before you can run code inside your notebook. See below or the FAQ for information on how to start a cluster. Creating a Notebook One way to create a notebook is to click on the New Notebook link from the main Databricks page. You can then provide a name for your notebook and select the default notebook language. From the available list of clusters, select the cluster to which you wish to attach your notebook. To start or change a cluster from within a notebook, open the notebook and click on the cluster drop down found at the top right of the notebook. You can then start the cluster or detach it and attach a different one. Sharing a Databricks Notebook To share a notebook or invite other collaborators, right-click on a specific notebook file or folder from the Workspace menu, and select Permissions . You can also do this by clicking on the Permissions button from within a notebook. Once shared, multiple authors can participate in the same notebook session and co-author at the same time. Note: To add a user to the Databricks workspace, please send a Slack message. Ingesting Data into Databricks Data can be mounted or uploaded to the Databricks File System (DBFS), which is storage specific to the Databricks workspace. You can read data from a data source or even upload a data file (e.g. CSV) directly to the DBFS. Note: The internal data lake container for your environment has already been mounted for you and you can work with the container directly. Please send a Slack message if you don't know the name of your mounted data lake container. Adding Data to Databricks Reading Mounted Files Example: %python testData = spark . read . format ( ' csv ' ). options ( header = ' true ' , inferSchema = ' true ' ). load ( ' / mnt / mad - du / incoming / age - single - years -2018 - census - csv . csv ' ) display ( testData ) Changing Notebook Default Language Mixing Notebook Languages You can override the default language by specifying the language magic command % at the beginning of a cell. The supported magic commands are: %python, %r, %scala, and %sql. Note: When you invoke a language magic command, the command is dispatched to the REPL in the execution context for the notebook. Variables defined in one language (and hence in the REPL for that language) are not available in the REPL of another language. REPLs can share state only through external resources such as files in DBFS or objects in object storage. Notebooks also support a few auxiliary magic commands: %sh: Allows you to run shell code in your notebook. To fail the cell if the shell command has a non-zero exit status, add the -e option. This command runs only on the Apache Spark driver, and not the workers. To run a shell command on all nodes, use an init script. %fs: Allows you to use dbutils filesystem commands. %md: Allows you to include various types of documentation, including text, images, and mathematical formulas and equations. Starting a Databricks Cluster Click on the cluster drop-down list. Select a cluster from the list. Click on the Start Cluster link. Click on the cluster drop-down list. Select a cluster from the list. Click on the Start Cluster link. Databricks Connect VM Setup Databricks connect is a method for accessing a databricks environment without having to connect through the Azure Portal. Its main use is to allow you to use other IDEs to work on databricks code. The following are the steps for installing and testing databricks connect on your VM environment. Databricks Connect has conflictions with the Pyspark instalation that is on our DataScience VMs by default. The default path of this is C:\\dsvm\\tools\\spark-2.4.4-bin-hadoop2.7 . This folder must be either deleted or moved in order to install Databricks connect. Before installing databricks connect a conda environment should be created. To do this open command prompt and do the following. conda create -- name dbconnect python = 3 . 7 conda activate dbconnect type pip install - U databricks - connect == X . Y . * (X and Y are to be replaced with the version number of the spark cluster. To see this open databricks from the azure portal and click clusters on the left of the page. You are looking for the runtime) 3. Once the installation has finished, you will need to collect 3 peices of information (copy the text somewhere) * The databricks Org ID (check URL from databricks page, look for ?o= the number that follows is the org ID) * A personal access token (Look at the top right of the databricks window for the button \"Databricks-XXX\", click user settings, then Generate New Token) * Cluster ID (go back to the clusters page, click on the cluster you wish to use, check the URL for clusters/XXXX-XXXXXX-XXXXXXXXX/configuration the Xs are the value) 4. In command prompt type databricks-connect configure, then enter these values. Databricks Host: https//:canadacentral.azuredatabricks.net **Databricks Token:** `the personal access token from step 3` **Cluster ID:** `the cluster ID from step 3` **Org ID:** `Once again from part 3` **Port:** leave as 15001 The last setup step requires changing an enviroment variable SPARK_HOME to c:\\miniconda\\envs\\(conda env name))\\lib\\site-packages\\pyspark then restart your VM (If you do not know how to change environment variables please ask for help). To test if your configuration setup works enter databricks-connect test in command prompt. If the cluster you are using is not running when you start your test you will receive warning messages until it has started. This can take time. Microsoft Documentation Databricks-Connects First Access to Databricks For more information on Databricks Install Libraries in Current Notebook Session Library Management for Admins Change Display Language See Language page to find out how to change the display language.","title":"Databricks"},{"location":"DataBricks/#azure-databricks","text":"","title":"Azure Databricks"},{"location":"DataBricks/#accessing-databricks","text":"","title":"Accessing Databricks"},{"location":"DataBricks/#dashboard","text":"See the Dashboard section of this documentation from more information. 1. Click on the Dashboard menu from the Azure Portal.","title":"Dashboard"},{"location":"DataBricks/#databricks-url","text":"Navigate to https://canadacentral.azuredatabricks.net/, sign in with your cloud account credentials, and select the Databricks workspace that was created for you.","title":"Databricks URL"},{"location":"DataBricks/#azure-portal","text":"In the Azure Portal Search box, search for Databricks . You should then see a list of the Databricks workspaces you were given permission to access.","title":"Azure Portal"},{"location":"DataBricks/#getting-started","text":"Once inside Databricks you can create a new notebook or open an existing notebook. See First Access to Databricks for more information.","title":"Getting Started"},{"location":"DataBricks/#creating-a-cluster","text":"Since you do not have permission to create a cluster, please send a slack message if a cluster has not been created for you or if you require changes to your cluster. Note: You must have a cluster running before you can run code inside your notebook. See below or the FAQ for information on how to start a cluster.","title":"Creating a Cluster"},{"location":"DataBricks/#creating-a-notebook","text":"One way to create a notebook is to click on the New Notebook link from the main Databricks page. You can then provide a name for your notebook and select the default notebook language. From the available list of clusters, select the cluster to which you wish to attach your notebook. To start or change a cluster from within a notebook, open the notebook and click on the cluster drop down found at the top right of the notebook. You can then start the cluster or detach it and attach a different one.","title":"Creating a Notebook"},{"location":"DataBricks/#sharing-a-databricks-notebook","text":"To share a notebook or invite other collaborators, right-click on a specific notebook file or folder from the Workspace menu, and select Permissions . You can also do this by clicking on the Permissions button from within a notebook. Once shared, multiple authors can participate in the same notebook session and co-author at the same time. Note: To add a user to the Databricks workspace, please send a Slack message.","title":"Sharing a Databricks Notebook"},{"location":"DataBricks/#ingesting-data-into-databricks","text":"Data can be mounted or uploaded to the Databricks File System (DBFS), which is storage specific to the Databricks workspace. You can read data from a data source or even upload a data file (e.g. CSV) directly to the DBFS. Note: The internal data lake container for your environment has already been mounted for you and you can work with the container directly. Please send a Slack message if you don't know the name of your mounted data lake container.","title":"Ingesting Data into Databricks"},{"location":"DataBricks/#adding-data-to-databricks","text":"","title":"Adding Data to Databricks"},{"location":"DataBricks/#reading-mounted-files","text":"Example: %python testData = spark . read . format ( ' csv ' ). options ( header = ' true ' , inferSchema = ' true ' ). load ( ' / mnt / mad - du / incoming / age - single - years -2018 - census - csv . csv ' ) display ( testData )","title":"Reading Mounted Files"},{"location":"DataBricks/#changing-notebook-default-language","text":"","title":"Changing Notebook Default Language"},{"location":"DataBricks/#mixing-notebook-languages","text":"You can override the default language by specifying the language magic command % at the beginning of a cell. The supported magic commands are: %python, %r, %scala, and %sql. Note: When you invoke a language magic command, the command is dispatched to the REPL in the execution context for the notebook. Variables defined in one language (and hence in the REPL for that language) are not available in the REPL of another language. REPLs can share state only through external resources such as files in DBFS or objects in object storage. Notebooks also support a few auxiliary magic commands: %sh: Allows you to run shell code in your notebook. To fail the cell if the shell command has a non-zero exit status, add the -e option. This command runs only on the Apache Spark driver, and not the workers. To run a shell command on all nodes, use an init script. %fs: Allows you to use dbutils filesystem commands. %md: Allows you to include various types of documentation, including text, images, and mathematical formulas and equations.","title":"Mixing Notebook Languages"},{"location":"DataBricks/#starting-a-databricks-cluster","text":"Click on the cluster drop-down list. Select a cluster from the list. Click on the Start Cluster link. Click on the cluster drop-down list. Select a cluster from the list. Click on the Start Cluster link.","title":"Starting a Databricks Cluster"},{"location":"DataBricks/#databricks-connect-vm-setup","text":"Databricks connect is a method for accessing a databricks environment without having to connect through the Azure Portal. Its main use is to allow you to use other IDEs to work on databricks code. The following are the steps for installing and testing databricks connect on your VM environment. Databricks Connect has conflictions with the Pyspark instalation that is on our DataScience VMs by default. The default path of this is C:\\dsvm\\tools\\spark-2.4.4-bin-hadoop2.7 . This folder must be either deleted or moved in order to install Databricks connect. Before installing databricks connect a conda environment should be created. To do this open command prompt and do the following. conda create -- name dbconnect python = 3 . 7 conda activate dbconnect type pip install - U databricks - connect == X . Y . * (X and Y are to be replaced with the version number of the spark cluster. To see this open databricks from the azure portal and click clusters on the left of the page. You are looking for the runtime) 3. Once the installation has finished, you will need to collect 3 peices of information (copy the text somewhere) * The databricks Org ID (check URL from databricks page, look for ?o= the number that follows is the org ID) * A personal access token (Look at the top right of the databricks window for the button \"Databricks-XXX\", click user settings, then Generate New Token) * Cluster ID (go back to the clusters page, click on the cluster you wish to use, check the URL for clusters/XXXX-XXXXXX-XXXXXXXXX/configuration the Xs are the value) 4. In command prompt type databricks-connect configure, then enter these values. Databricks Host: https//:canadacentral.azuredatabricks.net **Databricks Token:** `the personal access token from step 3` **Cluster ID:** `the cluster ID from step 3` **Org ID:** `Once again from part 3` **Port:** leave as 15001 The last setup step requires changing an enviroment variable SPARK_HOME to c:\\miniconda\\envs\\(conda env name))\\lib\\site-packages\\pyspark then restart your VM (If you do not know how to change environment variables please ask for help). To test if your configuration setup works enter databricks-connect test in command prompt. If the cluster you are using is not running when you start your test you will receive warning messages until it has started. This can take time.","title":"Databricks Connect VM Setup"},{"location":"DataBricks/#microsoft-documentation","text":"Databricks-Connects First Access to Databricks For more information on Databricks Install Libraries in Current Notebook Session Library Management for Admins","title":"Microsoft Documentation"},{"location":"DataBricks/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"DataFactory/","text":"Azure Data Factory (ADF) Access Data Factory Dashboard See the Dashboard section of this documentation from more information. Click on the Dashboard menu from the Azure Portal. ADF URL Navigate to https://adf.azure.com, and select the Data Factory instance that was created for you. Azure Portal In the Azure Portal Search box, search for Data factories . You should then see a list of the Data Factories you were given permission to access. Authoring Click on Author and Monitor . In Data Factory, you have the ability to author and deploy resources. See Visual authoring in Azure Data Factory for more information. You can also use some of the various wizards provided on Data Factory Overview page. NOTE: Configuring SSIS Integration is NOT recommended. Contact the support team through the Slack channel if you have questions. See Azure Documentation Tutorials for more details. Access the Data Lake from ADF A Data Lake connection has been pre-configured for your environment. 1. Click on Manage . 2. Click on Linked Services . 3. The linked service with the Azure Data Lake Storage Gen2 type is your Data Lake . Note: You have been granted access to specific containers created in the Data Lake for your environment. Access Azure SQL Database Some projects have an Azure SQL Database instance. 1. Click on Manage . 2. Click on Linked Services . 3. The linked service(s) with the Azure SQL Database type is / are your Database(s) Save / Publish Your Data Factory Resources Azure Data Factory can be configured to save your work to the following locations: 1. Git repository 2. Publish directly to Data Factory Git (when supported) When Git is enabled you can see your configuration and save your work to a specific branch. 1. Click on Manage 2. Click on Git Configuration . 3. See the Git configuration that was setup for you: 4. When authoring a workflow it can be saved to your branch. Click on + New branch from this branch dropdown to create a new feature branch. 5. When you are ready to merge the changes from your feature branch to your collaboration branch (master), click on the branch dropdown and select Create pull request . This action takes you to Azure DevOps Git Repo where you can create pull requests, do code reviews, and merge changes to your collaboration branch (master) after the pull request has been approved. 6. After you have merged changes to the collaboration branch (master), click on Publish to publish your code changes from the master branch to Azure Data Factory. Contact the support team through the Slack channel if you receive an error when trying to Publish. Data Factory Service When Data Factory is not integrated with source control your workflows are stored directly in the Data Factory service and you cannot save partial changes, you can only Publish all which overwrites the current state of the Data Factory with your changes, which are then visible to everyone. Ingest and Transform Data with ADF Copy Data Wizard Mapping Data Flows \u2013 GUI-driven ETL Example: How to connect John Hopkins Data There is an example workflow that shows how to ingest data from GitHub using a Data Factory Pipeline. Data can be filtered from within Data Factory. Alternatively, data can be pulled from GitHub using code in a Databricks notebook. Microsoft Documentation Introduction to Azure Data Factory - Azure Data Factory Create an Azure data factory using the Azure Data Factory UI - Azure Data Factory Copy data by using the Azure Copy Data tool - Azure Data Factory Create a mapping data flow - Azure Data Factory Expression functions in the mapping data flow - Azure Data Factory Mapping data flow Debug Mode - Azure Data Factory Mapping data flow Visual Monitoring - Azure Data Factory YouTube Videos Ingest, prepare & transform using Azure Databricks & Data Factory | Azure Friday Azure Friday | Visually build pipelines for Azure Data Factory V2 How to prepare data using wrangling data flows in Azure Data Factory | Azure Friday How to develop and debug with Azure Data Factory | Azure Friday Building Data Flows in Azure Data Factory Change Display Language See Language page to find out how to change the display language.","title":"Data Factory"},{"location":"DataFactory/#azure-data-factory-adf","text":"","title":"Azure Data Factory (ADF)"},{"location":"DataFactory/#access-data-factory","text":"","title":"Access Data Factory"},{"location":"DataFactory/#dashboard","text":"See the Dashboard section of this documentation from more information. Click on the Dashboard menu from the Azure Portal.","title":"Dashboard"},{"location":"DataFactory/#adf-url","text":"Navigate to https://adf.azure.com, and select the Data Factory instance that was created for you.","title":"ADF URL"},{"location":"DataFactory/#azure-portal","text":"In the Azure Portal Search box, search for Data factories . You should then see a list of the Data Factories you were given permission to access.","title":"Azure Portal"},{"location":"DataFactory/#authoring","text":"Click on Author and Monitor . In Data Factory, you have the ability to author and deploy resources. See Visual authoring in Azure Data Factory for more information. You can also use some of the various wizards provided on Data Factory Overview page. NOTE: Configuring SSIS Integration is NOT recommended. Contact the support team through the Slack channel if you have questions. See Azure Documentation Tutorials for more details.","title":"Authoring"},{"location":"DataFactory/#access-the-data-lake-from-adf","text":"A Data Lake connection has been pre-configured for your environment. 1. Click on Manage . 2. Click on Linked Services . 3. The linked service with the Azure Data Lake Storage Gen2 type is your Data Lake . Note: You have been granted access to specific containers created in the Data Lake for your environment.","title":"Access the Data Lake from ADF"},{"location":"DataFactory/#access-azure-sql-database","text":"Some projects have an Azure SQL Database instance. 1. Click on Manage . 2. Click on Linked Services . 3. The linked service(s) with the Azure SQL Database type is / are your Database(s)","title":"Access Azure SQL Database"},{"location":"DataFactory/#save-publish-your-data-factory-resources","text":"Azure Data Factory can be configured to save your work to the following locations: 1. Git repository 2. Publish directly to Data Factory","title":"Save / Publish Your Data Factory Resources"},{"location":"DataFactory/#git-when-supported","text":"When Git is enabled you can see your configuration and save your work to a specific branch. 1. Click on Manage 2. Click on Git Configuration . 3. See the Git configuration that was setup for you: 4. When authoring a workflow it can be saved to your branch. Click on + New branch from this branch dropdown to create a new feature branch. 5. When you are ready to merge the changes from your feature branch to your collaboration branch (master), click on the branch dropdown and select Create pull request . This action takes you to Azure DevOps Git Repo where you can create pull requests, do code reviews, and merge changes to your collaboration branch (master) after the pull request has been approved. 6. After you have merged changes to the collaboration branch (master), click on Publish to publish your code changes from the master branch to Azure Data Factory. Contact the support team through the Slack channel if you receive an error when trying to Publish.","title":"Git (when supported)"},{"location":"DataFactory/#data-factory-service","text":"When Data Factory is not integrated with source control your workflows are stored directly in the Data Factory service and you cannot save partial changes, you can only Publish all which overwrites the current state of the Data Factory with your changes, which are then visible to everyone.","title":"Data Factory Service"},{"location":"DataFactory/#ingest-and-transform-data-with-adf","text":"Copy Data Wizard Mapping Data Flows \u2013 GUI-driven ETL","title":"Ingest and Transform Data with ADF"},{"location":"DataFactory/#example-how-to-connect-john-hopkins-data","text":"There is an example workflow that shows how to ingest data from GitHub using a Data Factory Pipeline. Data can be filtered from within Data Factory. Alternatively, data can be pulled from GitHub using code in a Databricks notebook.","title":"Example: How to connect John Hopkins Data"},{"location":"DataFactory/#microsoft-documentation","text":"Introduction to Azure Data Factory - Azure Data Factory Create an Azure data factory using the Azure Data Factory UI - Azure Data Factory Copy data by using the Azure Copy Data tool - Azure Data Factory Create a mapping data flow - Azure Data Factory Expression functions in the mapping data flow - Azure Data Factory Mapping data flow Debug Mode - Azure Data Factory Mapping data flow Visual Monitoring - Azure Data Factory","title":"Microsoft Documentation"},{"location":"DataFactory/#youtube-videos","text":"Ingest, prepare & transform using Azure Databricks & Data Factory | Azure Friday Azure Friday | Visually build pipelines for Azure Data Factory V2 How to prepare data using wrangling data flows in Azure Data Factory | Azure Friday How to develop and debug with Azure Data Factory | Azure Friday Building Data Flows in Azure Data Factory","title":"YouTube Videos"},{"location":"DataFactory/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"FAQ/","text":"FAQ Storage Explorer How do I ingest data into the platform? Files may be uploaded into an external storage account, as documented in Azure Storage Explorer . These files will then automatically be moved into an internal storage account (Data Lake), and made accessible from authorized services. Platform tools such as Databricks or Data Factory may be used to ingest data from public data sources. How do I configure Azure Storage Explorer proxy settings on a network B VDI? For Statistics Canada Employees only 1. Proxy configuration is required if you receive the following error: 2. In Azure Storage Explorer, go to Edit --> Proxy Settings . Enter the necessary proxy settings, and click on OK . How do I request a new SAS token (required for Azure Storage Explorer on a Network B VDI)? For Statistics Canada Employees only Please contact the support team through the https://cae-eac.slack.com channel to request a temporary SAS token. Why do I get an error message when accessing the internal Data Lake? The internal Data Lake is only accessible from within a VM in the Collaborative Analytics Environment (CAE). It is not accessible from your personal or work laptop, Network B VDI or other cloud VM. Source Code Control How do I link my Visual Studio Subscription to my StatCan cloud account? Login to https://visualstudio.microsoft.com/subscriptions/ with your organization's email address. For StatCan employees, this will be your canada.ca email address. . Add your cloud account as an alternate account. This will allow you to use your licenses for Visual Studio & Azure DevOps in the CAE. For Statistics Canada employees: If you do not have a Visual Studio Subscription, please consult your supervisor. If they decide that a subscription is needed, they can then contact StatCan Software Asset Management by submitting an SRM to request a license on your behalf. Virtual Machines What do I do if I have forgotten the password for my virtual machine? If you forget the password of your virtual machine you can delete then recreate your virtual machine. Unfortunately, you will lose any data and software on your old machine. What do I do if I need to run a long running job on my virtual machine? Machines are shut down every day at 7pm EST in order to reduce costs. If you have a long-running job, it is recommended that you use Databricks or Data Factory. WARNING: Disabling Auto-shutdown is not recommended as it can incur significant costs. To disable Auto-shutdown: 1. Navigate to your virtual machine in the Azure Portal. 2. Disable Auto-shutdown. How do I request changes to my virtual machine? If the virtual machine you are currently using does not meet your requirements, please contact the support team through the https://cae-eac.slack.com channel. Databricks Why am I unable to run code from my Databricks notebook? You must first start a Databricks cluster that was previously created for you: 1. Click on Clusters. 2. Navigate to your cluster and click on the Start (arrow) button. Other How do I connect to the internal data lake with Power BI Desktop? Prerequisites: 1. A VM in the Collaborative Analytics Environment (CAE). 2. Power BI Desktop. (Available by default in the Windows Data Science Virtual Machine images.) Steps: 1. Login to your CAE VM. 2. Launch Power BI Desktop. 3. Follow the steps in Analyze data in Azure Data Lake Storage Gen2 by using Power BI - Create a report in Power BI Desktop . Please send a slack message to https://cae-eac.slack.com if you don't know the Azure Data Lake Storage Gen2 URL. How do I add a FAQ? Please send your suggestion through the https://cae-eac.slack.com channel. Change Display Language See Language page to find out how to change the display language.","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#storage-explorer","text":"","title":"Storage Explorer"},{"location":"FAQ/#how-do-i-ingest-data-into-the-platform","text":"Files may be uploaded into an external storage account, as documented in Azure Storage Explorer . These files will then automatically be moved into an internal storage account (Data Lake), and made accessible from authorized services. Platform tools such as Databricks or Data Factory may be used to ingest data from public data sources.","title":"How do I ingest data into the platform?"},{"location":"FAQ/#how-do-i-configure-azure-storage-explorer-proxy-settings-on-a-network-b-vdi","text":"For Statistics Canada Employees only 1. Proxy configuration is required if you receive the following error: 2. In Azure Storage Explorer, go to Edit --> Proxy Settings . Enter the necessary proxy settings, and click on OK .","title":"How do I configure Azure Storage Explorer proxy settings on a network B VDI?"},{"location":"FAQ/#how-do-i-request-a-new-sas-token-required-for-azure-storage-explorer-on-a-network-b-vdi","text":"For Statistics Canada Employees only Please contact the support team through the https://cae-eac.slack.com channel to request a temporary SAS token.","title":"How do I request a new SAS token (required for Azure Storage Explorer on a Network B VDI)?"},{"location":"FAQ/#why-do-i-get-an-error-message-when-accessing-the-internal-data-lake","text":"The internal Data Lake is only accessible from within a VM in the Collaborative Analytics Environment (CAE). It is not accessible from your personal or work laptop, Network B VDI or other cloud VM.","title":"Why do I get an error message when accessing the internal Data Lake?"},{"location":"FAQ/#source-code-control","text":"","title":"Source Code Control"},{"location":"FAQ/#how-do-i-link-my-visual-studio-subscription-to-my-statcan-cloud-account","text":"Login to https://visualstudio.microsoft.com/subscriptions/ with your organization's email address. For StatCan employees, this will be your canada.ca email address. . Add your cloud account as an alternate account. This will allow you to use your licenses for Visual Studio & Azure DevOps in the CAE. For Statistics Canada employees: If you do not have a Visual Studio Subscription, please consult your supervisor. If they decide that a subscription is needed, they can then contact StatCan Software Asset Management by submitting an SRM to request a license on your behalf.","title":"How do I link my Visual Studio Subscription to my StatCan cloud account?"},{"location":"FAQ/#virtual-machines","text":"","title":"Virtual Machines"},{"location":"FAQ/#what-do-i-do-if-i-have-forgotten-the-password-for-my-virtual-machine","text":"If you forget the password of your virtual machine you can delete then recreate your virtual machine. Unfortunately, you will lose any data and software on your old machine.","title":"What do I do if I have forgotten the password for my virtual machine?"},{"location":"FAQ/#what-do-i-do-if-i-need-to-run-a-long-running-job-on-my-virtual-machine","text":"Machines are shut down every day at 7pm EST in order to reduce costs. If you have a long-running job, it is recommended that you use Databricks or Data Factory. WARNING: Disabling Auto-shutdown is not recommended as it can incur significant costs. To disable Auto-shutdown: 1. Navigate to your virtual machine in the Azure Portal. 2. Disable Auto-shutdown.","title":"What do I do if I need to run a long running job on my virtual machine?"},{"location":"FAQ/#how-do-i-request-changes-to-my-virtual-machine","text":"If the virtual machine you are currently using does not meet your requirements, please contact the support team through the https://cae-eac.slack.com channel.","title":"How do I request changes to my virtual machine?"},{"location":"FAQ/#databricks","text":"","title":"Databricks"},{"location":"FAQ/#why-am-i-unable-to-run-code-from-my-databricks-notebook","text":"You must first start a Databricks cluster that was previously created for you: 1. Click on Clusters. 2. Navigate to your cluster and click on the Start (arrow) button.","title":"Why am I unable to run code from my Databricks notebook?"},{"location":"FAQ/#other","text":"","title":"Other"},{"location":"FAQ/#how-do-i-connect-to-the-internal-data-lake-with-power-bi-desktop","text":"Prerequisites: 1. A VM in the Collaborative Analytics Environment (CAE). 2. Power BI Desktop. (Available by default in the Windows Data Science Virtual Machine images.) Steps: 1. Login to your CAE VM. 2. Launch Power BI Desktop. 3. Follow the steps in Analyze data in Azure Data Lake Storage Gen2 by using Power BI - Create a report in Power BI Desktop . Please send a slack message to https://cae-eac.slack.com if you don't know the Azure Data Lake Storage Gen2 URL.","title":"How do I connect to the internal data lake with Power BI Desktop?"},{"location":"FAQ/#how-do-i-add-a-faq","text":"Please send your suggestion through the https://cae-eac.slack.com channel.","title":"How do I add a FAQ?"},{"location":"FAQ/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"Language/","text":"Language The document describes how to change languages in the various service offerings. Azure portal To change the language settings in the Azure portal: Click the Settings menu in the global page header. Click the Language & region tab. Use the drop-downs to choose your preferred language and regional format settings. Click Apply to update your language and regional format settings. Dashboard To select the English dashboard of the Collaborative Analytics Environment (CAE): From the dashboard view, click the arrow next to the dashboard name. Select the Collaborative Analytics Environment dashboard from the displayed list of dashboards. Note: If the dashboard is not listed, select Browse all dashboards to access the complete list. DataFactory This tool is available only in english for now. Databricks This tool is available only in english for now. Virtual Machines Windows Server To configure the display language for a Windows virtual machine: Go to Settings . Select Time & Language . Select Language . Under Preferred languages , select Add a language . In the Choose a language to install dialog box, select your preferred language pack and then click Next . In the Install language features dialog box, click Install . The Windows display language box should now include the newly added language. To switch to the new language, select it from the Windows display language box, sign out of the current Windows session, and then sign back in. Ubuntu Server If you are using X2GO to access the GUI of your Ubuntu machine, you might need to manually install additional language packages because the default session is available only in English. Machine Learning To change the language settings in the Microsoft Azure Machine Learning workspace: Click the Settings menu in the global page header. Under Language and formats , use the drop-downs to choose your preferred language and the regional format settings. Click Apply to update your language and regional format settings. Slack To change the language settings in the Slack application: Click the profile icon in the global page header. Click Preferences . Select the Language & region tab. Under Language , use the drop-down to choose your preferred language. Close the Preferences window. Microsoft Azure Storage Explorer By default, the application detects your language based on the language preferences on your computer. To change the language settings on Microsoft Azure Storage Explorer: Click Edit . Click Settings . In the Settings page, select Application . Under Regional Settings , use the drop-down to choose your preferred language. To switch to the new language, close and restart the application. Power BI More information is also available in Supported languages and countries/regions for Power BI . Power BI Service By default, the Power BI service detects your language based on the language preferences on your computer. The steps to access and change these preferences may vary depending on your operating system and browser. To switch the menu language in the Power BI service: In the Power BI service, click the Settings icon and select Settings . In the General tab, select Language . Select your language and click Apply . See Languages for the Power BI service for more details. Power BI Desktop By default, \u2022 the Application language is based on the Windows language \u2022 the Model language is based on the Application language \u2022 the Query steps are based on the Application language . It is recommended to set the Model language to English (United States) . The model language applies only when the report is first created and cannot be changed on existing reports. Thus, setting the language model to U.S. English is recommended, unless you have a specific need to use another language for the report model. String comparisons and internal date fields are affected by this setting. To switch the menu language and model language in Power BI Desktop: Open the Options menu. Under GLOBAL , click Regional Settings and set the Application language and Model language to the desired language. NOTE : The Import language is set separately in the CURRENT FILE section Regional Settings . You need to change this only if you import data files that have numbers and dates in a specific locale (e.g., Canada English DD/MM/YYYY, United State English MM/DD/YYYY). Web browsers Chrome Safari Edge Firefox Opera Change Display Language See Language page to find out how to change the display language.","title":"Language"},{"location":"Language/#language","text":"The document describes how to change languages in the various service offerings.","title":"Language"},{"location":"Language/#azure-portal","text":"To change the language settings in the Azure portal: Click the Settings menu in the global page header. Click the Language & region tab. Use the drop-downs to choose your preferred language and regional format settings. Click Apply to update your language and regional format settings.","title":"Azure portal"},{"location":"Language/#dashboard","text":"To select the English dashboard of the Collaborative Analytics Environment (CAE): From the dashboard view, click the arrow next to the dashboard name. Select the Collaborative Analytics Environment dashboard from the displayed list of dashboards. Note: If the dashboard is not listed, select Browse all dashboards to access the complete list.","title":"Dashboard"},{"location":"Language/#datafactory","text":"This tool is available only in english for now.","title":"DataFactory"},{"location":"Language/#databricks","text":"This tool is available only in english for now.","title":"Databricks"},{"location":"Language/#virtual-machines","text":"","title":"Virtual Machines"},{"location":"Language/#windows-server","text":"To configure the display language for a Windows virtual machine: Go to Settings . Select Time & Language . Select Language . Under Preferred languages , select Add a language . In the Choose a language to install dialog box, select your preferred language pack and then click Next . In the Install language features dialog box, click Install . The Windows display language box should now include the newly added language. To switch to the new language, select it from the Windows display language box, sign out of the current Windows session, and then sign back in.","title":"Windows Server"},{"location":"Language/#ubuntu-server","text":"If you are using X2GO to access the GUI of your Ubuntu machine, you might need to manually install additional language packages because the default session is available only in English.","title":"Ubuntu Server"},{"location":"Language/#machine-learning","text":"To change the language settings in the Microsoft Azure Machine Learning workspace: Click the Settings menu in the global page header. Under Language and formats , use the drop-downs to choose your preferred language and the regional format settings. Click Apply to update your language and regional format settings.","title":"Machine Learning"},{"location":"Language/#slack","text":"To change the language settings in the Slack application: Click the profile icon in the global page header. Click Preferences . Select the Language & region tab. Under Language , use the drop-down to choose your preferred language. Close the Preferences window.","title":"Slack"},{"location":"Language/#microsoft-azure-storage-explorer","text":"By default, the application detects your language based on the language preferences on your computer. To change the language settings on Microsoft Azure Storage Explorer: Click Edit . Click Settings . In the Settings page, select Application . Under Regional Settings , use the drop-down to choose your preferred language. To switch to the new language, close and restart the application.","title":"Microsoft Azure Storage Explorer"},{"location":"Language/#power-bi","text":"More information is also available in Supported languages and countries/regions for Power BI .","title":"Power BI"},{"location":"Language/#power-bi-service","text":"By default, the Power BI service detects your language based on the language preferences on your computer. The steps to access and change these preferences may vary depending on your operating system and browser. To switch the menu language in the Power BI service: In the Power BI service, click the Settings icon and select Settings . In the General tab, select Language . Select your language and click Apply . See Languages for the Power BI service for more details.","title":"Power BI Service"},{"location":"Language/#power-bi-desktop","text":"By default, \u2022 the Application language is based on the Windows language \u2022 the Model language is based on the Application language \u2022 the Query steps are based on the Application language . It is recommended to set the Model language to English (United States) . The model language applies only when the report is first created and cannot be changed on existing reports. Thus, setting the language model to U.S. English is recommended, unless you have a specific need to use another language for the report model. String comparisons and internal date fields are affected by this setting. To switch the menu language and model language in Power BI Desktop: Open the Options menu. Under GLOBAL , click Regional Settings and set the Application language and Model language to the desired language. NOTE : The Import language is set separately in the CURRENT FILE section Regional Settings . You need to change this only if you import data files that have numbers and dates in a specific locale (e.g., Canada English DD/MM/YYYY, United State English MM/DD/YYYY).","title":"Power BI Desktop"},{"location":"Language/#web-browsers","text":"Chrome Safari Edge Firefox Opera","title":"Web browsers"},{"location":"Language/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"Login/","text":"How to Login Prerequisites An authorized StatCan Cloud account or guest account. Access using StatCan Network accounts is currently only available for the Power BI Service, but may be added in the future for other services in the Collaborative Analytics Environment (CAE). Notes We recommend you use Chrome, Chromium or Edge (not Internet Explorer) to access the Azure Portal, Azure services or the Power BI Service. When connecting to the Azure cloud services, you will either login with your: - StatCan Cloud account (i.e.\u202ffirstname.lastname@cloud.statcan.ca) or - Other government or researcher email credentials (e.g. firstname.lastname@dept-d\u00e9pt.gc.ca or name@gov.prov.ca) or - StatCan Network account (i.e. firstname.lastname@statcan.gc.ca) for StatCan employees using the Power BI Service only Follow the instructions for your type of account to complete your sign-in. StatCan Cloud Account (firstname.lastname@cloud.statcan.ca) Applicable to all Azure cloud Services (Power BI, Databricks, Data Factory, Virtual Machine, etc.) Using Chrome, Chromium or Edge, open either: The Collaborative Analytics Environment Azure Portal Dashboard The Power BI App URL (if provided) or Power BI Service Login Page When opening a Power BI App URL or the Power BI Service login page, you will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. Click on SIGN IN . You will then be prompted to either enter or pick an account: Upon your first time signing in, you will receive the Microsoft Sign in prompt, as shown below. Enter your cloud account credentials (firstname.lastname@cloud.statcan.ca), and click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your cloud.statcan.ca account. You will then be prompted to enter your cloud account password, as shown below. Once entered, click on Sign in . Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you log in to a Web portal with your cloud account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions. Other Government or Researcher Email Credentials Applicable to most Azure cloud Services (Power BI, Databricks, Data Factory, Virtual Machine, etc.) Using Chrome, Chromium or Edge, open either: The Collaborative Analytics Environment Azure Portal Dashboard The Power BI App URL (if provided) or Power BI Service Login Page Azure Databricks Azure Data Factory When opening a Power BI App URL or the Power BI Service login page, you will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. Click on SIGN IN . You will then be prompted to either enter or pick an account: Upon your first time signing in, you will receive the Microsoft Sign in prompt, as shown below. Enter your official email/O365 credentials or GCCollaboration credentials (e.g., firstname.lastname@dept-d\u00e9pt.gc.ca, firstname.lastname.department@gccollaboration.ca or name@gov.prov.ca), and click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your official email/O365 credentials or GCCollaboration credentials (e.g., firstname.lastname@dept-d\u00e9pt.gc.ca, firstname.lastname.department@gccollaboration.ca or name@gov.prov.ca) account. You will then be prompted to enter your cloud account password, as shown below. Once entered, click on Sign in . If your Official Email Credentials do not support this type of login you will automatically be emailed a code to enter in place of a password and then click on Sign in . - The Email you receive will look like the following , if you do not receive it double check if it was sent to your Spam or Junk folder . Accept the Review permissions (first time only consent). You will then receive the following message. Wait until completed. Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you log in to a Web portal with your cloud account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions. StatCan Network Account (firstname.lastname@statcan.gc.ca) Applicable to the Power BI Service for Statistics Canada employees only. May be added in the future for other services in the Collaborative Analytics Environment (CAE) Please note that step 5 (Internet password) below may not appear in the order specified. From a StatCan laptop or Network B VDI, and using Chrome or Chromium, open either: -The Power BI App URL (if provided) or -https://powerbi.microsoft.com/en-us/landing/signin/ You will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. You will then be prompted to either enter or pick an account: On first time sign-in, you will receive the Microsoft Sign in prompt, as shown below. Enter your StatCan Network account (firstname.lastname@statcan.gc.ca), and then, click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your statcan.gc.ca account. You will then receive a Microsoft message \u201cTaking you to your organizations sign-in page\u201d. You may then be prompted to enter your Internet username and password as shown below. Once entered, click Sign in . You will then be prompted to sign in using your StatCan Network account (i.e.\u202ffirstname.lastname@statcan.gc.ca) and Network A password. Once entered, click Sign in . Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you logged in to a Web portal with your StatCan Network account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions. Microsoft Documentation https://docs.microsoft.com/en-us/azure/azure-portal/ Change Display Language See Language page to find out how to change the display language.","title":"Login"},{"location":"Login/#how-to-login","text":"","title":"How to Login"},{"location":"Login/#prerequisites","text":"An authorized StatCan Cloud account or guest account. Access using StatCan Network accounts is currently only available for the Power BI Service, but may be added in the future for other services in the Collaborative Analytics Environment (CAE).","title":"Prerequisites"},{"location":"Login/#notes","text":"We recommend you use Chrome, Chromium or Edge (not Internet Explorer) to access the Azure Portal, Azure services or the Power BI Service. When connecting to the Azure cloud services, you will either login with your: - StatCan Cloud account (i.e.\u202ffirstname.lastname@cloud.statcan.ca) or - Other government or researcher email credentials (e.g. firstname.lastname@dept-d\u00e9pt.gc.ca or name@gov.prov.ca) or - StatCan Network account (i.e. firstname.lastname@statcan.gc.ca) for StatCan employees using the Power BI Service only Follow the instructions for your type of account to complete your sign-in.","title":"Notes"},{"location":"Login/#statcan-cloud-account-firstnamelastnamecloudstatcanca","text":"Applicable to all Azure cloud Services (Power BI, Databricks, Data Factory, Virtual Machine, etc.) Using Chrome, Chromium or Edge, open either: The Collaborative Analytics Environment Azure Portal Dashboard The Power BI App URL (if provided) or Power BI Service Login Page When opening a Power BI App URL or the Power BI Service login page, you will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. Click on SIGN IN . You will then be prompted to either enter or pick an account: Upon your first time signing in, you will receive the Microsoft Sign in prompt, as shown below. Enter your cloud account credentials (firstname.lastname@cloud.statcan.ca), and click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your cloud.statcan.ca account. You will then be prompted to enter your cloud account password, as shown below. Once entered, click on Sign in . Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you log in to a Web portal with your cloud account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions.","title":"StatCan Cloud Account (firstname.lastname@cloud.statcan.ca)"},{"location":"Login/#other-government-or-researcher-email-credentials","text":"Applicable to most Azure cloud Services (Power BI, Databricks, Data Factory, Virtual Machine, etc.) Using Chrome, Chromium or Edge, open either: The Collaborative Analytics Environment Azure Portal Dashboard The Power BI App URL (if provided) or Power BI Service Login Page Azure Databricks Azure Data Factory When opening a Power BI App URL or the Power BI Service login page, you will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. Click on SIGN IN . You will then be prompted to either enter or pick an account: Upon your first time signing in, you will receive the Microsoft Sign in prompt, as shown below. Enter your official email/O365 credentials or GCCollaboration credentials (e.g., firstname.lastname@dept-d\u00e9pt.gc.ca, firstname.lastname.department@gccollaboration.ca or name@gov.prov.ca), and click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your official email/O365 credentials or GCCollaboration credentials (e.g., firstname.lastname@dept-d\u00e9pt.gc.ca, firstname.lastname.department@gccollaboration.ca or name@gov.prov.ca) account. You will then be prompted to enter your cloud account password, as shown below. Once entered, click on Sign in . If your Official Email Credentials do not support this type of login you will automatically be emailed a code to enter in place of a password and then click on Sign in . - The Email you receive will look like the following , if you do not receive it double check if it was sent to your Spam or Junk folder . Accept the Review permissions (first time only consent). You will then receive the following message. Wait until completed. Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you log in to a Web portal with your cloud account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions.","title":"Other Government or Researcher Email Credentials"},{"location":"Login/#statcan-network-account-firstnamelastnamestatcangcca","text":"Applicable to the Power BI Service for Statistics Canada employees only. May be added in the future for other services in the Collaborative Analytics Environment (CAE) Please note that step 5 (Internet password) below may not appear in the order specified. From a StatCan laptop or Network B VDI, and using Chrome or Chromium, open either: -The Power BI App URL (if provided) or -https://powerbi.microsoft.com/en-us/landing/signin/ You will be directed to the Microsoft Power BI Sign In landing page, as shown below, saying \u201cAlready have an account?\u201d. You will then be prompted to either enter or pick an account: On first time sign-in, you will receive the Microsoft Sign in prompt, as shown below. Enter your StatCan Network account (firstname.lastname@statcan.gc.ca), and then, click on Next . On subsequent sign-ins, you will receive the Microsoft Pick an account prompt, as shown below. Click on your statcan.gc.ca account. You will then receive a Microsoft message \u201cTaking you to your organizations sign-in page\u201d. You may then be prompted to enter your Internet username and password as shown below. Once entered, click Sign in . You will then be prompted to sign in using your StatCan Network account (i.e.\u202ffirstname.lastname@statcan.gc.ca) and Network A password. Once entered, click Sign in . Lastly, you may receive the More Information required \u2013 Your organization needs more information to keep your account secure prompt from Statistics Canada, as shown below, especially if it\u2019s the first time you logged in to a Web portal with your StatCan Network account. Click on Next and ensure to follow the instructions to secure your account by configuring your authentication email and configuring your security questions.","title":"StatCan Network Account (firstname.lastname@statcan.gc.ca)"},{"location":"Login/#microsoft-documentation","text":"https://docs.microsoft.com/en-us/azure/azure-portal/","title":"Microsoft Documentation"},{"location":"Login/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"R-Shiny/","text":"R-Shiny from RStudio The document describes how to access to R-Shiny package from RStudio. Getting Starting Please send a slack message to the CEA team to enable RStudio on your databricks cluster to be able to use R-Shiny. Warning : R-Shiny clusters are shut down everyday at 7pm . To save cost, please stop your R-Shiny clusters when you are not using them. How to Access From the Azure portal, Launch the Databricks workspace that was created for you. From the Databricks workspace, click on Clusters . From the available list of clusters, select the cluster with RStudio installed. Note: You must have the cluster running before you can access to RStudio. See the Databricks section for information on how to start a cluster. Select the Apps tab. Click on Set up RStudio . A one-time password is generated for you, click on the show to display and copy it. Click on Open RStudio . A new tab opens, enter the username and password provided (step 6) in the login form and sign in to RStudio. From the RStudio UI, enter the library(shiny) command in the console to import the Shiny package. RShiny app example We will use the Hello Shiny example to explore the structure of a Shiny app. Launch the app from your R session by running: library(shiny) runExample(\"01_hello\") Your app should match the image below. Accessing files from the datalake By default, the working directory in RStudio will be on the driver node, to persist your work you'll need to use DBFS. To have access DBFS in the File Explorer, click on the ... to the right and enter /dbfs/mnt/ at the prompt. The datalake will be available and you will be able to acces and store your files. When your cluster is terminated at the end of your session, the work will be there for you when you return. NOTE: Here are sample codes to access your files from the datalake. library(SparkR) sparkR.session() testData = as.data.frame(read.df(\"/mnt/the file path\", source = \"the file extension\", header=\"true\", inferSchema = \"true\")) str(testData) setwd(\"/dbfs/mnt/the file path\") testData = read.csv(\"the filename\") str(testData) Change Display Language See Language page to find out how to change the display language.","title":"R-Shiny from RStudio"},{"location":"R-Shiny/#r-shiny-from-rstudio","text":"The document describes how to access to R-Shiny package from RStudio.","title":"R-Shiny from RStudio"},{"location":"R-Shiny/#getting-starting","text":"Please send a slack message to the CEA team to enable RStudio on your databricks cluster to be able to use R-Shiny. Warning : R-Shiny clusters are shut down everyday at 7pm . To save cost, please stop your R-Shiny clusters when you are not using them.","title":"Getting Starting"},{"location":"R-Shiny/#how-to-access","text":"From the Azure portal, Launch the Databricks workspace that was created for you. From the Databricks workspace, click on Clusters . From the available list of clusters, select the cluster with RStudio installed. Note: You must have the cluster running before you can access to RStudio. See the Databricks section for information on how to start a cluster. Select the Apps tab. Click on Set up RStudio . A one-time password is generated for you, click on the show to display and copy it. Click on Open RStudio . A new tab opens, enter the username and password provided (step 6) in the login form and sign in to RStudio. From the RStudio UI, enter the library(shiny) command in the console to import the Shiny package.","title":"How to Access"},{"location":"R-Shiny/#rshiny-app-example","text":"We will use the Hello Shiny example to explore the structure of a Shiny app. Launch the app from your R session by running: library(shiny) runExample(\"01_hello\") Your app should match the image below.","title":"RShiny app example"},{"location":"R-Shiny/#accessing-files-from-the-datalake","text":"By default, the working directory in RStudio will be on the driver node, to persist your work you'll need to use DBFS. To have access DBFS in the File Explorer, click on the ... to the right and enter /dbfs/mnt/ at the prompt. The datalake will be available and you will be able to acces and store your files. When your cluster is terminated at the end of your session, the work will be there for you when you return. NOTE: Here are sample codes to access your files from the datalake. library(SparkR) sparkR.session() testData = as.data.frame(read.df(\"/mnt/the file path\", source = \"the file extension\", header=\"true\", inferSchema = \"true\")) str(testData) setwd(\"/dbfs/mnt/the file path\") testData = read.csv(\"the filename\") str(testData)","title":"Accessing files from the datalake"},{"location":"R-Shiny/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"RequestAccess/","text":"Request Access If you have already been given access to the platform, see How to login for more information. Otherwise, you request access via the slack channel. Change Display Language See Language page to find out how to change the display language.","title":"Request Access"},{"location":"RequestAccess/#request-access","text":"If you have already been given access to the platform, see How to login for more information. Otherwise, you request access via the slack channel.","title":"Request Access"},{"location":"RequestAccess/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"SwitchLanguage/","text":"Switch Language How to swtich langiages using the folliwng tools... Azure Portal instrctions... # DevTest Labs ## Windows VM Steps on how to change language inside the VM Linux BM (Ubunutu XX) Steps to change to French or english Machine Learning Please see Data Factory Databrick Browser For details on how to change your specifice to a different language. Plese see these sotes\u00e0 Chrome Firefox IE","title":"Switch Language"},{"location":"SwitchLanguage/#switch-language","text":"How to swtich langiages using the folliwng tools...","title":"Switch Language"},{"location":"SwitchLanguage/#azure-portal","text":"instrctions... # DevTest Labs ## Windows VM Steps on how to change language inside the VM","title":"Azure Portal"},{"location":"SwitchLanguage/#linux-bm-ubunutu-xx","text":"Steps to change to French or english","title":"Linux BM (Ubunutu XX)"},{"location":"SwitchLanguage/#machine-learning","text":"Please see","title":"Machine Learning"},{"location":"SwitchLanguage/#data-factory","text":"","title":"Data Factory"},{"location":"SwitchLanguage/#databrick","text":"","title":"Databrick"},{"location":"SwitchLanguage/#browser","text":"For details on how to change your specifice to a different language. Plese see these sotes\u00e0 Chrome Firefox IE","title":"Browser"},{"location":"VirtualMachines/","text":"Virtual Machines Find Your DevTest Lab In your project's custom Dashboard in the Azure Portal, click on the DevTest Lab. Create Your Virtual Machine Note: In some instances a Virtual Machine will be pre-created for you and you will not have permission to create a virtual machine. See the FAQ if you need to make changes to your virtual machine. From the DevTest Lab Overview page, click on the + Add button. Choose an appropriate base for your VM (e.g., Data Science Virtual Machine - Windows Server 2019). For more details on the software included with the Data Science Virtual Machines, please click here . Enter a name for your VM and a User name and password that you will use to login to the VM. Be sure to deselect the Use a saved secret and Save as default password checkboxes. Leave the rest as defaults and click on the Create button. Find Your Virtual Machine From the DevTest Lab Overview page, scroll down until you see your VM under My virtual machines . Click on your VM to access its Overview page. Start Your Virtual Machine From the Overview page for your VM, click on the Start button. It takes a few minutes for your VM to start up. Monitor its startup progress by selecting the Notifications icon at the top right of the window. Connect To Your Virtual Machine From the Overview page for your VM, click on the Browser connect button (if you do not see a Browser connect button you might have to click on the Connect button and then choose Bastion from the dropdown menu). Ensure the Open in new window checkbox is selected, enter the Username and Password that you used when you created your VM, and click on the Connect button. Your VM should open in a new browser tab. Note : By default, the Ubuntu virtual machine opens in Terminal mode. You can access the GUI of your Ubuntu machine from a Windows machine using X2Go . Stop Your Virtual Machine Virtual machines only incur costs while they are running. You should shut down your virtual machine when not in use to prevent unneccessary charges. 1. From the Overview page for your VM, click on the Stop button. Change Display Language See Language page to find out how to change the display language.","title":"Virtual Machines (VMs)"},{"location":"VirtualMachines/#virtual-machines","text":"","title":"Virtual Machines"},{"location":"VirtualMachines/#find-your-devtest-lab","text":"In your project's custom Dashboard in the Azure Portal, click on the DevTest Lab.","title":"Find Your DevTest Lab"},{"location":"VirtualMachines/#create-your-virtual-machine","text":"Note: In some instances a Virtual Machine will be pre-created for you and you will not have permission to create a virtual machine. See the FAQ if you need to make changes to your virtual machine. From the DevTest Lab Overview page, click on the + Add button. Choose an appropriate base for your VM (e.g., Data Science Virtual Machine - Windows Server 2019). For more details on the software included with the Data Science Virtual Machines, please click here . Enter a name for your VM and a User name and password that you will use to login to the VM. Be sure to deselect the Use a saved secret and Save as default password checkboxes. Leave the rest as defaults and click on the Create button.","title":"Create Your Virtual Machine"},{"location":"VirtualMachines/#find-your-virtual-machine","text":"From the DevTest Lab Overview page, scroll down until you see your VM under My virtual machines . Click on your VM to access its Overview page.","title":"Find Your Virtual Machine"},{"location":"VirtualMachines/#start-your-virtual-machine","text":"From the Overview page for your VM, click on the Start button. It takes a few minutes for your VM to start up. Monitor its startup progress by selecting the Notifications icon at the top right of the window.","title":"Start Your Virtual Machine"},{"location":"VirtualMachines/#connect-to-your-virtual-machine","text":"From the Overview page for your VM, click on the Browser connect button (if you do not see a Browser connect button you might have to click on the Connect button and then choose Bastion from the dropdown menu). Ensure the Open in new window checkbox is selected, enter the Username and Password that you used when you created your VM, and click on the Connect button. Your VM should open in a new browser tab. Note : By default, the Ubuntu virtual machine opens in Terminal mode. You can access the GUI of your Ubuntu machine from a Windows machine using X2Go .","title":"Connect To Your Virtual Machine"},{"location":"VirtualMachines/#stop-your-virtual-machine","text":"Virtual machines only incur costs while they are running. You should shut down your virtual machine when not in use to prevent unneccessary charges. 1. From the Overview page for your VM, click on the Stop button.","title":"Stop Your Virtual Machine"},{"location":"VirtualMachines/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"help/","text":"Help FAQ See FAQ Slack Channels Subscribe to the following slack channel: https://cae-eac.slack.com Change Display Language See Language page to find out how to change the display language.","title":"Help/Contact"},{"location":"help/#help","text":"","title":"Help"},{"location":"help/#faq","text":"See FAQ","title":"FAQ"},{"location":"help/#slack-channels","text":"Subscribe to the following slack channel: https://cae-eac.slack.com","title":"Slack Channels"},{"location":"help/#change-display-language","text":"See Language page to find out how to change the display language.","title":"Change Display Language"},{"location":"Archive/VirtualMachineAccess/","text":"Find Your Virtual Machine From your project's DevTest Lab's Overview page scroll down until you see your VM under My virtual machines . Click this to access the Overview page for your VM. Start Your Virtual Machine From the Overview page for your VM, click the Start button. It takes a few minutes for your VM to start up, monitor its startup progress by selecting the Notifications icon at the top right of the window. Connect To Your Virtual Machine From your project's DevTest Lab's Overview page scroll down until you see your VM under My virtual machines . Click this and then from the Overview page for your VM click the Browser connect button (if you do not see a Browser connect button you might have to hit the Connect button and then choose Bastion from the dropdown menu). Ensure the Open in new window checkbox is selected, type in the Username and Password that you used when you created your VM, and click the Connect button. Your VM should open in a new browser tab. Stop Your Virtual Machine From the Overview page for your VM, click the Stop button.","title":"Find Your Virtual Machine"},{"location":"Archive/VirtualMachineAccess/#find-your-virtual-machine","text":"From your project's DevTest Lab's Overview page scroll down until you see your VM under My virtual machines . Click this to access the Overview page for your VM.","title":"Find Your Virtual Machine"},{"location":"Archive/VirtualMachineAccess/#start-your-virtual-machine","text":"From the Overview page for your VM, click the Start button. It takes a few minutes for your VM to start up, monitor its startup progress by selecting the Notifications icon at the top right of the window.","title":"Start Your Virtual Machine"},{"location":"Archive/VirtualMachineAccess/#connect-to-your-virtual-machine","text":"From your project's DevTest Lab's Overview page scroll down until you see your VM under My virtual machines . Click this and then from the Overview page for your VM click the Browser connect button (if you do not see a Browser connect button you might have to hit the Connect button and then choose Bastion from the dropdown menu). Ensure the Open in new window checkbox is selected, type in the Username and Password that you used when you created your VM, and click the Connect button. Your VM should open in a new browser tab.","title":"Connect To Your Virtual Machine"},{"location":"Archive/VirtualMachineAccess/#stop-your-virtual-machine","text":"From the Overview page for your VM, click the Stop button.","title":"Stop Your Virtual Machine"},{"location":"Archive/VirtualMachineCreate/","text":"Create Your Virtual Machine From your project's DevTest Lab's Overview page press the + Add button. Choose an appropriate base for your VM (eg. Data Science Virtual Machine - Windows Server 2019). For more details on software included with the Data Science Virtual Machines please click here . Enter a name for your VM and a User name and password that you wish to use to log into it. Be sure to deselect Save as default password checkbox. Leave the rest as defaults and click the Create button","title":"Create Your Virtual Machine"},{"location":"Archive/VirtualMachineCreate/#create-your-virtual-machine","text":"From your project's DevTest Lab's Overview page press the + Add button. Choose an appropriate base for your VM (eg. Data Science Virtual Machine - Windows Server 2019). For more details on software included with the Data Science Virtual Machines please click here . Enter a name for your VM and a User name and password that you wish to use to log into it. Be sure to deselect Save as default password checkbox. Leave the rest as defaults and click the Create button","title":"Create Your Virtual Machine"},{"location":"Archive/VirtualMachineDevTestLab/","text":"Find Your DevTest Lab Go to your project's DevTest Lab by clicking it from within your project's custom Dashboard.","title":"Find Your DevTest Lab"},{"location":"Archive/VirtualMachineDevTestLab/#find-your-devtest-lab","text":"Go to your project's DevTest Lab by clicking it from within your project's custom Dashboard.","title":"Find Your DevTest Lab"}]}